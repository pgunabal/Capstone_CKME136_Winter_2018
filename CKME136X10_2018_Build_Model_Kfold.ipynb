{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#in case we need to repeat experiment\n",
    "#np.random.seed(255)\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 22\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('classic')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "#sklearn imports\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pickle # allows for model to be saved/load to file\n",
    "import time\n",
    "\n",
    "#Use print instead of display when run as python script\n",
    "pyscript = True\n",
    "\n",
    "#Classifier verborsity where supported\n",
    "verbose_level=3\n",
    "\n",
    "#Multiclass classification, binary if falase\n",
    "multiclass = True\n",
    "over_sample = True\n",
    "\n",
    "#inputfile = 'CKME136X10_2018_Data_CTF.csv'\n",
    "if multiclass:\n",
    "    inputfile_train_O = 'CKME136X10_2018_Data_CTFB_M_O_Train.csv'\n",
    "    inputfile_train_U = 'CKME136X10_2018_Data_CTFB_M_U_Train.csv'\n",
    "    inputfile_test = 'CKME136X10_2018_Data_CTFB_M_Test.csv'\n",
    "else:\n",
    "    inputfile_train_O = 'CKME136X10_2018_Data_CTFB_B_O_Train.csv'\n",
    "    inputfile_train_U = 'CKME136X10_2018_Data_CTFB_B_U_Train.csv'\n",
    "    inputfile_test = 'CKME136X10_2018_Data_CTFB_B_Test.csv'\n",
    "\n",
    "if over_sample:\n",
    "    datafile_train = inputfile_train_O\n",
    "else:\n",
    "    datafile_train = inputfile_train_U\n",
    "\n",
    "datafile_test = inputfile_test\n",
    "    \n",
    "model_max_iter = 100\n",
    "datestr = 'dec_09_binary_run_1000_KBO'\n",
    "\n",
    "#Model Store\n",
    "file_lr = 'lr_' + datestr + '.model'\n",
    "file_lr_l1 = 'lr_l2_' + datestr + '.model'\n",
    "file_dt = 'dt_' + datestr + '.model'\n",
    "file_svm = 'svm_' + datestr + '.model'\n",
    "file_knn = 'knn_' + datestr + '.model'\n",
    "file_mlp = 'mlp_' + datestr + '.model'\n",
    "file_kmean = 'kmean_' + datestr + '.model'\n",
    "file_nbayes = 'nbayes_' + datestr + '.model'\n",
    "\n",
    "file_final_train = 'final_train_' + datestr + '.csv'\n",
    "file_final_test = 'final_test_' + datestr + '.csv'\n",
    "\n",
    "#Enable Optimization Algorithms\n",
    "enable_grid_search = False\n",
    "svm_c = 1\n",
    "svm_gamma = 1\n",
    "nfold = 10\n",
    "\n",
    "enable_lr_l1 = False\n",
    "predict_lr_l1 = False\n",
    "\n",
    "# Enable Algorithms\n",
    "enable_lr = True\n",
    "enable_dt = True\n",
    "enable_svm = True\n",
    "enable_knn = False\n",
    "enable_mlp = True\n",
    "enable_nbayes = True\n",
    "\n",
    "predict_lr = True\n",
    "predict_dt = True\n",
    "predict_svm = True\n",
    "predict_knn = False\n",
    "predict_mlp = True\n",
    "predict_nbayes = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function converts the data frame to the appropriate data type\n",
    "def convert_type(data):\n",
    "    data = data.astype('category')\n",
    "    data['C_MNTH'] = data['C_MNTH'].astype(CategoricalDtype(ordered=True))\n",
    "    data['C_WDAY'] = data['C_WDAY'].astype(CategoricalDtype(ordered=True))\n",
    "    data['C_HOUR'] = data['C_HOUR'].astype(CategoricalDtype(ordered=True))\n",
    "    data['C_VEHS'] = data['C_VEHS'].astype(CategoricalDtype(ordered=True))\n",
    "    data['P_AGE'] = data['P_AGE'].astype(CategoricalDtype(ordered=True))\n",
    "    data['P_PSN'] = data['P_PSN'].astype(CategoricalDtype(ordered=True))\n",
    "    data['P_ISEV'] = data['P_ISEV'].astype('int')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Class Classification: Enabled\n",
      "Logistic Regression: Enabled\n",
      "Decision Tree: Enabled\n",
      "Support Vector Machines: Enabled\n",
      "KNN: Disabled\n",
      "Naive Bayes: Enabled\n",
      "MLP: Enabled\n"
     ]
    }
   ],
   "source": [
    "#print(\"Sample size: {}\".format(sampleN))\n",
    "\n",
    "if multiclass:\n",
    "    print(\"Multi-Class Classification: Enabled\")\n",
    "else:\n",
    "    print(\"Multi-Class Classification: Disabled\")\n",
    "\n",
    "if enable_lr:\n",
    "    print(\"Logistic Regression: Enabled\")\n",
    "else:\n",
    "    print(\"Logistic Regression: Disabled\")\n",
    "    \n",
    "if enable_dt:\n",
    "    print(\"Decision Tree: Enabled\")\n",
    "else:\n",
    "    print(\"Decision Tree: Disabled\")\n",
    "    \n",
    "if enable_svm:\n",
    "    print(\"Support Vector Machines: Enabled\")\n",
    "else:\n",
    "    print(\"Support Vector Machines: Disabled\")\n",
    "\n",
    "if  enable_knn:\n",
    "    print(\"KNN: Enabled\")\n",
    "else:\n",
    "    print(\"KNN: Disabled\")\n",
    "    \n",
    "if enable_nbayes:\n",
    "    print(\"Naive Bayes: Enabled\")\n",
    "else:\n",
    "    print(\"Naive Bayes: Disabled\")\n",
    "    \n",
    "if enable_mlp:\n",
    "    print(\"MLP: Enabled\")\n",
    "else:\n",
    "    print(\"MLP: Disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C_MNTH  C_WDAY  C_HOUR  C_VEHS  C_CONF  C_RCFG  C_WTHR  C_RSUR  C_RALN  \\\n",
      "0       5       6       1       2      35       2       1       1       1   \n",
      "1       8       4       3       2      21       2       2       1       1   \n",
      "\n",
      "   C_TRAF  P_SEX  P_AGE  P_PSN  P_USER  P_ISEV  \n",
      "0       1      2      3      1       1       1  \n",
      "1       5      2      4      1       1       0  \n",
      "   C_MNTH  C_WDAY  C_HOUR  C_VEHS  C_CONF  C_RCFG  C_WTHR  C_RSUR  C_RALN  \\\n",
      "0       4       7       5       3      22       1       1       2       3   \n",
      "1      11       4       5       1       6       1       1       1       1   \n",
      "\n",
      "   C_TRAF  P_SEX  P_AGE  P_PSN  P_USER  P_ISEV  \n",
      "0       7      1      1      2       2       0  \n",
      "1       7      2      4      1       1       1  \n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "df_test = pd.read_csv(datafile_test, engine = 'python')\n",
    "df_train = pd.read_csv(datafile_train, engine = 'python')\n",
    "df = df_train.copy()\n",
    "\n",
    "print(df_test.head(2))\n",
    "print(df_train.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1444846 entries, 0 to 1444845\n",
      "Data columns (total 15 columns):\n",
      "C_MNTH    1444846 non-null category\n",
      "C_WDAY    1444846 non-null category\n",
      "C_HOUR    1444846 non-null category\n",
      "C_VEHS    1444846 non-null category\n",
      "C_CONF    1444846 non-null category\n",
      "C_RCFG    1444846 non-null category\n",
      "C_WTHR    1444846 non-null category\n",
      "C_RSUR    1444846 non-null category\n",
      "C_RALN    1444846 non-null category\n",
      "C_TRAF    1444846 non-null category\n",
      "P_SEX     1444846 non-null category\n",
      "P_AGE     1444846 non-null category\n",
      "P_PSN     1444846 non-null category\n",
      "P_USER    1444846 non-null category\n",
      "P_ISEV    1444846 non-null int32\n",
      "dtypes: category(14), int32(1)\n",
      "memory usage: 24.8 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5259385 entries, 0 to 5259384\n",
      "Data columns (total 15 columns):\n",
      "C_MNTH    category\n",
      "C_WDAY    category\n",
      "C_HOUR    category\n",
      "C_VEHS    category\n",
      "C_CONF    category\n",
      "C_RCFG    category\n",
      "C_WTHR    category\n",
      "C_RSUR    category\n",
      "C_RALN    category\n",
      "C_TRAF    category\n",
      "P_SEX     category\n",
      "P_AGE     category\n",
      "P_PSN     category\n",
      "P_USER    category\n",
      "P_ISEV    int32\n",
      "dtypes: category(14), int32(1)\n",
      "memory usage: 90.3 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_test_cat = convert_type(df_test)\n",
    "print(df_test_cat.info())\n",
    "df_train_cat = convert_type(df_train)\n",
    "print(df_train_cat.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows in test data: 1444846\n",
      "Number of Rows in train data: 5259385\n"
     ]
    }
   ],
   "source": [
    "total_test_Rows = df_test_cat.index.size\n",
    "print(\"Number of Rows in test data: {}\".format(total_test_Rows))\n",
    "\n",
    "total_train_Rows = df_train_cat.index.size\n",
    "print(\"Number of Rows in train data: {}\".format(total_train_Rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split between data and class for training\n",
    "Y = df_train_cat[df_train_cat.columns[-1]]\n",
    "X = df_train_cat[df_train_cat.columns[0:df_train_cat.columns.size -1]]\n",
    "\n",
    "Y_test = df_test_cat[df_test_cat.columns[-1]]\n",
    "X_test = df_test_cat[df_test_cat.columns[0:df_test_cat.columns.size -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "P_ISEV\n",
      "0    1432039\n",
      "1    1913673\n",
      "2    1913673\n",
      "Name: P_ISEV, dtype: int64\n",
      "[1 0 2]\n",
      "P_ISEV\n",
      "0    613731\n",
      "1    820145\n",
      "2     10970\n",
      "Name: P_ISEV, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Y.unique())\n",
    "print(Y.groupby(Y).size())\n",
    "print(Y_test.unique())\n",
    "print(Y_test.groupby(Y_test).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### Logistic Regression Model Evaluation with cross fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Start\n",
      "\n",
      "Model: Logistic Regression\n",
      "Sun Dec  9 15:33:34 2018\n",
      "\n",
      "Using Kfold: 10\n",
      "\n",
      "Model: Logistic Regression\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=10,\n",
      "          penalty='l2', random_state=0, solver='saga', tol=0.0001,\n",
      "          verbose=3, warm_start=False)\n",
      "\n",
      "Logistic Regression: Fit\n",
      "convergence after 14 epochs took 171 seconds\n",
      "convergence after 14 epochs took 173 seconds\n",
      "convergence after 16 epochs took 179 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 14 epochs took 173 seconds\n",
      "convergence after 14 epochs took 174 seconds\n",
      "convergence after 16 epochs took 181 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 13 epochs took 161 seconds\n",
      "convergence after 15 epochs took 171 seconds\n",
      "convergence after 16 epochs took 175 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 14 epochs took 174 seconds\n",
      "convergence after 14 epochs took 174 seconds\n",
      "convergence after 18 epochs took 187 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 14 epochs took 170 seconds\n",
      "convergence after 14 epochs took 174 seconds\n",
      "convergence after 16 epochs took 178 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 13 epochs took 159 seconds\n",
      "convergence after 14 epochs took 163 seconds\n",
      "convergence after 15 epochs took 168 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 14 epochs took 174 seconds\n",
      "convergence after 14 epochs took 175 seconds\n",
      "convergence after 15 epochs took 177 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 14 epochs took 169 seconds\n",
      "convergence after 15 epochs took 177 seconds\n",
      "convergence after 15 epochs took 178 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 14 epochs took 170 seconds\n",
      "convergence after 14 epochs took 172 seconds\n",
      "convergence after 15 epochs took 175 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 13 epochs took 161 seconds\n",
      "convergence after 14 epochs took 167 seconds\n",
      "convergence after 16 epochs took 174 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold results: [0.52025516 0.52244362 0.52082177 0.52150824 0.52055565 0.52068114\n",
      " 0.51968673 0.52066593 0.52190372 0.52083424]\n",
      "K-fold mean: 0.5209356224104622\n",
      "Sun Dec  9 16:03:50 2018\n",
      "Logistic Regression: End\n"
     ]
    }
   ],
   "source": [
    "if enable_lr:\n",
    "    print(\"Logistic Regression: Start\")\n",
    "    t_start =  time.time()\n",
    "    print()\n",
    "    print(\"Model: Logistic Regression\")\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print()\n",
    "    print(\"Using Kfold: {}\".format(nfold))\n",
    "    #kfold = model_selection.KFold(n_splits=nfold)\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=nfold, shuffle=True)  \n",
    "    \n",
    "    lr = LogisticRegression(C=1, random_state=0, solver='saga', multi_class='ovr', \n",
    "                            verbose=verbose_level, n_jobs=10, max_iter=model_max_iter)\n",
    "    print()\n",
    "    print(\"Model: Logistic Regression\")\n",
    "    print(lr)\n",
    "    print()\n",
    "    print(\"Logistic Regression: Fit\")\n",
    "    results = model_selection.cross_val_score(lr, X, Y, cv=kfold)\n",
    "    \n",
    "    print('K-fold results: {}'.format(results))\n",
    "    print('K-fold mean: {}'.format(results.mean()))\n",
    "\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"Logistic Regression: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Model Evaluation with cross fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes: Start\n",
      "\n",
      "Model: Naive Bayes\n",
      "Sun Dec  9 16:03:50 2018\n",
      "\n",
      "Using Stratified Kfold: 10\n",
      "\n",
      "Model: Naive Bayes\n",
      "GaussianNB(priors=None)\n",
      "\n",
      "Naive Bayes: Fit\n",
      "K-fold results: [0.47117732 0.46979503 0.47048903 0.47146051 0.47057258 0.47079884\n",
      " 0.47162023 0.47013336 0.47105552 0.46967793]\n",
      "K-fold mean: 0.470678035577418\n",
      "Sun Dec  9 16:04:49 2018\n",
      "Naive Bayes: End\n"
     ]
    }
   ],
   "source": [
    "if enable_nbayes:\n",
    "    print(\"Naive Bayes: Start\")\n",
    "    t_start =  time.time()\n",
    "    print()\n",
    "    print(\"Model: Naive Bayes\")\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print()\n",
    "    print(\"Using Stratified Kfold: {}\".format(nfold))\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=nfold, shuffle=True)  \n",
    "    nbayes = GaussianNB()\n",
    "    print()\n",
    "    print(\"Model: Naive Bayes\")\n",
    "    print(nbayes)\n",
    "    print()\n",
    "    print(\"Naive Bayes: Fit\")\n",
    "    results = model_selection.cross_val_score(nbayes, X, Y, cv=kfold)\n",
    "    #lr.fit(X_train, Y_train)\n",
    "    \n",
    "    print('K-fold results: {}'.format(results))\n",
    "    print('K-fold mean: {}'.format(results.mean()))\n",
    "\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"Naive Bayes: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model Evaluation with cross fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: Start\n",
      "\n",
      "Model: Decision Tree\n",
      "Sun Dec  9 16:04:49 2018\n",
      "\n",
      "Using Stratified Kfold: 10\n",
      "\n",
      "Model: Decision Tree\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=50,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "\n",
      "Decision Tree: Fit\n",
      "K-fold results: [0.72722554 0.72708864 0.72724645 0.72727964 0.7272188  0.72731577\n",
      " 0.7268062  0.72702866 0.72629664 0.72781911]\n",
      "K-fold mean: 0.7271325450334152\n",
      "Sun Dec  9 16:15:01 2018\n",
      "Decision Tree: End\n"
     ]
    }
   ],
   "source": [
    "if predict_dt:\n",
    "    print(\"Decision Tree: Start\")\n",
    "    t_start =  time.time()\n",
    "    print()\n",
    "    print(\"Model: Decision Tree\")\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print()\n",
    "    print(\"Using Stratified Kfold: {}\".format(nfold))\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=nfold, shuffle=True)  \n",
    "    tree = DecisionTreeClassifier(criterion='entropy',max_depth=50)\n",
    "    print()\n",
    "    print(\"Model: Decision Tree\")\n",
    "    print(tree)\n",
    "    print()\n",
    "    print(\"Decision Tree: Fit\")\n",
    "    results = model_selection.cross_val_score(tree, X, Y, cv=kfold)\n",
    "    #lr.fit(X_train, Y_train)\n",
    "    \n",
    "    print('K-fold results: {}'.format(results))\n",
    "    print('K-fold mean: {}'.format(results.mean()))\n",
    "\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"Decision Tree: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN - Multilayer Perceptron Model evaluation with cross fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Perceptron: Start\n",
      "\n",
      "Model: Multilayer Perceptron\n",
      "Sun Dec  9 16:15:01 2018\n",
      "\n",
      "Using Stratified Kfold: 10\n",
      "\n",
      "Model: Multilayer Perceptron\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(12, 12, 12), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=3, warm_start=False)\n",
      "\n",
      "Multilayer Perceptron: Fit\n",
      "Iteration 1, loss = 0.89839276\n",
      "Iteration 2, loss = 0.86490088\n",
      "Iteration 3, loss = 0.85889796\n",
      "Iteration 4, loss = 0.85605729\n",
      "Iteration 5, loss = 0.85340451\n",
      "Iteration 6, loss = 0.85171759\n",
      "Iteration 7, loss = 0.85072361\n",
      "Iteration 8, loss = 0.85006409\n",
      "Iteration 9, loss = 0.84904910\n",
      "Iteration 10, loss = 0.84842696\n",
      "Iteration 11, loss = 0.84779716\n",
      "Iteration 12, loss = 0.84724909\n",
      "Iteration 13, loss = 0.84679325\n",
      "Iteration 14, loss = 0.84630359\n",
      "Iteration 15, loss = 0.84576175\n",
      "Iteration 16, loss = 0.84525710\n",
      "Iteration 17, loss = 0.84458116\n",
      "Iteration 18, loss = 0.84414120\n",
      "Iteration 19, loss = 0.84389024\n",
      "Iteration 20, loss = 0.84367652\n",
      "Iteration 21, loss = 0.84306378\n",
      "Iteration 22, loss = 0.84248628\n",
      "Iteration 23, loss = 0.84203368\n",
      "Iteration 24, loss = 0.84185845\n",
      "Iteration 25, loss = 0.84165622\n",
      "Iteration 26, loss = 0.84158272\n",
      "Iteration 27, loss = 0.84138585\n",
      "Iteration 28, loss = 0.84129181\n",
      "Iteration 29, loss = 0.84110541\n",
      "Iteration 30, loss = 0.84111505\n",
      "Iteration 31, loss = 0.84095886\n",
      "Iteration 32, loss = 0.84089057\n",
      "Iteration 33, loss = 0.84076815\n",
      "Iteration 34, loss = 0.84072519\n",
      "Iteration 35, loss = 0.84062023\n",
      "Iteration 36, loss = 0.84046409\n",
      "Iteration 37, loss = 0.84032273\n",
      "Iteration 38, loss = 0.84015346\n",
      "Iteration 39, loss = 0.84000697\n",
      "Iteration 40, loss = 0.83975422\n",
      "Iteration 41, loss = 0.83959655\n",
      "Iteration 42, loss = 0.83933236\n",
      "Iteration 43, loss = 0.83912016\n",
      "Iteration 44, loss = 0.83894252\n",
      "Iteration 45, loss = 0.83875125\n",
      "Iteration 46, loss = 0.83868478\n",
      "Iteration 47, loss = 0.83841313\n",
      "Iteration 48, loss = 0.83827434\n",
      "Iteration 49, loss = 0.83801030\n",
      "Iteration 50, loss = 0.83766794\n",
      "Iteration 51, loss = 0.83750310\n",
      "Iteration 52, loss = 0.83731281\n",
      "Iteration 53, loss = 0.83729984\n",
      "Iteration 54, loss = 0.83719459\n",
      "Iteration 55, loss = 0.83710621\n",
      "Iteration 56, loss = 0.83704242\n",
      "Iteration 57, loss = 0.83693217\n",
      "Iteration 58, loss = 0.83683446\n",
      "Iteration 59, loss = 0.83678558\n",
      "Iteration 60, loss = 0.83673407\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.89668792\n",
      "Iteration 2, loss = 0.86768898\n",
      "Iteration 3, loss = 0.85836945\n",
      "Iteration 4, loss = 0.85420940\n",
      "Iteration 5, loss = 0.85251407\n",
      "Iteration 6, loss = 0.85098133\n",
      "Iteration 7, loss = 0.84931590\n",
      "Iteration 8, loss = 0.84835309\n",
      "Iteration 9, loss = 0.84753040\n",
      "Iteration 10, loss = 0.84682756\n",
      "Iteration 11, loss = 0.84634448\n",
      "Iteration 12, loss = 0.84613120\n",
      "Iteration 13, loss = 0.84586040\n",
      "Iteration 14, loss = 0.84551861\n",
      "Iteration 15, loss = 0.84521400\n",
      "Iteration 16, loss = 0.84505587\n",
      "Iteration 17, loss = 0.84478737\n",
      "Iteration 18, loss = 0.84459277\n",
      "Iteration 19, loss = 0.84450544\n",
      "Iteration 20, loss = 0.84435857\n",
      "Iteration 21, loss = 0.84418930\n",
      "Iteration 22, loss = 0.84398738\n",
      "Iteration 23, loss = 0.84383571\n",
      "Iteration 24, loss = 0.84372900\n",
      "Iteration 25, loss = 0.84358874\n",
      "Iteration 26, loss = 0.84349445\n",
      "Iteration 27, loss = 0.84338195\n",
      "Iteration 28, loss = 0.84336915\n",
      "Iteration 29, loss = 0.84315107\n",
      "Iteration 30, loss = 0.84314500\n",
      "Iteration 31, loss = 0.84306211\n",
      "Iteration 32, loss = 0.84292653\n",
      "Iteration 33, loss = 0.84288525\n",
      "Iteration 34, loss = 0.84283558\n",
      "Iteration 35, loss = 0.84285633\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.88713585\n",
      "Iteration 2, loss = 0.85976033\n",
      "Iteration 3, loss = 0.85494006\n",
      "Iteration 4, loss = 0.85147523\n",
      "Iteration 5, loss = 0.84872717\n",
      "Iteration 6, loss = 0.84721547\n",
      "Iteration 7, loss = 0.84616309\n",
      "Iteration 8, loss = 0.84536845\n",
      "Iteration 9, loss = 0.84479464\n",
      "Iteration 10, loss = 0.84412823\n",
      "Iteration 11, loss = 0.84369353\n",
      "Iteration 12, loss = 0.84330738\n",
      "Iteration 13, loss = 0.84289762\n",
      "Iteration 14, loss = 0.84255558\n",
      "Iteration 15, loss = 0.84230100\n",
      "Iteration 16, loss = 0.84197053\n",
      "Iteration 17, loss = 0.84159566\n",
      "Iteration 18, loss = 0.84117176\n",
      "Iteration 19, loss = 0.84100554\n",
      "Iteration 20, loss = 0.84080613\n",
      "Iteration 21, loss = 0.84071963\n",
      "Iteration 22, loss = 0.84060159\n",
      "Iteration 23, loss = 0.84049326\n",
      "Iteration 24, loss = 0.84051301\n",
      "Iteration 25, loss = 0.84048716\n",
      "Iteration 26, loss = 0.84035634\n",
      "Iteration 27, loss = 0.84029873\n",
      "Iteration 28, loss = 0.84033432\n",
      "Iteration 29, loss = 0.84021397\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.89163691\n",
      "Iteration 2, loss = 0.86351672\n",
      "Iteration 3, loss = 0.85669482\n",
      "Iteration 4, loss = 0.85217873\n",
      "Iteration 5, loss = 0.84980999\n",
      "Iteration 6, loss = 0.84825343\n",
      "Iteration 7, loss = 0.84639952\n",
      "Iteration 8, loss = 0.84486297\n",
      "Iteration 9, loss = 0.84377309\n",
      "Iteration 10, loss = 0.84309577\n",
      "Iteration 11, loss = 0.84279446\n",
      "Iteration 12, loss = 0.84255513\n",
      "Iteration 13, loss = 0.84228490\n",
      "Iteration 14, loss = 0.84211453\n",
      "Iteration 15, loss = 0.84191553\n",
      "Iteration 16, loss = 0.84166459\n",
      "Iteration 17, loss = 0.84152870\n",
      "Iteration 18, loss = 0.84136591\n",
      "Iteration 19, loss = 0.84128771\n",
      "Iteration 20, loss = 0.84098000\n",
      "Iteration 21, loss = 0.84071319\n",
      "Iteration 22, loss = 0.84057159\n",
      "Iteration 23, loss = 0.84038489\n",
      "Iteration 24, loss = 0.84021897\n",
      "Iteration 25, loss = 0.84005482\n",
      "Iteration 26, loss = 0.83997814\n",
      "Iteration 27, loss = 0.83984366\n",
      "Iteration 28, loss = 0.83980669\n",
      "Iteration 29, loss = 0.83958572\n",
      "Iteration 30, loss = 0.83945079\n",
      "Iteration 31, loss = 0.83938082\n",
      "Iteration 32, loss = 0.83925131\n",
      "Iteration 33, loss = 0.83914566\n",
      "Iteration 34, loss = 0.83913661\n",
      "Iteration 35, loss = 0.83902341\n",
      "Iteration 36, loss = 0.83897867\n",
      "Iteration 37, loss = 0.83897960\n",
      "Iteration 38, loss = 0.83882020\n",
      "Iteration 39, loss = 0.83889222\n",
      "Iteration 40, loss = 0.83875702\n",
      "Iteration 41, loss = 0.83880167\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.88683806\n",
      "Iteration 2, loss = 0.85895397\n",
      "Iteration 3, loss = 0.85548121\n",
      "Iteration 4, loss = 0.85329126\n",
      "Iteration 5, loss = 0.85138435\n",
      "Iteration 6, loss = 0.84965504\n",
      "Iteration 7, loss = 0.84839282\n",
      "Iteration 8, loss = 0.84745170\n",
      "Iteration 9, loss = 0.84671414\n",
      "Iteration 10, loss = 0.84619194\n",
      "Iteration 11, loss = 0.84567415\n",
      "Iteration 12, loss = 0.84523092\n",
      "Iteration 13, loss = 0.84503346\n",
      "Iteration 14, loss = 0.84465752\n",
      "Iteration 15, loss = 0.84412776\n",
      "Iteration 16, loss = 0.84374979\n",
      "Iteration 17, loss = 0.84346451\n",
      "Iteration 18, loss = 0.84324361\n",
      "Iteration 19, loss = 0.84297998\n",
      "Iteration 20, loss = 0.84289099\n",
      "Iteration 21, loss = 0.84272677\n",
      "Iteration 22, loss = 0.84260112\n",
      "Iteration 23, loss = 0.84227357\n",
      "Iteration 24, loss = 0.84213608\n",
      "Iteration 25, loss = 0.84197917\n",
      "Iteration 26, loss = 0.84187579\n",
      "Iteration 27, loss = 0.84178410\n",
      "Iteration 28, loss = 0.84162023\n",
      "Iteration 29, loss = 0.84154054\n",
      "Iteration 30, loss = 0.84149870\n",
      "Iteration 31, loss = 0.84142282\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.90775519\n",
      "Iteration 2, loss = 0.86657950\n",
      "Iteration 3, loss = 0.85653999\n",
      "Iteration 4, loss = 0.85092136\n",
      "Iteration 5, loss = 0.84798734\n",
      "Iteration 6, loss = 0.84598136\n",
      "Iteration 7, loss = 0.84432816\n",
      "Iteration 8, loss = 0.84289192\n",
      "Iteration 9, loss = 0.84155644\n",
      "Iteration 10, loss = 0.84031900\n",
      "Iteration 11, loss = 0.83942295\n",
      "Iteration 12, loss = 0.83897732\n",
      "Iteration 13, loss = 0.83852884\n",
      "Iteration 14, loss = 0.83796686\n",
      "Iteration 15, loss = 0.83731324\n",
      "Iteration 16, loss = 0.83677899\n",
      "Iteration 17, loss = 0.83631386\n",
      "Iteration 18, loss = 0.83606279\n",
      "Iteration 19, loss = 0.83540185\n",
      "Iteration 20, loss = 0.83494354\n",
      "Iteration 21, loss = 0.83466291\n",
      "Iteration 22, loss = 0.83426152\n",
      "Iteration 23, loss = 0.83376721\n",
      "Iteration 24, loss = 0.83324096\n",
      "Iteration 25, loss = 0.83278378\n",
      "Iteration 26, loss = 0.83259920\n",
      "Iteration 27, loss = 0.83247207\n",
      "Iteration 28, loss = 0.83237050\n",
      "Iteration 29, loss = 0.83223345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30, loss = 0.83212541\n",
      "Iteration 31, loss = 0.83214392\n",
      "Iteration 32, loss = 0.83190121\n",
      "Iteration 33, loss = 0.83189668\n",
      "Iteration 34, loss = 0.83164697\n",
      "Iteration 35, loss = 0.83154879\n",
      "Iteration 36, loss = 0.83149812\n",
      "Iteration 37, loss = 0.83149829\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.90038735\n",
      "Iteration 2, loss = 0.86349982\n",
      "Iteration 3, loss = 0.85634717\n",
      "Iteration 4, loss = 0.84954394\n",
      "Iteration 5, loss = 0.84603006\n",
      "Iteration 6, loss = 0.84437768\n",
      "Iteration 7, loss = 0.84343667\n",
      "Iteration 8, loss = 0.84252144\n",
      "Iteration 9, loss = 0.84175350\n",
      "Iteration 10, loss = 0.84105159\n",
      "Iteration 11, loss = 0.84057992\n",
      "Iteration 12, loss = 0.84034315\n",
      "Iteration 13, loss = 0.83996196\n",
      "Iteration 14, loss = 0.83945631\n",
      "Iteration 15, loss = 0.83920385\n",
      "Iteration 16, loss = 0.83899730\n",
      "Iteration 17, loss = 0.83891561\n",
      "Iteration 18, loss = 0.83875150\n",
      "Iteration 19, loss = 0.83867495\n",
      "Iteration 20, loss = 0.83847478\n",
      "Iteration 21, loss = 0.83832207\n",
      "Iteration 22, loss = 0.83822126\n",
      "Iteration 23, loss = 0.83808726\n",
      "Iteration 24, loss = 0.83806880\n",
      "Iteration 25, loss = 0.83795606\n",
      "Iteration 26, loss = 0.83791850\n",
      "Iteration 27, loss = 0.83782380\n",
      "Iteration 28, loss = 0.83765427\n",
      "Iteration 29, loss = 0.83747605\n",
      "Iteration 30, loss = 0.83742627\n",
      "Iteration 31, loss = 0.83735679\n",
      "Iteration 32, loss = 0.83707136\n",
      "Iteration 33, loss = 0.83691991\n",
      "Iteration 34, loss = 0.83677767\n",
      "Iteration 35, loss = 0.83678555\n",
      "Iteration 36, loss = 0.83641456\n",
      "Iteration 37, loss = 0.83635049\n",
      "Iteration 38, loss = 0.83609895\n",
      "Iteration 39, loss = 0.83598304\n",
      "Iteration 40, loss = 0.83587160\n",
      "Iteration 41, loss = 0.83576120\n",
      "Iteration 42, loss = 0.83563981\n",
      "Iteration 43, loss = 0.83546843\n",
      "Iteration 44, loss = 0.83539297\n",
      "Iteration 45, loss = 0.83385654\n",
      "Iteration 46, loss = 0.83356322\n",
      "Iteration 47, loss = 0.83336025\n",
      "Iteration 48, loss = 0.83318556\n",
      "Iteration 49, loss = 0.83323336\n",
      "Iteration 50, loss = 0.83311247\n",
      "Iteration 51, loss = 0.83310997\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.89025418\n",
      "Iteration 2, loss = 0.85722117\n",
      "Iteration 3, loss = 0.85179533\n",
      "Iteration 4, loss = 0.84903833\n",
      "Iteration 5, loss = 0.84755391\n",
      "Iteration 6, loss = 0.84612128\n",
      "Iteration 7, loss = 0.84501481\n",
      "Iteration 8, loss = 0.84422640\n",
      "Iteration 9, loss = 0.84367817\n",
      "Iteration 10, loss = 0.84340716\n",
      "Iteration 11, loss = 0.84302608\n",
      "Iteration 12, loss = 0.84265897\n",
      "Iteration 13, loss = 0.84218531\n",
      "Iteration 14, loss = 0.84182435\n",
      "Iteration 15, loss = 0.84126585\n",
      "Iteration 16, loss = 0.84098663\n",
      "Iteration 17, loss = 0.84073564\n",
      "Iteration 18, loss = 0.84048936\n",
      "Iteration 19, loss = 0.84028100\n",
      "Iteration 20, loss = 0.84015341\n",
      "Iteration 21, loss = 0.83998327\n",
      "Iteration 22, loss = 0.83964904\n",
      "Iteration 23, loss = 0.83942723\n",
      "Iteration 24, loss = 0.83924413\n",
      "Iteration 25, loss = 0.83890665\n",
      "Iteration 26, loss = 0.83868391\n",
      "Iteration 27, loss = 0.83836679\n",
      "Iteration 28, loss = 0.83799745\n",
      "Iteration 29, loss = 0.83774070\n",
      "Iteration 30, loss = 0.83761229\n",
      "Iteration 31, loss = 0.83750255\n",
      "Iteration 32, loss = 0.83736197\n",
      "Iteration 33, loss = 0.83723851\n",
      "Iteration 34, loss = 0.83716046\n",
      "Iteration 35, loss = 0.83708399\n",
      "Iteration 36, loss = 0.83701935\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.89570385\n",
      "Iteration 2, loss = 0.85990347\n",
      "Iteration 3, loss = 0.85324994\n",
      "Iteration 4, loss = 0.84909310\n",
      "Iteration 5, loss = 0.84725064\n",
      "Iteration 6, loss = 0.84626612\n",
      "Iteration 7, loss = 0.84526315\n",
      "Iteration 8, loss = 0.84438150\n",
      "Iteration 9, loss = 0.84364858\n",
      "Iteration 10, loss = 0.84287648\n",
      "Iteration 11, loss = 0.84228988\n",
      "Iteration 12, loss = 0.84178278\n",
      "Iteration 13, loss = 0.84157247\n",
      "Iteration 14, loss = 0.84136615\n",
      "Iteration 15, loss = 0.84106274\n",
      "Iteration 16, loss = 0.84092061\n",
      "Iteration 17, loss = 0.84058804\n",
      "Iteration 18, loss = 0.84024688\n",
      "Iteration 19, loss = 0.84003952\n",
      "Iteration 20, loss = 0.83982249\n",
      "Iteration 21, loss = 0.83961317\n",
      "Iteration 22, loss = 0.83960473\n",
      "Iteration 23, loss = 0.83945661\n",
      "Iteration 24, loss = 0.83940556\n",
      "Iteration 25, loss = 0.83922960\n",
      "Iteration 26, loss = 0.83920528\n",
      "Iteration 27, loss = 0.83913362\n",
      "Iteration 28, loss = 0.83907004\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.89457800\n",
      "Iteration 2, loss = 0.85930737\n",
      "Iteration 3, loss = 0.85096467\n",
      "Iteration 4, loss = 0.84732762\n",
      "Iteration 5, loss = 0.84421748\n",
      "Iteration 6, loss = 0.84178436\n",
      "Iteration 7, loss = 0.83953771\n",
      "Iteration 8, loss = 0.83990610\n",
      "Iteration 9, loss = 0.83885192\n",
      "Iteration 10, loss = 0.83909018\n",
      "Iteration 11, loss = 0.83968822\n",
      "Iteration 12, loss = 0.83857068\n",
      "Iteration 13, loss = 0.83747888\n",
      "Iteration 14, loss = 0.83767825\n",
      "Iteration 15, loss = 0.83837830\n",
      "Iteration 16, loss = 0.83762310\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "K-fold results: [0.59091531 0.58798342 0.59140967 0.58563557 0.59062665 0.59742213\n",
      " 0.59509676 0.5937525  0.59058862 0.59267555]\n",
      "K-fold mean: 0.5916106179927574\n",
      "Sun Dec  9 18:15:05 2018\n",
      "Multilayer Perceptron: End\n"
     ]
    }
   ],
   "source": [
    "if predict_mlp:\n",
    "    print(\"Multilayer Perceptron: Start\")\n",
    "    t_start =  time.time()\n",
    "    print()\n",
    "    print(\"Model: Multilayer Perceptron\")\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print()\n",
    "    print(\"Using Stratified Kfold: {}\".format(nfold))\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=nfold, shuffle=True)  \n",
    "    mlpc = MLPClassifier(hidden_layer_sizes=(12, 12, 12), verbose=verbose_level, max_iter=model_max_iter)\n",
    "    print()\n",
    "    print(\"Model: Multilayer Perceptron\")\n",
    "    print(mlpc)\n",
    "    print()\n",
    "    print(\"Multilayer Perceptron: Fit\")\n",
    "    results = model_selection.cross_val_score(mlpc, X, Y, cv=kfold)\n",
    "    #lr.fit(X_train, Y_train)\n",
    "    \n",
    "    print('K-fold results: {}'.format(results))\n",
    "    print('K-fold mean: {}'.format(results.mean()))\n",
    "\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"Multilayer Perceptron: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model Evaluation with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: Start\n",
      "\n",
      "Model: SVM\n",
      "Sun Dec  9 18:15:05 2018\n",
      "\n",
      "Using Stratified Kfold: 10\n",
      "\n",
      "Model: SVM\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=100, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=3)\n",
      "\n",
      "SVM: Fit\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold results: [0.27603529 0.27223448 0.27247785 0.2734695  0.27369956 0.27265571\n",
      " 0.27377181 0.27370717 0.27470348 0.27271898]\n",
      "K-fold mean: 0.2735473822434865\n",
      "Sun Dec  9 18:28:12 2018\n",
      "SVM: End\n"
     ]
    }
   ],
   "source": [
    "if predict_svm:\n",
    "    print(\"SVM: Start\")\n",
    "    t_start =  time.time()\n",
    "    print()\n",
    "    print(\"Model: SVM\")\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print()\n",
    "    print(\"Using Stratified Kfold: {}\".format(nfold))\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=nfold, shuffle=True)  \n",
    "    svm = SVC(C=1, gamma = 'auto', verbose = verbose_level, max_iter=model_max_iter)\n",
    "    print()\n",
    "    print(\"Model: SVM\")\n",
    "    print(svm)\n",
    "    print()\n",
    "    print(\"SVM: Fit\")\n",
    "    results = model_selection.cross_val_score(svm, X, Y, cv=kfold)\n",
    "    #lr.fit(X_train, Y_train)\n",
    "    \n",
    "    print('K-fold results: {}'.format(results))\n",
    "    print('K-fold mean: {}'.format(results.mean()))\n",
    "\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"SVM: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-N-N Model Evaluation with cross fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: End\n"
     ]
    }
   ],
   "source": [
    "if predict_knn:\n",
    "    print(\"KNN: Start\")\n",
    "    t_start =  time.time()\n",
    "    print()\n",
    "    print(\"Model: KNN\")\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print()\n",
    "    print(\"Using Stratified Kfold: {}\".format(nfold))\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=nfold, shuffle=True)  \n",
    "    knn = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski', n_jobs = -1)\n",
    "    print()\n",
    "    print(\"Model: KNN\")\n",
    "    print(knn)\n",
    "    print()\n",
    "    print(\"KNN: Fit\")\n",
    "    results = model_selection.cross_val_score(knn, X, Y, cv=kfold)\n",
    "    #lr.fit(X_train, Y_train)\n",
    "    \n",
    "    print('K-fold results: {}'.format(results))\n",
    "    print('K-fold mean: {}'.format(results.mean()))\n",
    "\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"KNN: End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extra code and play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (False):    \n",
    "    seed = 101\n",
    "    print(\"Logistic Regression: Start\")\n",
    "    t_start =  time.time()\n",
    "    print()\n",
    "    print(\"Model: Logistic Regression\")\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print()\n",
    "    print(\"Using Kfold: {}\".format(nfold))\n",
    "    #kfold = model_selection.StratifiedKFold(n_splits=nfold, shuffle=True, random_state=seed)\n",
    "    kfold = model_selection.KFold(n_splits=nfold, random_state=seed)\n",
    "    \n",
    "    models = []\n",
    "    model_scores_train = []\n",
    "    model_scores_val = []\n",
    "    \n",
    "    X_kfold = np.array(X)\n",
    "    Y_kfold = np.array(Y)\n",
    "    \n",
    "    i = 0\n",
    "    for train_index, val_index in kfold.split(X_kfold):\n",
    "        i = i+1\n",
    "        print(\"Fold: {}\".format(i))\n",
    "        \n",
    "        X_train, X_val = X_kfold[train_index], X_kfold[val_index]\n",
    "        y_train, y_val = Y_kfold[train_index], Y_kfold[val_index]\n",
    "        \n",
    "        lr = LogisticRegression(C=1, random_state=0, solver='saga', multi_class='ovr', \n",
    "                            verbose=verbose_level, n_jobs=10, max_iter=model_max_iter)\n",
    "        print()\n",
    "        print(\"Model: Logistic Regression\")\n",
    "        print(lr)\n",
    "        print()\n",
    "        print(\"Logistic Regression: Fit\")\n",
    "        lr.fit(X_train, y_train)\n",
    "\n",
    "        #add model for list\n",
    "        models.append(lr)\n",
    "\n",
    "        print(\"Logistic Regression: Predict\")\n",
    "        y_pred = lr.predict(X_val)\n",
    "\n",
    "        mst = lr.score(X_train, y_train)\n",
    "        model_scores_train.append(mst)\n",
    "        \n",
    "        msv = lr.score(X_val, y_val)\n",
    "        model_scores_val.append(msv)\n",
    "        \n",
    "        print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(mst))\n",
    "        print('Accuracy of logistic regression classifier on validation set: {:.2f}'.format(msv))\n",
    "\n",
    "        # print the intercept (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "        print(\"Logistic Regression: Intercept\")\n",
    "        print(lr.intercept_)\n",
    "\n",
    "        # print the coeficients (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "        print(\"Logistic Regression: Coefficients\")\n",
    "        print(lr.coef_)\n",
    "\n",
    "        print(\"Logistic Regression: Confusion Matrix\")\n",
    "        cnf_matrix_lg = confusion_matrix(y_val, y_pred)\n",
    "        print(cnf_matrix_lg)\n",
    "    \n",
    "        print(\"Logistic Regression: Classification Report\")\n",
    "        print(classification_report(y_val, y_pred))\n",
    "\n",
    "    print('AVG Accuracy of logistic regression classifier on train set: {:.2f}'.format(np.mean(model_scores_train)))\n",
    "    print('AVG Accuracy of logistic regression classifier on validation set: {:.2f}'.format(np.mean(model_scores_val)))\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "    # save model to file\n",
    "    pickle.dump(models, open(file_lr, \"wb\"))\n",
    "    print(\"Logistic Regression: End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (False):    \n",
    "    seed = 101\n",
    "    print(\"Logistic Regression: Start\")\n",
    "    t_start =  time.time()\n",
    "    print()\n",
    "    print(\"Model: Logistic Regression\")\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print()\n",
    "    print(\"Using Stratified Kfold: {}\".format(nfold))\n",
    "    \n",
    "    models = []\n",
    "    model_scores_train = []\n",
    "    model_scores_val = []\n",
    "    \n",
    "    X_kfold = np.array(X)\n",
    "    Y_kfold = np.array(Y)\n",
    "    \n",
    "    skf = model_selection.StratifiedKFold(n_splits=nfold, shuffle=True, random_state=seed)    \n",
    "    i = 0\n",
    "    for train_index, val_index in skf.split(X_kfold, Y_kfold):\n",
    "        i = i+1\n",
    "        print(\"Fold: {}\".format(i))\n",
    "        \n",
    "        X_train, X_val = X_kfold[train_index], X_kfold[val_index]\n",
    "        y_train, y_val = Y_kfold[train_index], Y_kfold[val_index]\n",
    "        \n",
    "        lr = LogisticRegression(C=1, random_state=0, solver='saga', multi_class='ovr', \n",
    "                            verbose=verbose_level, n_jobs=10, max_iter=model_max_iter)\n",
    "        print()\n",
    "        print(\"Model: Logistic Regression\")\n",
    "        print(lr)\n",
    "        print()\n",
    "        print(\"Logistic Regression: Fit\")\n",
    "        lr.fit(X_train, y_train)\n",
    "\n",
    "        #add model for list\n",
    "        models.append(lr)\n",
    "\n",
    "        print(\"Logistic Regression: Predict\")\n",
    "        y_pred = lr.predict(X_val)\n",
    "\n",
    "        mst = lr.score(X_train, y_train)\n",
    "        model_scores_train.append(mst)\n",
    "        \n",
    "        msv = lr.score(X_val, y_val)\n",
    "        model_scores_val.append(msv)\n",
    "        \n",
    "        print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(mst))\n",
    "        print('Accuracy of logistic regression classifier on validation set: {:.2f}'.format(msv))\n",
    "\n",
    "        # print the intercept (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "        print(\"Logistic Regression: Intercept\")\n",
    "        print(lr.intercept_)\n",
    "\n",
    "        # print the coeficients (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "        print(\"Logistic Regression: Coefficients\")\n",
    "        print(lr.coef_)\n",
    "\n",
    "        print(\"Logistic Regression: Confusion Matrix\")\n",
    "        cnf_matrix_lg = confusion_matrix(y_val, y_pred)\n",
    "        print(cnf_matrix_lg)\n",
    "    \n",
    "        print(\"Logistic Regression: Classification Report\")\n",
    "        print(classification_report(y_val, y_pred))\n",
    "\n",
    "    print('AVG Accuracy of logistic regression classifier on train set: {:.2f}'.format(np.mean(model_scores_train)))\n",
    "    print('AVG Accuracy of logistic regression classifier on validation set: {:.2f}'.format(np.mean(model_scores_val)))\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "    # save model to file\n",
    "    pickle.dump(models, open(file_lr, \"wb\"))\n",
    "    print(\"Logistic Regression: End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-54-c5448911bff4>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-54-c5448911bff4>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    if (False)\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "if (False)\n",
    "    ## for each model generated, lets predict the on test set\n",
    "    ## note, this is the first time any of these observations are seen by the model\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_lr, \"rb\"))\n",
    "    print(\"Logistic Regression: Predict on test set\")\n",
    "\n",
    "    i = 0\n",
    "    for model in loaded_model:\n",
    "        i = i + 1\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(model.score(X_test, Y_test)))\n",
    "\n",
    "        # print the intercept (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "        print(\"Logistic Regression: Intercept\")\n",
    "        print(model.intercept_)\n",
    "\n",
    "        # print the coeficients (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "        print(\"Logistic Regression: Coefficients\")\n",
    "        print(model.coef_)\n",
    "\n",
    "        print(\"Logistic Regression: Confusion Matrix\")\n",
    "        cnf_matrix_lg = confusion_matrix(Y_test, y_pred)\n",
    "        print(cnf_matrix_lg)\n",
    "    \n",
    "        print(\"Logistic Regression: Classification Report\")\n",
    "        print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
