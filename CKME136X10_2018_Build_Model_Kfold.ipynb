{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#in case we need to repeat experiment\n",
    "#np.random.seed(255)\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 22\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('classic')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "#sklearn imports\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pickle # allows for model to be saved/load to file\n",
    "import time\n",
    "\n",
    "#Use print instead of display when run as python script\n",
    "pyscript = True\n",
    "\n",
    "#Classifier verborsity where supported\n",
    "verbose_level=3\n",
    "\n",
    "#Multiclass classification, binary if falase\n",
    "multiclass = True\n",
    "over_sample = True\n",
    "\n",
    "#inputfile = 'CKME136X10_2018_Data_CTF.csv'\n",
    "if multiclass:\n",
    "    inputfile_train_O = 'CKME136X10_2018_Data_CTFB_M_O_Train.csv'\n",
    "    inputfile_train_U = 'CKME136X10_2018_Data_CTFB_M_U_Train.csv'\n",
    "    inputfile_test = 'CKME136X10_2018_Data_CTFB_M_Test.csv'\n",
    "else:\n",
    "    inputfile_train_O = 'CKME136X10_2018_Data_CTFB_B_O_Train.csv'\n",
    "    inputfile_train_U = 'CKME136X10_2018_Data_CTFB_B_U_Train.csv'\n",
    "    inputfile_test = 'CKME136X10_2018_Data_CTFB_B_Test.csv'\n",
    "\n",
    "if over_sample:\n",
    "    datafile_train = inputfile_train_O\n",
    "else:\n",
    "    datafile_train = inputfile_train_U\n",
    "\n",
    "datafile_test = inputfile_test\n",
    "    \n",
    "model_max_iter = 100\n",
    "datestr = 'dec_09_binary_run_1000_KBO'\n",
    "\n",
    "#Model Store\n",
    "file_lr = 'lr_' + datestr + '.model'\n",
    "file_lr_l1 = 'lr_l2_' + datestr + '.model'\n",
    "file_dt = 'dt_' + datestr + '.model'\n",
    "file_svm = 'svm_' + datestr + '.model'\n",
    "file_knn = 'knn_' + datestr + '.model'\n",
    "file_mlp = 'mlp_' + datestr + '.model'\n",
    "file_kmean = 'kmean_' + datestr + '.model'\n",
    "file_nbayes = 'nbayes_' + datestr + '.model'\n",
    "\n",
    "file_final_train = 'final_train_' + datestr + '.csv'\n",
    "file_final_test = 'final_test_' + datestr + '.csv'\n",
    "\n",
    "#Enable Optimization Algorithms\n",
    "enable_grid_search = False\n",
    "svm_c = 1\n",
    "svm_gamma = 1\n",
    "nfold = 3\n",
    "\n",
    "enable_lr_l1 = False\n",
    "predict_lr_l1 = False\n",
    "\n",
    "# Enable Algorithms\n",
    "enable_lr = True\n",
    "enable_dt = True\n",
    "enable_svm = True\n",
    "enable_knn = False\n",
    "enable_mlp = True\n",
    "enable_nbayes = True\n",
    "\n",
    "predict_lr = True\n",
    "predict_dt = True\n",
    "predict_svm = True\n",
    "predict_knn = False\n",
    "predict_mlp = True\n",
    "predict_nbayes = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function converts the data frame to the appropriate data type\n",
    "def convert_type(data):\n",
    "    data = data.astype('category')\n",
    "    data['C_MNTH'] = data['C_MNTH'].astype(CategoricalDtype(ordered=True))\n",
    "    data['C_WDAY'] = data['C_WDAY'].astype(CategoricalDtype(ordered=True))\n",
    "    data['C_HOUR'] = data['C_HOUR'].astype(CategoricalDtype(ordered=True))\n",
    "    data['C_VEHS'] = data['C_VEHS'].astype(CategoricalDtype(ordered=True))\n",
    "    data['P_AGE'] = data['P_AGE'].astype(CategoricalDtype(ordered=True))\n",
    "    data['P_PSN'] = data['P_PSN'].astype(CategoricalDtype(ordered=True))\n",
    "    data['P_ISEV'] = data['P_ISEV'].astype('int')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Class Classification: Enabled\n",
      "Logistic Regression: Enabled\n",
      "Decision Tree: Enabled\n",
      "Support Vector Machines: Enabled\n",
      "KNN: Disabled\n",
      "Naive Bayes: Enabled\n",
      "MLP: Enabled\n"
     ]
    }
   ],
   "source": [
    "#print(\"Sample size: {}\".format(sampleN))\n",
    "\n",
    "if multiclass:\n",
    "    print(\"Multi-Class Classification: Enabled\")\n",
    "else:\n",
    "    print(\"Multi-Class Classification: Disabled\")\n",
    "\n",
    "if enable_lr:\n",
    "    print(\"Logistic Regression: Enabled\")\n",
    "else:\n",
    "    print(\"Logistic Regression: Disabled\")\n",
    "    \n",
    "if enable_dt:\n",
    "    print(\"Decision Tree: Enabled\")\n",
    "else:\n",
    "    print(\"Decision Tree: Disabled\")\n",
    "    \n",
    "if enable_svm:\n",
    "    print(\"Support Vector Machines: Enabled\")\n",
    "else:\n",
    "    print(\"Support Vector Machines: Disabled\")\n",
    "\n",
    "if  enable_knn:\n",
    "    print(\"KNN: Enabled\")\n",
    "else:\n",
    "    print(\"KNN: Disabled\")\n",
    "    \n",
    "if enable_nbayes:\n",
    "    print(\"Naive Bayes: Enabled\")\n",
    "else:\n",
    "    print(\"Naive Bayes: Disabled\")\n",
    "    \n",
    "if enable_mlp:\n",
    "    print(\"MLP: Enabled\")\n",
    "else:\n",
    "    print(\"MLP: Disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C_MNTH  C_WDAY  C_HOUR  C_VEHS  C_CONF  C_RCFG  C_WTHR  C_RSUR  C_RALN  \\\n",
      "0       5       6       1       2      35       2       1       1       1   \n",
      "1       8       4       3       2      21       2       2       1       1   \n",
      "\n",
      "   C_TRAF  P_SEX  P_AGE  P_PSN  P_USER  P_ISEV  \n",
      "0       1      2      3      1       1       1  \n",
      "1       5      2      4      1       1       0  \n",
      "   C_MNTH  C_WDAY  C_HOUR  C_VEHS  C_CONF  C_RCFG  C_WTHR  C_RSUR  C_RALN  \\\n",
      "0       4       7       5       3      22       1       1       2       3   \n",
      "1      11       4       5       1       6       1       1       1       1   \n",
      "\n",
      "   C_TRAF  P_SEX  P_AGE  P_PSN  P_USER  P_ISEV  \n",
      "0       7      1      1      2       2       0  \n",
      "1       7      2      4      1       1       1  \n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "df_test = pd.read_csv(datafile_test, engine = 'python')\n",
    "df_train = pd.read_csv(datafile_train, engine = 'python')\n",
    "df = df_train.copy()\n",
    "\n",
    "print(df_test.head(2))\n",
    "print(df_train.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1444846 entries, 0 to 1444845\n",
      "Data columns (total 15 columns):\n",
      "C_MNTH    1444846 non-null category\n",
      "C_WDAY    1444846 non-null category\n",
      "C_HOUR    1444846 non-null category\n",
      "C_VEHS    1444846 non-null category\n",
      "C_CONF    1444846 non-null category\n",
      "C_RCFG    1444846 non-null category\n",
      "C_WTHR    1444846 non-null category\n",
      "C_RSUR    1444846 non-null category\n",
      "C_RALN    1444846 non-null category\n",
      "C_TRAF    1444846 non-null category\n",
      "P_SEX     1444846 non-null category\n",
      "P_AGE     1444846 non-null category\n",
      "P_PSN     1444846 non-null category\n",
      "P_USER    1444846 non-null category\n",
      "P_ISEV    1444846 non-null int32\n",
      "dtypes: category(14), int32(1)\n",
      "memory usage: 24.8 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5259385 entries, 0 to 5259384\n",
      "Data columns (total 15 columns):\n",
      "C_MNTH    category\n",
      "C_WDAY    category\n",
      "C_HOUR    category\n",
      "C_VEHS    category\n",
      "C_CONF    category\n",
      "C_RCFG    category\n",
      "C_WTHR    category\n",
      "C_RSUR    category\n",
      "C_RALN    category\n",
      "C_TRAF    category\n",
      "P_SEX     category\n",
      "P_AGE     category\n",
      "P_PSN     category\n",
      "P_USER    category\n",
      "P_ISEV    int32\n",
      "dtypes: category(14), int32(1)\n",
      "memory usage: 90.3 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_test_cat = convert_type(df_test)\n",
    "print(df_test_cat.info())\n",
    "df_train_cat = convert_type(df_train)\n",
    "print(df_train_cat.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows in test data: 1444846\n",
      "Number of Rows in train data: 5259385\n"
     ]
    }
   ],
   "source": [
    "total_test_Rows = df_test_cat.index.size\n",
    "print(\"Number of Rows in test data: {}\".format(total_test_Rows))\n",
    "\n",
    "total_train_Rows = df_train_cat.index.size\n",
    "print(\"Number of Rows in train data: {}\".format(total_train_Rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split between data and class for training\n",
    "Y = df_train_cat[df_train_cat.columns[-1]]\n",
    "X = df_train_cat[df_train_cat.columns[0:df_train_cat.columns.size -1]]\n",
    "\n",
    "Y_test = df_test_cat[df_test_cat.columns[-1]]\n",
    "X_test = df_test_cat[df_test_cat.columns[0:df_test_cat.columns.size -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "P_ISEV\n",
      "0    1432039\n",
      "1    1913673\n",
      "2    1913673\n",
      "Name: P_ISEV, dtype: int64\n",
      "[1 0 2]\n",
      "P_ISEV\n",
      "0    613731\n",
      "1    820145\n",
      "2     10970\n",
      "Name: P_ISEV, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Y.unique())\n",
    "print(Y.groupby(Y).size())\n",
    "print(Y_test.unique())\n",
    "print(Y_test.groupby(Y_test).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### Logistic Regression Model Evaluation with cross fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Start\n",
      "\n",
      "Model: Logistic Regression\n",
      "Sun Dec  9 13:01:57 2018\n",
      "\n",
      "Using Kfold: 3\n",
      "\n",
      "Model: Logistic Regression\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=10,\n",
      "          penalty='l2', random_state=0, solver='saga', tol=0.0001,\n",
      "          verbose=3, warm_start=False)\n",
      "\n",
      "Logistic Regression: Fit\n",
      "convergence after 14 epochs took 126 seconds\n",
      "convergence after 14 epochs took 127 seconds\n",
      "convergence after 16 epochs took 133 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 13 epochs took 116 seconds\n",
      "convergence after 14 epochs took 120 seconds\n",
      "convergence after 17 epochs took 130 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 13 epochs took 115 seconds\n",
      "convergence after 14 epochs took 120 seconds\n",
      "convergence after 17 epochs took 129 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kfold results: [0.52050305 0.52072524 0.52156146]\n",
      "Kfold mean\" 0.5209299186933195\n",
      "Sun Dec  9 13:08:43 2018\n",
      "Logistic Regression: End\n"
     ]
    }
   ],
   "source": [
    "if enable_lr:\n",
    "    print(\"Logistic Regression: Start\")\n",
    "    t_start =  time.time()\n",
    "    print()\n",
    "    print(\"Model: Logistic Regression\")\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print()\n",
    "    print(\"Using Kfold: {}\".format(nfold))\n",
    "    #kfold = model_selection.KFold(n_splits=nfold)\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=nfold, shuffle=True)  \n",
    "    \n",
    "    lr = LogisticRegression(C=1, random_state=0, solver='saga', multi_class='ovr', \n",
    "                            verbose=verbose_level, n_jobs=10, max_iter=model_max_iter)\n",
    "    print()\n",
    "    print(\"Model: Logistic Regression\")\n",
    "    print(lr)\n",
    "    print()\n",
    "    print(\"Logistic Regression: Fit\")\n",
    "    results = model_selection.cross_val_score(lr, X, Y, cv=kfold)\n",
    "    \n",
    "    print('K-fold results: {}'.format(results))\n",
    "    print('K-fold mean: {}'.format(results.mean()))\n",
    "\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"Logistic Regression: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Model Evaluation with cross fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes: Start\n",
      "\n",
      "Model: Naive Bayes\n",
      "Sun Dec  9 13:08:43 2018\n",
      "\n",
      "Using Stratified Kfold: 3\n",
      "\n",
      "Model: Naive Bayes\n",
      "GaussianNB(priors=None)\n",
      "\n",
      "Naive Bayes: Fit\n",
      "Kfold results: [0.47143992 0.47037524 0.47009289]\n",
      "Kfold mean\" 0.4706360152748073\n",
      "Sun Dec  9 13:09:05 2018\n",
      "Naive Bayes: End\n"
     ]
    }
   ],
   "source": [
    "if enable_nbayes:\n",
    "    print(\"Naive Bayes: Start\")\n",
    "    t_start =  time.time()\n",
    "    print()\n",
    "    print(\"Model: Naive Bayes\")\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print()\n",
    "    print(\"Using Stratified Kfold: {}\".format(nfold))\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=nfold, shuffle=True)  \n",
    "    nbayes = GaussianNB()\n",
    "    print()\n",
    "    print(\"Model: Naive Bayes\")\n",
    "    print(nbayes)\n",
    "    print()\n",
    "    print(\"Naive Bayes: Fit\")\n",
    "    results = model_selection.cross_val_score(nbayes, X, Y, cv=kfold)\n",
    "    #lr.fit(X_train, Y_train)\n",
    "    \n",
    "    print('K-fold results: {}'.format(results))\n",
    "    print('K-fold mean: {}'.format(results.mean()))\n",
    "\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"Naive Bayes: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model Evaluation with cross fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: Start\n",
      "\n",
      "Model: Decision Tree\n",
      "Sun Dec  9 13:09:05 2018\n",
      "\n",
      "Using Stratified Kfold: 3\n",
      "\n",
      "Model: Decision Tree\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=50,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "\n",
      "Decision Tree: Fit\n",
      "Kfold results: [0.72277625 0.72243841 0.72235285]\n",
      "Kfold mean\" 0.7225225002060608\n",
      "Sun Dec  9 13:11:36 2018\n",
      "Decision Tree: End\n"
     ]
    }
   ],
   "source": [
    "if predict_dt:\n",
    "    print(\"Decision Tree: Start\")\n",
    "    t_start =  time.time()\n",
    "    print()\n",
    "    print(\"Model: Decision Tree\")\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print()\n",
    "    print(\"Using Stratified Kfold: {}\".format(nfold))\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=nfold, shuffle=True)  \n",
    "    tree = DecisionTreeClassifier(criterion='entropy',max_depth=50)\n",
    "    print()\n",
    "    print(\"Model: Decision Tree\")\n",
    "    print(tree)\n",
    "    print()\n",
    "    print(\"Decision Tree: Fit\")\n",
    "    results = model_selection.cross_val_score(tree, X, Y, cv=kfold)\n",
    "    #lr.fit(X_train, Y_train)\n",
    "    \n",
    "    print('K-fold results: {}'.format(results))\n",
    "    print('K-fold mean: {}'.format(results.mean()))\n",
    "\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"Decision Tree: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN - Multilayer Perceptron Model evaluation with cross fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Perceptron: Start\n",
      "\n",
      "Model: Multilayer Perceptron\n",
      "Sun Dec  9 13:11:36 2018\n",
      "\n",
      "Using Stratified Kfold: 3\n",
      "\n",
      "Model: Multilayer Perceptron\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(25, 25, 25), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=3, warm_start=False)\n",
      "\n",
      "Multilayer Perceptron: Fit\n",
      "Iteration 1, loss = 0.87278497\n",
      "Iteration 2, loss = 0.84244793\n",
      "Iteration 3, loss = 0.83554912\n",
      "Iteration 4, loss = 0.83137791\n",
      "Iteration 5, loss = 0.82822735\n",
      "Iteration 6, loss = 0.82610023\n",
      "Iteration 7, loss = 0.82469926\n",
      "Iteration 8, loss = 0.82332219\n",
      "Iteration 9, loss = 0.82247130\n",
      "Iteration 10, loss = 0.82150653\n",
      "Iteration 11, loss = 0.82077550\n",
      "Iteration 12, loss = 0.82012991\n",
      "Iteration 13, loss = 0.81953171\n",
      "Iteration 14, loss = 0.81900657\n",
      "Iteration 15, loss = 0.81863481\n",
      "Iteration 16, loss = 0.81830316\n",
      "Iteration 17, loss = 0.81790191\n",
      "Iteration 18, loss = 0.81755014\n",
      "Iteration 19, loss = 0.81742361\n",
      "Iteration 20, loss = 0.81709637\n",
      "Iteration 21, loss = 0.81693009\n",
      "Iteration 22, loss = 0.81659921\n",
      "Iteration 23, loss = 0.81655121\n",
      "Iteration 24, loss = 0.81632826\n",
      "Iteration 25, loss = 0.81615866\n",
      "Iteration 26, loss = 0.81589906\n",
      "Iteration 27, loss = 0.81567452\n",
      "Iteration 28, loss = 0.81562396\n",
      "Iteration 29, loss = 0.81543365\n",
      "Iteration 30, loss = 0.81539501\n",
      "Iteration 31, loss = 0.81528818\n",
      "Iteration 32, loss = 0.81523226\n",
      "Iteration 33, loss = 0.81509969\n",
      "Iteration 34, loss = 0.81508546\n",
      "Iteration 35, loss = 0.81493296\n",
      "Iteration 36, loss = 0.81476137\n",
      "Iteration 37, loss = 0.81467223\n",
      "Iteration 38, loss = 0.81453282\n",
      "Iteration 39, loss = 0.81443781\n",
      "Iteration 40, loss = 0.81437312\n",
      "Iteration 41, loss = 0.81435019\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.87310640\n",
      "Iteration 2, loss = 0.84057818\n",
      "Iteration 3, loss = 0.83410236\n",
      "Iteration 4, loss = 0.83020210\n",
      "Iteration 5, loss = 0.82724625\n",
      "Iteration 6, loss = 0.82533088\n",
      "Iteration 7, loss = 0.82385619\n"
     ]
    }
   ],
   "source": [
    "if predict_mlp:\n",
    "    print(\"Multilayer Perceptron: Start\")\n",
    "    t_start =  time.time()\n",
    "    print()\n",
    "    print(\"Model: Multilayer Perceptron\")\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print()\n",
    "    print(\"Using Stratified Kfold: {}\".format(nfold))\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=nfold, shuffle=True)  \n",
    "    mlpc = MLPClassifier(hidden_layer_sizes=(25, 25, 25), verbose=verbose_level, max_iter=model_max_iter)\n",
    "    print()\n",
    "    print(\"Model: Multilayer Perceptron\")\n",
    "    print(mlpc)\n",
    "    print()\n",
    "    print(\"Multilayer Perceptron: Fit\")\n",
    "    results = model_selection.cross_val_score(mlpc, X, Y, cv=kfold)\n",
    "    #lr.fit(X_train, Y_train)\n",
    "    \n",
    "    print('K-fold results: {}'.format(results))\n",
    "    print('K-fold mean: {}'.format(results.mean()))\n",
    "\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"Multilayer Perceptron: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model Evaluation with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if predict_svm:\n",
    "    print(\"SVM: Start\")\n",
    "    t_start =  time.time()\n",
    "    print()\n",
    "    print(\"Model: SVM\")\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print()\n",
    "    print(\"Using Stratified Kfold: {}\".format(nfold))\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=nfold, shuffle=True)  \n",
    "    svm = SVC(C=1, gamma = 'auto', verbose = verbose_level, max_iter=model_max_iter)\n",
    "    print()\n",
    "    print(\"Model: SVM\")\n",
    "    print(svm)\n",
    "    print()\n",
    "    print(\"SVM: Fit\")\n",
    "    results = model_selection.cross_val_score(svm, X, Y, cv=kfold)\n",
    "    #lr.fit(X_train, Y_train)\n",
    "    \n",
    "    print('K-fold results: {}'.format(results))\n",
    "    print('K-fold mean: {}'.format(results.mean()))\n",
    "\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"SVM: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-N-N Model Evaluation with cross fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if predict_knn:\n",
    "    print(\"KNN: Start\")\n",
    "    t_start =  time.time()\n",
    "    print()\n",
    "    print(\"Model: KNN\")\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print()\n",
    "    print(\"Using Stratified Kfold: {}\".format(nfold))\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=nfold, shuffle=True)  \n",
    "    knn = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski', n_jobs = -1)\n",
    "    print()\n",
    "    print(\"Model: KNN\")\n",
    "    print(knn)\n",
    "    print()\n",
    "    print(\"KNN: Fit\")\n",
    "    results = model_selection.cross_val_score(knn, X, Y, cv=kfold)\n",
    "    #lr.fit(X_train, Y_train)\n",
    "    \n",
    "    print('K-fold results: {}'.format(results))\n",
    "    print('K-fold mean: {}'.format(results.mean()))\n",
    "\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"KNN: End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extra code and play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (False):    \n",
    "    seed = 101\n",
    "    print(\"Logistic Regression: Start\")\n",
    "    t_start =  time.time()\n",
    "    print()\n",
    "    print(\"Model: Logistic Regression\")\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print()\n",
    "    print(\"Using Kfold: {}\".format(nfold))\n",
    "    #kfold = model_selection.StratifiedKFold(n_splits=nfold, shuffle=True, random_state=seed)\n",
    "    kfold = model_selection.KFold(n_splits=nfold, random_state=seed)\n",
    "    \n",
    "    models = []\n",
    "    model_scores_train = []\n",
    "    model_scores_val = []\n",
    "    \n",
    "    X_kfold = np.array(X)\n",
    "    Y_kfold = np.array(Y)\n",
    "    \n",
    "    i = 0\n",
    "    for train_index, val_index in kfold.split(X_kfold):\n",
    "        i = i+1\n",
    "        print(\"Fold: {}\".format(i))\n",
    "        \n",
    "        X_train, X_val = X_kfold[train_index], X_kfold[val_index]\n",
    "        y_train, y_val = Y_kfold[train_index], Y_kfold[val_index]\n",
    "        \n",
    "        lr = LogisticRegression(C=1, random_state=0, solver='saga', multi_class='ovr', \n",
    "                            verbose=verbose_level, n_jobs=10, max_iter=model_max_iter)\n",
    "        print()\n",
    "        print(\"Model: Logistic Regression\")\n",
    "        print(lr)\n",
    "        print()\n",
    "        print(\"Logistic Regression: Fit\")\n",
    "        lr.fit(X_train, y_train)\n",
    "\n",
    "        #add model for list\n",
    "        models.append(lr)\n",
    "\n",
    "        print(\"Logistic Regression: Predict\")\n",
    "        y_pred = lr.predict(X_val)\n",
    "\n",
    "        mst = lr.score(X_train, y_train)\n",
    "        model_scores_train.append(mst)\n",
    "        \n",
    "        msv = lr.score(X_val, y_val)\n",
    "        model_scores_val.append(msv)\n",
    "        \n",
    "        print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(mst))\n",
    "        print('Accuracy of logistic regression classifier on validation set: {:.2f}'.format(msv))\n",
    "\n",
    "        # print the intercept (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "        print(\"Logistic Regression: Intercept\")\n",
    "        print(lr.intercept_)\n",
    "\n",
    "        # print the coeficients (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "        print(\"Logistic Regression: Coefficients\")\n",
    "        print(lr.coef_)\n",
    "\n",
    "        print(\"Logistic Regression: Confusion Matrix\")\n",
    "        cnf_matrix_lg = confusion_matrix(y_val, y_pred)\n",
    "        print(cnf_matrix_lg)\n",
    "    \n",
    "        print(\"Logistic Regression: Classification Report\")\n",
    "        print(classification_report(y_val, y_pred))\n",
    "\n",
    "    print('AVG Accuracy of logistic regression classifier on train set: {:.2f}'.format(np.mean(model_scores_train)))\n",
    "    print('AVG Accuracy of logistic regression classifier on validation set: {:.2f}'.format(np.mean(model_scores_val)))\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "    # save model to file\n",
    "    pickle.dump(models, open(file_lr, \"wb\"))\n",
    "    print(\"Logistic Regression: End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (False):    \n",
    "    seed = 101\n",
    "    print(\"Logistic Regression: Start\")\n",
    "    t_start =  time.time()\n",
    "    print()\n",
    "    print(\"Model: Logistic Regression\")\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print()\n",
    "    print(\"Using Stratified Kfold: {}\".format(nfold))\n",
    "    \n",
    "    models = []\n",
    "    model_scores_train = []\n",
    "    model_scores_val = []\n",
    "    \n",
    "    X_kfold = np.array(X)\n",
    "    Y_kfold = np.array(Y)\n",
    "    \n",
    "    skf = model_selection.StratifiedKFold(n_splits=nfold, shuffle=True, random_state=seed)    \n",
    "    i = 0\n",
    "    for train_index, val_index in skf.split(X_kfold, Y_kfold):\n",
    "        i = i+1\n",
    "        print(\"Fold: {}\".format(i))\n",
    "        \n",
    "        X_train, X_val = X_kfold[train_index], X_kfold[val_index]\n",
    "        y_train, y_val = Y_kfold[train_index], Y_kfold[val_index]\n",
    "        \n",
    "        lr = LogisticRegression(C=1, random_state=0, solver='saga', multi_class='ovr', \n",
    "                            verbose=verbose_level, n_jobs=10, max_iter=model_max_iter)\n",
    "        print()\n",
    "        print(\"Model: Logistic Regression\")\n",
    "        print(lr)\n",
    "        print()\n",
    "        print(\"Logistic Regression: Fit\")\n",
    "        lr.fit(X_train, y_train)\n",
    "\n",
    "        #add model for list\n",
    "        models.append(lr)\n",
    "\n",
    "        print(\"Logistic Regression: Predict\")\n",
    "        y_pred = lr.predict(X_val)\n",
    "\n",
    "        mst = lr.score(X_train, y_train)\n",
    "        model_scores_train.append(mst)\n",
    "        \n",
    "        msv = lr.score(X_val, y_val)\n",
    "        model_scores_val.append(msv)\n",
    "        \n",
    "        print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(mst))\n",
    "        print('Accuracy of logistic regression classifier on validation set: {:.2f}'.format(msv))\n",
    "\n",
    "        # print the intercept (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "        print(\"Logistic Regression: Intercept\")\n",
    "        print(lr.intercept_)\n",
    "\n",
    "        # print the coeficients (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "        print(\"Logistic Regression: Coefficients\")\n",
    "        print(lr.coef_)\n",
    "\n",
    "        print(\"Logistic Regression: Confusion Matrix\")\n",
    "        cnf_matrix_lg = confusion_matrix(y_val, y_pred)\n",
    "        print(cnf_matrix_lg)\n",
    "    \n",
    "        print(\"Logistic Regression: Classification Report\")\n",
    "        print(classification_report(y_val, y_pred))\n",
    "\n",
    "    print('AVG Accuracy of logistic regression classifier on train set: {:.2f}'.format(np.mean(model_scores_train)))\n",
    "    print('AVG Accuracy of logistic regression classifier on validation set: {:.2f}'.format(np.mean(model_scores_val)))\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "    # save model to file\n",
    "    pickle.dump(models, open(file_lr, \"wb\"))\n",
    "    print(\"Logistic Regression: End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (False)\n",
    "    ## for each model generated, lets predict the on test set\n",
    "    ## note, this is the first time any of these observations are seen by the model\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_lr, \"rb\"))\n",
    "    print(\"Logistic Regression: Predict on test set\")\n",
    "\n",
    "    i = 0\n",
    "    for model in loaded_model:\n",
    "        i = i + 1\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(model.score(X_test, Y_test)))\n",
    "\n",
    "        # print the intercept (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "        print(\"Logistic Regression: Intercept\")\n",
    "        print(model.intercept_)\n",
    "\n",
    "        # print the coeficients (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "        print(\"Logistic Regression: Coefficients\")\n",
    "        print(model.coef_)\n",
    "\n",
    "        print(\"Logistic Regression: Confusion Matrix\")\n",
    "        cnf_matrix_lg = confusion_matrix(Y_test, y_pred)\n",
    "        print(cnf_matrix_lg)\n",
    "    \n",
    "        print(\"Logistic Regression: Classification Report\")\n",
    "        print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
