{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#in case we need to repeat experiment\n",
    "#np.random.seed(255)\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 22\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('classic')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "#sklearn imports\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pickle # allows for model to be saved/load to file\n",
    "import time\n",
    "\n",
    "#Use print instead of display when run as python script\n",
    "pyscript = True\n",
    "\n",
    "#Classifier verborsity where supported\n",
    "verbose_level=3\n",
    "\n",
    "#Multiclass classification, binary if falase\n",
    "multiclass = False\n",
    "over_sample = True\n",
    "\n",
    "#inputfile = 'CKME136X10_2018_Data_CTF.csv'\n",
    "if multiclass:\n",
    "    inputfile_train_O = 'CKME136X10_2018_Data_CTFB_M_O_Train.csv'\n",
    "    inputfile_train_U = 'CKME136X10_2018_Data_CTFB_M_U_Train.csv'\n",
    "    inputfile_test = 'CKME136X10_2018_Data_CTFB_M_Test.csv'\n",
    "else:\n",
    "    inputfile_train_O = 'CKME136X10_2018_Data_CTFB_B_O_Train.csv'\n",
    "    inputfile_train_U = 'CKME136X10_2018_Data_CTFB_B_U_Train.csv'\n",
    "    inputfile_test = 'CKME136X10_2018_Data_CTFB_B_Test.csv'\n",
    "\n",
    "if over_sample:\n",
    "    datafile_train = inputfile_train_O\n",
    "else:\n",
    "    datafile_train = inputfile_train_U\n",
    "\n",
    "datafile_test = inputfile_test\n",
    "    \n",
    "model_max_iter = 1000\n",
    "datestr = 'dec_07_binary_run_1000_KBO'\n",
    "\n",
    "#Model Store\n",
    "file_lr = 'lr_' + datestr + '.model'\n",
    "file_lr_l1 = 'lr_l2_' + datestr + '.model'\n",
    "file_dt = 'dt_' + datestr + '.model'\n",
    "file_svm = 'svm_' + datestr + '.model'\n",
    "file_knn = 'knn_' + datestr + '.model'\n",
    "file_mlp = 'mlp_' + datestr + '.model'\n",
    "file_kmean = 'kmean_' + datestr + '.model'\n",
    "file_nbayes = 'nbayes_' + datestr + '.model'\n",
    "\n",
    "file_final_train = 'final_train_' + datestr + '.csv'\n",
    "file_final_test = 'final_test_' + datestr + '.csv'\n",
    "\n",
    "#Enable Optimization Algorithms\n",
    "enable_grid_search = False\n",
    "svm_c = 1\n",
    "svm_gamma = 1\n",
    "nfold = 10\n",
    "\n",
    "enable_lr_l1 = False\n",
    "predict_lr_l1 = False\n",
    "\n",
    "# Enable Algorithms\n",
    "enable_lr = True\n",
    "enable_dt = True\n",
    "enable_svm = True\n",
    "enable_knn = True\n",
    "enable_mlp = True\n",
    "enable_nbayes = True\n",
    "\n",
    "predict_lr = False\n",
    "predict_dt = True\n",
    "predict_svm = True\n",
    "predict_knn = False\n",
    "predict_mlp = True\n",
    "predict_nbayes = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function converts the data frame to the appropriate data type\n",
    "def convert_type(data):\n",
    "    data = data.astype('category')\n",
    "    data['C_MNTH'] = data['C_MNTH'].astype(CategoricalDtype(ordered=True))\n",
    "    data['C_WDAY'] = data['C_WDAY'].astype(CategoricalDtype(ordered=True))\n",
    "    data['C_HOUR'] = data['C_HOUR'].astype(CategoricalDtype(ordered=True))\n",
    "    data['C_VEHS'] = data['C_VEHS'].astype(CategoricalDtype(ordered=True))\n",
    "    data['P_AGE'] = data['P_AGE'].astype(CategoricalDtype(ordered=True))\n",
    "    data['P_PSN'] = data['P_PSN'].astype(CategoricalDtype(ordered=True))\n",
    "    data['P_ISEV'] = data['P_ISEV'].astype('int')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Class Classification: Disabled\n",
      "Logistic Regression: Enabled\n",
      "Decision Tree: Enabled\n",
      "Support Vector Machines: Enabled\n",
      "KNN: Enabled\n",
      "Naive Bayes: Enabled\n",
      "MLP: Enabled\n"
     ]
    }
   ],
   "source": [
    "#print(\"Sample size: {}\".format(sampleN))\n",
    "\n",
    "if multiclass:\n",
    "    print(\"Multi-Class Classification: Enabled\")\n",
    "else:\n",
    "    print(\"Multi-Class Classification: Disabled\")\n",
    "\n",
    "if enable_lr:\n",
    "    print(\"Logistic Regression: Enabled\")\n",
    "else:\n",
    "    print(\"Logistic Regression: Disabled\")\n",
    "    \n",
    "if enable_dt:\n",
    "    print(\"Decision Tree: Enabled\")\n",
    "else:\n",
    "    print(\"Decision Tree: Disabled\")\n",
    "    \n",
    "if enable_svm:\n",
    "    print(\"Support Vector Machines: Enabled\")\n",
    "else:\n",
    "    print(\"Support Vector Machines: Disabled\")\n",
    "\n",
    "if  enable_knn:\n",
    "    print(\"KNN: Enabled\")\n",
    "else:\n",
    "    print(\"KNN: Disabled\")\n",
    "    \n",
    "if enable_nbayes:\n",
    "    print(\"Naive Bayes: Enabled\")\n",
    "else:\n",
    "    print(\"Naive Bayes: Disabled\")\n",
    "    \n",
    "if enable_mlp:\n",
    "    print(\"MLP: Enabled\")\n",
    "else:\n",
    "    print(\"MLP: Disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C_MNTH  C_WDAY  C_HOUR  C_VEHS  C_CONF  C_RCFG  C_WTHR  C_RSUR  C_RALN  \\\n",
      "0       8       5       2       2      36       2       1       1       1   \n",
      "1       6       5       2       2      33       2       1       1       1   \n",
      "\n",
      "   C_TRAF  P_SEX  P_AGE  P_PSN  P_USER  P_ISEV  \n",
      "0       2      2      1      1       3       1  \n",
      "1       1      1      4      1       2       0  \n",
      "   C_MNTH  C_WDAY  C_HOUR  C_VEHS  C_CONF  C_RCFG  C_WTHR  C_RSUR  C_RALN  \\\n",
      "0       6       2       4       2      23       1       1       1       1   \n",
      "1       2       6       1       1       3       1       4       6       1   \n",
      "\n",
      "   C_TRAF  P_SEX  P_AGE  P_PSN  P_USER  P_ISEV  \n",
      "0       7      2      4      1       1       1  \n",
      "1       7      1      4      1       1       1  \n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "df_test = pd.read_csv(datafile_test, engine = 'python')\n",
    "df_train = pd.read_csv(datafile_train, engine = 'python')\n",
    "df = df_train.copy()\n",
    "\n",
    "print(df_test.head(2))\n",
    "print(df_train.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1444846 entries, 0 to 1444845\n",
      "Data columns (total 15 columns):\n",
      "C_MNTH    1444846 non-null category\n",
      "C_WDAY    1444846 non-null category\n",
      "C_HOUR    1444846 non-null category\n",
      "C_VEHS    1444846 non-null category\n",
      "C_CONF    1444846 non-null category\n",
      "C_RCFG    1444846 non-null category\n",
      "C_WTHR    1444846 non-null category\n",
      "C_RSUR    1444846 non-null category\n",
      "C_RALN    1444846 non-null category\n",
      "C_TRAF    1444846 non-null category\n",
      "P_SEX     1444846 non-null category\n",
      "P_AGE     1444846 non-null category\n",
      "P_PSN     1444846 non-null category\n",
      "P_USER    1444846 non-null category\n",
      "P_ISEV    1444846 non-null int32\n",
      "dtypes: category(14), int32(1)\n",
      "memory usage: 24.8 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3878536 entries, 0 to 3878535\n",
      "Data columns (total 15 columns):\n",
      "C_MNTH    category\n",
      "C_WDAY    category\n",
      "C_HOUR    category\n",
      "C_VEHS    category\n",
      "C_CONF    category\n",
      "C_RCFG    category\n",
      "C_WTHR    category\n",
      "C_RSUR    category\n",
      "C_RALN    category\n",
      "C_TRAF    category\n",
      "P_SEX     category\n",
      "P_AGE     category\n",
      "P_PSN     category\n",
      "P_USER    category\n",
      "P_ISEV    int32\n",
      "dtypes: category(14), int32(1)\n",
      "memory usage: 66.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_test_cat = convert_type(df_test)\n",
    "print(df_test_cat.info())\n",
    "df_train_cat = convert_type(df_train)\n",
    "print(df_train_cat.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows in test data: 1444846\n",
      "Number of Rows in train data: 3878536\n"
     ]
    }
   ],
   "source": [
    "total_test_Rows = df_test_cat.index.size\n",
    "print(\"Number of Rows in test data: {}\".format(total_test_Rows))\n",
    "\n",
    "total_train_Rows = df_train_cat.index.size\n",
    "print(\"Number of Rows in train data: {}\".format(total_train_Rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split between data and class for training\n",
    "Y = df_train_cat[df_train_cat.columns[-1]]\n",
    "X = df_train_cat[df_train_cat.columns[0:df_train_cat.columns.size -1]]\n",
    "\n",
    "Y_test = df_test_cat[df_test_cat.columns[-1]]\n",
    "X_test = df_test_cat[df_test_cat.columns[0:df_test_cat.columns.size -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "P_ISEV\n",
      "0    1939268\n",
      "1    1939268\n",
      "Name: P_ISEV, dtype: int64\n",
      "[1 0]\n",
      "P_ISEV\n",
      "0    613731\n",
      "1    831115\n",
      "Name: P_ISEV, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Y.unique())\n",
    "print(Y.groupby(Y).size())\n",
    "print(Y_test.unique())\n",
    "print(Y_test.groupby(Y_test).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### Logistic Regression Model Evaluation with cross fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Start\n",
      "\n",
      "Model: Logistic Regression\n",
      "Fri Dec  7 17:39:50 2018\n",
      "\n",
      "Using Kfold: 10\n",
      "\n",
      "Model: Logistic Regression\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=10,\n",
      "          penalty='l2', random_state=0, solver='saga', tol=0.0001,\n",
      "          verbose=3, warm_start=False)\n",
      "\n",
      "Logistic Regression: Fit\n",
      "convergence after 16 epochs took 40 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   40.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 14 epochs took 35 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   35.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 15 epochs took 35 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   34.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 14 epochs took 31 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   31.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 15 epochs took 36 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   35.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 14 epochs took 34 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   33.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 15 epochs took 36 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   36.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 16 epochs took 37 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   36.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 15 epochs took 34 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   33.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 15 epochs took 37 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   37.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kfold results: [0.62984267 0.62883714 0.62879073 0.62945593 0.62717414 0.62913622\n",
      " 0.62849681 0.62947398 0.62968864 0.62696853]\n",
      "Kfold mean\" 0.6287864797873317\n",
      "Fri Dec  7 17:46:18 2018\n",
      "Logistic Regression: End\n"
     ]
    }
   ],
   "source": [
    "if enable_lr:\n",
    "    print(\"Logistic Regression: Start\")\n",
    "    t_start =  time.time()\n",
    "    print()\n",
    "    print(\"Model: Logistic Regression\")\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print()\n",
    "    print(\"Using Kfold: {}\".format(nfold))\n",
    "    #kfold = model_selection.KFold(n_splits=nfold)\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=nfold, shuffle=True)  \n",
    "    \n",
    "    lr = LogisticRegression(C=1, random_state=0, solver='saga', multi_class='ovr', \n",
    "                            verbose=verbose_level, n_jobs=10, max_iter=model_max_iter)\n",
    "    print()\n",
    "    print(\"Model: Logistic Regression\")\n",
    "    print(lr)\n",
    "    print()\n",
    "    print(\"Logistic Regression: Fit\")\n",
    "    results = model_selection.cross_val_score(lr, X, Y, cv=kfold)\n",
    "    \n",
    "    print('Kfold results: {}'.format(results))\n",
    "    print('Kfold mean\" {}'.format(results.mean()))\n",
    "\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"Logistic Regression: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Model Evaluation with cross fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes: Start\n",
      "\n",
      "Model: Naive Bayes\n",
      "Fri Dec  7 17:46:18 2018\n",
      "\n",
      "Using Stratified Kfold: 10\n",
      "\n",
      "Model: Naive Bayes\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=10,\n",
      "          penalty='l2', random_state=0, solver='saga', tol=0.0001,\n",
      "          verbose=3, warm_start=False)\n",
      "\n",
      "Naive Bayes: Fit\n",
      "Kfold results: [0.5989032  0.59893671 0.60032641 0.59868662 0.59991904 0.59963285\n",
      " 0.60000413 0.59924353 0.59917443 0.59801935]\n",
      "Kfold mean\" 0.5992846262736881\n",
      "Fri Dec  7 17:46:59 2018\n",
      "Naive Bayes: End\n"
     ]
    }
   ],
   "source": [
    "if enable_nbayes:\n",
    "    print(\"Naive Bayes: Start\")\n",
    "    t_start =  time.time()\n",
    "    print()\n",
    "    print(\"Model: Naive Bayes\")\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print()\n",
    "    print(\"Using Stratified Kfold: {}\".format(nfold))\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=nfold, shuffle=True)  \n",
    "    nbayes = GaussianNB()\n",
    "    print()\n",
    "    print(\"Model: Naive Bayes\")\n",
    "    print(nbayes)\n",
    "    print()\n",
    "    print(\"Naive Bayes: Fit\")\n",
    "    results = model_selection.cross_val_score(nbayes, X, Y, cv=kfold)\n",
    "    #lr.fit(X_train, Y_train)\n",
    "    \n",
    "    print('Kfold results: {}'.format(results))\n",
    "    print('Kfold mean\" {}'.format(results.mean()))\n",
    "\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"Naive Bayes: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model Evaluation with cross fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: Start\n",
      "\n",
      "Model: Decision Tree\n",
      "Fri Dec  7 17:46:59 2018\n",
      "\n",
      "Using Stratified Kfold: 10\n",
      "\n",
      "Model: Decision Tree\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=10,\n",
      "          penalty='l2', random_state=0, solver='saga', tol=0.0001,\n",
      "          verbose=3, warm_start=False)\n",
      "\n",
      "Decision Tree: Fit\n",
      "Kfold results: [0.65743811 0.65820902 0.65795892 0.65858803 0.65695597 0.65817808\n",
      " 0.65740717 0.65688378 0.65736931 0.65749306]\n",
      "Kfold mean\" 0.6576481433025675\n",
      "Fri Dec  7 17:54:43 2018\n",
      "Decision Tree: End\n"
     ]
    }
   ],
   "source": [
    "if predict_dt:\n",
    "    print(\"Decision Tree: Start\")\n",
    "    t_start =  time.time()\n",
    "    print()\n",
    "    print(\"Model: Decision Tree\")\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print()\n",
    "    print(\"Using Stratified Kfold: {}\".format(nfold))\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=nfold, shuffle=True)  \n",
    "    tree = DecisionTreeClassifier(criterion='entropy',max_depth=50)\n",
    "    print()\n",
    "    print(\"Model: Decision Tree\")\n",
    "    print(tree)\n",
    "    print()\n",
    "    print(\"Decision Tree: Fit\")\n",
    "    results = model_selection.cross_val_score(tree, X, Y, cv=kfold)\n",
    "    #lr.fit(X_train, Y_train)\n",
    "    \n",
    "    print('Kfold results: {}'.format(results))\n",
    "    print('Kfold mean\" {}'.format(results.mean()))\n",
    "\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"Decision Tree: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN - Multilayer Perceptron Model evaluation with cross fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Perceptron: Start\n",
      "\n",
      "Model: Multilayer Perceptron\n",
      "Fri Dec  7 17:54:43 2018\n",
      "\n",
      "Using Stratified Kfold: 10\n",
      "\n",
      "Model: Multilayer Perceptron\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=10,\n",
      "          penalty='l2', random_state=0, solver='saga', tol=0.0001,\n",
      "          verbose=3, warm_start=False)\n",
      "\n",
      "Multilayer Perceptron: Fit\n",
      "Iteration 1, loss = 0.60978339\n",
      "Iteration 2, loss = 0.60219070\n",
      "Iteration 3, loss = 0.60031652\n",
      "Iteration 4, loss = 0.59918413\n",
      "Iteration 5, loss = 0.59791984\n",
      "Iteration 6, loss = 0.59741047\n",
      "Iteration 7, loss = 0.59705158\n",
      "Iteration 8, loss = 0.59685187\n",
      "Iteration 9, loss = 0.59662792\n",
      "Iteration 10, loss = 0.59644359\n",
      "Iteration 11, loss = 0.59630366\n",
      "Iteration 12, loss = 0.59620469\n",
      "Iteration 13, loss = 0.59602715\n",
      "Iteration 14, loss = 0.59602250\n",
      "Iteration 15, loss = 0.59586309\n",
      "Iteration 16, loss = 0.59574551\n",
      "Iteration 17, loss = 0.59565466\n",
      "Iteration 18, loss = 0.59558321\n",
      "Iteration 19, loss = 0.59548332\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.61516569\n",
      "Iteration 2, loss = 0.60328647\n",
      "Iteration 3, loss = 0.60104763\n",
      "Iteration 4, loss = 0.59978321\n",
      "Iteration 5, loss = 0.59891314\n",
      "Iteration 6, loss = 0.59801389\n",
      "Iteration 7, loss = 0.59747690\n",
      "Iteration 8, loss = 0.59718370\n",
      "Iteration 9, loss = 0.59687531\n",
      "Iteration 10, loss = 0.59670156\n",
      "Iteration 11, loss = 0.59652091\n",
      "Iteration 12, loss = 0.59632979\n",
      "Iteration 13, loss = 0.59619354\n",
      "Iteration 14, loss = 0.59606559\n",
      "Iteration 15, loss = 0.59597370\n",
      "Iteration 16, loss = 0.59584563\n",
      "Iteration 17, loss = 0.59572552\n",
      "Iteration 18, loss = 0.59567106\n",
      "Iteration 19, loss = 0.59559498\n",
      "Iteration 20, loss = 0.59552679\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.61102046\n",
      "Iteration 2, loss = 0.60230648\n",
      "Iteration 3, loss = 0.60041785\n",
      "Iteration 4, loss = 0.59935282\n",
      "Iteration 5, loss = 0.59847521\n",
      "Iteration 6, loss = 0.59792526\n",
      "Iteration 7, loss = 0.59748664\n",
      "Iteration 8, loss = 0.59708844\n",
      "Iteration 9, loss = 0.59674804\n",
      "Iteration 10, loss = 0.59638767\n",
      "Iteration 11, loss = 0.59604473\n",
      "Iteration 12, loss = 0.59581010\n",
      "Iteration 13, loss = 0.59561036\n",
      "Iteration 14, loss = 0.59543518\n",
      "Iteration 15, loss = 0.59529113\n",
      "Iteration 16, loss = 0.59518578\n",
      "Iteration 17, loss = 0.59508573\n",
      "Iteration 18, loss = 0.59496592\n",
      "Iteration 19, loss = 0.59484263\n",
      "Iteration 20, loss = 0.59478609\n",
      "Iteration 21, loss = 0.59472176\n",
      "Iteration 22, loss = 0.59465815\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.61047074\n",
      "Iteration 2, loss = 0.60169128\n",
      "Iteration 3, loss = 0.59993526\n",
      "Iteration 4, loss = 0.59896124\n",
      "Iteration 5, loss = 0.59832247\n",
      "Iteration 6, loss = 0.59767699\n",
      "Iteration 7, loss = 0.59707953\n",
      "Iteration 8, loss = 0.59653180\n",
      "Iteration 9, loss = 0.59604690\n",
      "Iteration 10, loss = 0.59567501\n",
      "Iteration 11, loss = 0.59549964\n",
      "Iteration 12, loss = 0.59522093\n",
      "Iteration 13, loss = 0.59509324\n",
      "Iteration 14, loss = 0.59493072\n",
      "Iteration 15, loss = 0.59475716\n",
      "Iteration 16, loss = 0.59459179\n",
      "Iteration 17, loss = 0.59446709\n",
      "Iteration 18, loss = 0.59439440\n",
      "Iteration 19, loss = 0.59430565\n",
      "Iteration 20, loss = 0.59419037\n",
      "Iteration 21, loss = 0.59406986\n",
      "Iteration 22, loss = 0.59404588\n",
      "Iteration 23, loss = 0.59395553\n",
      "Iteration 24, loss = 0.59395806\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.61008865\n",
      "Iteration 2, loss = 0.60205793\n",
      "Iteration 3, loss = 0.60071054\n",
      "Iteration 4, loss = 0.59980506\n",
      "Iteration 5, loss = 0.59895862\n",
      "Iteration 6, loss = 0.59842592\n",
      "Iteration 7, loss = 0.59799711\n",
      "Iteration 8, loss = 0.59751055\n",
      "Iteration 9, loss = 0.59710290\n",
      "Iteration 10, loss = 0.59670293\n",
      "Iteration 11, loss = 0.59639971\n",
      "Iteration 12, loss = 0.59613918\n",
      "Iteration 13, loss = 0.59596550\n",
      "Iteration 14, loss = 0.59585808\n",
      "Iteration 15, loss = 0.59571951\n",
      "Iteration 16, loss = 0.59550366\n",
      "Iteration 17, loss = 0.59543516\n",
      "Iteration 18, loss = 0.59533165\n",
      "Iteration 19, loss = 0.59523943\n",
      "Iteration 20, loss = 0.59515853\n",
      "Iteration 21, loss = 0.59510870\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.61164272\n",
      "Iteration 2, loss = 0.60169104\n",
      "Iteration 3, loss = 0.59967889\n",
      "Iteration 4, loss = 0.59833807\n",
      "Iteration 5, loss = 0.59754855\n",
      "Iteration 6, loss = 0.59714351\n",
      "Iteration 7, loss = 0.59685967\n",
      "Iteration 8, loss = 0.59666641\n",
      "Iteration 9, loss = 0.59646700\n",
      "Iteration 10, loss = 0.59633455\n",
      "Iteration 11, loss = 0.59622731\n",
      "Iteration 12, loss = 0.59608337\n",
      "Iteration 13, loss = 0.59599138\n",
      "Iteration 14, loss = 0.59582931\n",
      "Iteration 15, loss = 0.59574177\n",
      "Iteration 16, loss = 0.59564880\n",
      "Iteration 17, loss = 0.59557136\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.61264189\n",
      "Iteration 2, loss = 0.60304303\n",
      "Iteration 3, loss = 0.60099497\n",
      "Iteration 4, loss = 0.59968495\n",
      "Iteration 5, loss = 0.59858767\n",
      "Iteration 6, loss = 0.59786098\n",
      "Iteration 7, loss = 0.59728539\n",
      "Iteration 8, loss = 0.59691683\n",
      "Iteration 9, loss = 0.59662128\n",
      "Iteration 10, loss = 0.59640232\n",
      "Iteration 11, loss = 0.59623564\n",
      "Iteration 12, loss = 0.59607111\n",
      "Iteration 13, loss = 0.59588629\n",
      "Iteration 14, loss = 0.59582327\n",
      "Iteration 15, loss = 0.59564971\n",
      "Iteration 16, loss = 0.59554852\n",
      "Iteration 17, loss = 0.59537172\n",
      "Iteration 18, loss = 0.59530655\n",
      "Iteration 19, loss = 0.59520742\n",
      "Iteration 20, loss = 0.59514439\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.61090079\n",
      "Iteration 2, loss = 0.60173930\n",
      "Iteration 3, loss = 0.59975385\n",
      "Iteration 4, loss = 0.59871424\n",
      "Iteration 5, loss = 0.59805746\n",
      "Iteration 6, loss = 0.59761541\n",
      "Iteration 7, loss = 0.59722740\n",
      "Iteration 8, loss = 0.59685691\n",
      "Iteration 9, loss = 0.59651306\n",
      "Iteration 10, loss = 0.59627870\n",
      "Iteration 11, loss = 0.59609628\n",
      "Iteration 12, loss = 0.59591290\n",
      "Iteration 13, loss = 0.59580364\n",
      "Iteration 14, loss = 0.59572113\n",
      "Iteration 15, loss = 0.59559314\n",
      "Iteration 16, loss = 0.59554375\n",
      "Iteration 17, loss = 0.59544132\n",
      "Iteration 18, loss = 0.59539271\n",
      "Iteration 19, loss = 0.59528855\n",
      "Iteration 20, loss = 0.59521043\n",
      "Iteration 21, loss = 0.59517183\n",
      "Iteration 22, loss = 0.59511117\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.61278611\n",
      "Iteration 2, loss = 0.60198579\n",
      "Iteration 3, loss = 0.60012023\n",
      "Iteration 4, loss = 0.59910543\n",
      "Iteration 5, loss = 0.59837254\n",
      "Iteration 6, loss = 0.59768304\n",
      "Iteration 7, loss = 0.59713599\n",
      "Iteration 8, loss = 0.59666861\n",
      "Iteration 9, loss = 0.59639108\n",
      "Iteration 10, loss = 0.59612798\n",
      "Iteration 11, loss = 0.59591162\n",
      "Iteration 12, loss = 0.59566232\n",
      "Iteration 13, loss = 0.59554228\n",
      "Iteration 14, loss = 0.59542839\n",
      "Iteration 15, loss = 0.59525442\n",
      "Iteration 16, loss = 0.59514995\n",
      "Iteration 17, loss = 0.59503936\n",
      "Iteration 18, loss = 0.59496193\n",
      "Iteration 19, loss = 0.59487089\n",
      "Iteration 20, loss = 0.59478890\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.61276384\n",
      "Iteration 2, loss = 0.60191825\n",
      "Iteration 3, loss = 0.59971292\n",
      "Iteration 4, loss = 0.59838373\n",
      "Iteration 5, loss = 0.59747750\n",
      "Iteration 6, loss = 0.59685973\n",
      "Iteration 7, loss = 0.59638726\n",
      "Iteration 8, loss = 0.59596009\n",
      "Iteration 9, loss = 0.59566437\n",
      "Iteration 10, loss = 0.59536665\n",
      "Iteration 11, loss = 0.59516049\n",
      "Iteration 12, loss = 0.59507072\n",
      "Iteration 13, loss = 0.59494012\n",
      "Iteration 14, loss = 0.59483800\n",
      "Iteration 15, loss = 0.59472681\n",
      "Iteration 16, loss = 0.59465777\n",
      "Iteration 17, loss = 0.59460273\n",
      "Iteration 18, loss = 0.59446379\n",
      "Iteration 19, loss = 0.59444314\n",
      "Iteration 20, loss = 0.59441615\n",
      "Iteration 21, loss = 0.59434823\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Kfold results: [0.66659877 0.66775127 0.66889087 0.66758883 0.6686975  0.66452325\n",
      " 0.66803746 0.66886767 0.66884791 0.66915731]\n",
      "Kfold mean\" 0.6678960835805321\n",
      "Fri Dec  7 19:34:12 2018\n",
      "Multilayer Perceptron: End\n"
     ]
    }
   ],
   "source": [
    "if predict_mlp:\n",
    "    print(\"Multilayer Perceptron: Start\")\n",
    "    t_start =  time.time()\n",
    "    print()\n",
    "    print(\"Model: Multilayer Perceptron\")\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print()\n",
    "    print(\"Using Stratified Kfold: {}\".format(nfold))\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=nfold, shuffle=True)  \n",
    "    mlpc = MLPClassifier(hidden_layer_sizes=(25, 25, 25), verbose=verbose_level, max_iter=model_max_iter)\n",
    "    print()\n",
    "    print(\"Model: Multilayer Perceptron\")\n",
    "    print(mlpc)\n",
    "    print()\n",
    "    print(\"Multilayer Perceptron: Fit\")\n",
    "    results = model_selection.cross_val_score(mlpc, X, Y, cv=kfold)\n",
    "    #lr.fit(X_train, Y_train)\n",
    "    \n",
    "    print('Kfold results: {}'.format(results))\n",
    "    print('Kfold mean\" {}'.format(results.mean()))\n",
    "\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"Multilayer Perceptron: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model Evaluation with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: Start\n",
      "\n",
      "Model: SVM\n",
      "Fri Dec  7 19:34:12 2018\n",
      "\n",
      "Using Stratified Kfold: 10\n",
      "\n",
      "Model: SVM\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=10,\n",
      "          penalty='l2', random_state=0, solver='saga', tol=0.0001,\n",
      "          verbose=3, warm_start=False)\n",
      "\n",
      "SVM: Fit\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kfold results: [0.49676682 0.49743202 0.49750679 0.49841435 0.49470677 0.49593146\n",
      " 0.49304377 0.49518375 0.4948073  0.49814362]\n",
      "Kfold mean\" 0.496193667179361\n",
      "Fri Dec  7 20:13:04 2018\n",
      "SVM: End\n"
     ]
    }
   ],
   "source": [
    "if predict_svm:\n",
    "    print(\"SVM: Start\")\n",
    "    t_start =  time.time()\n",
    "    print()\n",
    "    print(\"Model: SVM\")\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print()\n",
    "    print(\"Using Stratified Kfold: {}\".format(nfold))\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=nfold, shuffle=True)  \n",
    "    svm = SVC(C=1, gamma = 'auto', verbose = verbose_level, max_iter=model_max_iter)\n",
    "    print()\n",
    "    print(\"Model: SVM\")\n",
    "    print(svm)\n",
    "    print()\n",
    "    print(\"SVM: Fit\")\n",
    "    results = model_selection.cross_val_score(svm, X, Y, cv=kfold)\n",
    "    #lr.fit(X_train, Y_train)\n",
    "    \n",
    "    print('Kfold results: {}'.format(results))\n",
    "    print('Kfold mean\" {}'.format(results.mean()))\n",
    "\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"SVM: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-N-N Model Evaluation with cross fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: End\n"
     ]
    }
   ],
   "source": [
    "if predict_knn:\n",
    "    print(\"KNN: Start\")\n",
    "    t_start =  time.time()\n",
    "    print()\n",
    "    print(\"Model: KNN\")\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print()\n",
    "    print(\"Using Stratified Kfold: {}\".format(nfold))\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=nfold, shuffle=True)  \n",
    "    knn = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski', n_jobs = -1)\n",
    "    print()\n",
    "    print(\"Model: KNN\")\n",
    "    print(knn)\n",
    "    print()\n",
    "    print(\"KNN: Fit\")\n",
    "    results = model_selection.cross_val_score(knn, X, Y, cv=kfold)\n",
    "    #lr.fit(X_train, Y_train)\n",
    "    \n",
    "    print('Kfold results: {}'.format(results))\n",
    "    print('Kfold mean\" {}'.format(results.mean()))\n",
    "\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"KNN: End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extra code and play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (False):    \n",
    "    seed = 101\n",
    "    print(\"Logistic Regression: Start\")\n",
    "    t_start =  time.time()\n",
    "    print()\n",
    "    print(\"Model: Logistic Regression\")\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print()\n",
    "    print(\"Using Kfold: {}\".format(nfold))\n",
    "    #kfold = model_selection.StratifiedKFold(n_splits=nfold, shuffle=True, random_state=seed)\n",
    "    kfold = model_selection.KFold(n_splits=nfold, random_state=seed)\n",
    "    \n",
    "    models = []\n",
    "    model_scores_train = []\n",
    "    model_scores_val = []\n",
    "    \n",
    "    X_kfold = np.array(X)\n",
    "    Y_kfold = np.array(Y)\n",
    "    \n",
    "    i = 0\n",
    "    for train_index, val_index in kfold.split(X_kfold):\n",
    "        i = i+1\n",
    "        print(\"Fold: {}\".format(i))\n",
    "        \n",
    "        X_train, X_val = X_kfold[train_index], X_kfold[val_index]\n",
    "        y_train, y_val = Y_kfold[train_index], Y_kfold[val_index]\n",
    "        \n",
    "        lr = LogisticRegression(C=1, random_state=0, solver='saga', multi_class='ovr', \n",
    "                            verbose=verbose_level, n_jobs=10, max_iter=model_max_iter)\n",
    "        print()\n",
    "        print(\"Model: Logistic Regression\")\n",
    "        print(lr)\n",
    "        print()\n",
    "        print(\"Logistic Regression: Fit\")\n",
    "        lr.fit(X_train, y_train)\n",
    "\n",
    "        #add model for list\n",
    "        models.append(lr)\n",
    "\n",
    "        print(\"Logistic Regression: Predict\")\n",
    "        y_pred = lr.predict(X_val)\n",
    "\n",
    "        mst = lr.score(X_train, y_train)\n",
    "        model_scores_train.append(mst)\n",
    "        \n",
    "        msv = lr.score(X_val, y_val)\n",
    "        model_scores_val.append(msv)\n",
    "        \n",
    "        print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(mst))\n",
    "        print('Accuracy of logistic regression classifier on validation set: {:.2f}'.format(msv))\n",
    "\n",
    "        # print the intercept (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "        print(\"Logistic Regression: Intercept\")\n",
    "        print(lr.intercept_)\n",
    "\n",
    "        # print the coeficients (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "        print(\"Logistic Regression: Coefficients\")\n",
    "        print(lr.coef_)\n",
    "\n",
    "        print(\"Logistic Regression: Confusion Matrix\")\n",
    "        cnf_matrix_lg = confusion_matrix(y_val, y_pred)\n",
    "        print(cnf_matrix_lg)\n",
    "    \n",
    "        print(\"Logistic Regression: Classification Report\")\n",
    "        print(classification_report(y_val, y_pred))\n",
    "\n",
    "    print('AVG Accuracy of logistic regression classifier on train set: {:.2f}'.format(np.mean(model_scores_train)))\n",
    "    print('AVG Accuracy of logistic regression classifier on validation set: {:.2f}'.format(np.mean(model_scores_val)))\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "    # save model to file\n",
    "    pickle.dump(models, open(file_lr, \"wb\"))\n",
    "    print(\"Logistic Regression: End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Start\n",
      "\n",
      "Model: Logistic Regression\n",
      "Fri Dec  7 20:13:04 2018\n",
      "\n",
      "Using Stratified Kfold: 10\n",
      "Fold: 1\n",
      "\n",
      "Model: Logistic Regression\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=10,\n",
      "          penalty='l2', random_state=0, solver='saga', tol=0.0001,\n",
      "          verbose=3, warm_start=False)\n",
      "\n",
      "Logistic Regression: Fit\n",
      "convergence after 15 epochs took 31 seconds\n",
      "Logistic Regression: Predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   31.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on train set: 0.63\n",
      "Accuracy of logistic regression classifier on validation set: 0.63\n",
      "Logistic Regression: Intercept\n",
      "[0.04576488]\n",
      "Logistic Regression: Coefficients\n",
      "[[ 0.00095438 -0.00998305 -0.06217297 -0.42946142 -0.00333273 -0.04236027\n",
      "   0.0315637   0.0450024   0.19386947  0.04082231 -0.55242555  0.17658465\n",
      "  -0.14325497  0.7504041 ]]\n",
      "Logistic Regression: Confusion Matrix\n",
      "[[129192  64735]\n",
      " [ 79293 114634]]\n",
      "Logistic Regression: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.67      0.64    193927\n",
      "          1       0.64      0.59      0.61    193927\n",
      "\n",
      "avg / total       0.63      0.63      0.63    387854\n",
      "\n",
      "Fold: 2\n",
      "\n",
      "Model: Logistic Regression\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=10,\n",
      "          penalty='l2', random_state=0, solver='saga', tol=0.0001,\n",
      "          verbose=3, warm_start=False)\n",
      "\n",
      "Logistic Regression: Fit\n",
      "convergence after 16 epochs took 34 seconds\n",
      "Logistic Regression: Predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   33.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on train set: 0.63\n",
      "Accuracy of logistic regression classifier on validation set: 0.63\n",
      "Logistic Regression: Intercept\n",
      "[0.05013813]\n",
      "Logistic Regression: Coefficients\n",
      "[[ 0.00089065 -0.01029917 -0.06168978 -0.43099227 -0.00336988 -0.0415294\n",
      "   0.03150169  0.04472478  0.19434951  0.04111407 -0.55317587  0.17637422\n",
      "  -0.14284058  0.74935495]]\n",
      "Logistic Regression: Confusion Matrix\n",
      "[[128961  64966]\n",
      " [ 79312 114615]]\n",
      "Logistic Regression: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.66      0.64    193927\n",
      "          1       0.64      0.59      0.61    193927\n",
      "\n",
      "avg / total       0.63      0.63      0.63    387854\n",
      "\n",
      "Fold: 3\n",
      "\n",
      "Model: Logistic Regression\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=10,\n",
      "          penalty='l2', random_state=0, solver='saga', tol=0.0001,\n",
      "          verbose=3, warm_start=False)\n",
      "\n",
      "Logistic Regression: Fit\n",
      "convergence after 15 epochs took 31 seconds\n",
      "Logistic Regression: Predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   31.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on train set: 0.63\n",
      "Accuracy of logistic regression classifier on validation set: 0.63\n",
      "Logistic Regression: Intercept\n",
      "[0.04985382]\n",
      "Logistic Regression: Coefficients\n",
      "[[ 0.00108901 -0.0102931  -0.06145372 -0.43102029 -0.00333513 -0.04127671\n",
      "   0.0311159   0.04519123  0.1933699   0.04105674 -0.55343716  0.17619402\n",
      "  -0.14220419  0.74829508]]\n",
      "Logistic Regression: Confusion Matrix\n",
      "[[128849  65078]\n",
      " [ 78840 115087]]\n",
      "Logistic Regression: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.66      0.64    193927\n",
      "          1       0.64      0.59      0.62    193927\n",
      "\n",
      "avg / total       0.63      0.63      0.63    387854\n",
      "\n",
      "Fold: 4\n",
      "\n",
      "Model: Logistic Regression\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=10,\n",
      "          penalty='l2', random_state=0, solver='saga', tol=0.0001,\n",
      "          verbose=3, warm_start=False)\n",
      "\n",
      "Logistic Regression: Fit\n",
      "convergence after 14 epochs took 30 seconds\n",
      "Logistic Regression: Predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   29.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on train set: 0.63\n",
      "Accuracy of logistic regression classifier on validation set: 0.63\n",
      "Logistic Regression: Intercept\n",
      "[0.05302057]\n",
      "Logistic Regression: Coefficients\n",
      "[[ 0.00102491 -0.01010956 -0.06149766 -0.43092898 -0.00335661 -0.04208629\n",
      "   0.03149519  0.04512186  0.19263745  0.04099241 -0.55332555  0.17628237\n",
      "  -0.1438324   0.74862796]]\n",
      "Logistic Regression: Confusion Matrix\n",
      "[[129362  64565]\n",
      " [ 79364 114563]]\n",
      "Logistic Regression: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.67      0.64    193927\n",
      "          1       0.64      0.59      0.61    193927\n",
      "\n",
      "avg / total       0.63      0.63      0.63    387854\n",
      "\n",
      "Fold: 5\n",
      "\n",
      "Model: Logistic Regression\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=10,\n",
      "          penalty='l2', random_state=0, solver='saga', tol=0.0001,\n",
      "          verbose=3, warm_start=False)\n",
      "\n",
      "Logistic Regression: Fit\n",
      "convergence after 15 epochs took 32 seconds\n",
      "Logistic Regression: Predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   31.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on train set: 0.63\n",
      "Accuracy of logistic regression classifier on validation set: 0.63\n",
      "Logistic Regression: Intercept\n",
      "[0.0506881]\n",
      "Logistic Regression: Coefficients\n",
      "[[ 0.00098631 -0.00989385 -0.06156148 -0.43117492 -0.00337184 -0.04114844\n",
      "   0.03086232  0.0454345   0.19401041  0.04098624 -0.55361211  0.17581114\n",
      "  -0.14291931  0.74912311]]\n",
      "Logistic Regression: Confusion Matrix\n",
      "[[129158  64769]\n",
      " [ 79351 114576]]\n",
      "Logistic Regression: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.67      0.64    193927\n",
      "          1       0.64      0.59      0.61    193927\n",
      "\n",
      "avg / total       0.63      0.63      0.63    387854\n",
      "\n",
      "Fold: 6\n",
      "\n",
      "Model: Logistic Regression\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=10,\n",
      "          penalty='l2', random_state=0, solver='saga', tol=0.0001,\n",
      "          verbose=3, warm_start=False)\n",
      "\n",
      "Logistic Regression: Fit\n",
      "convergence after 15 epochs took 32 seconds\n",
      "Logistic Regression: Predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   31.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on train set: 0.63\n",
      "Accuracy of logistic regression classifier on validation set: 0.63\n",
      "Logistic Regression: Intercept\n",
      "[0.05157121]\n",
      "Logistic Regression: Coefficients\n",
      "[[ 0.00105357 -0.00964278 -0.06169014 -0.42987344 -0.00336007 -0.04157123\n",
      "   0.03121015  0.04514742  0.19245648  0.04097728 -0.55380319  0.17576076\n",
      "  -0.1440211   0.748921  ]]\n",
      "Logistic Regression: Confusion Matrix\n",
      "[[129293  64634]\n",
      " [ 78908 115019]]\n",
      "Logistic Regression: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.67      0.64    193927\n",
      "          1       0.64      0.59      0.62    193927\n",
      "\n",
      "avg / total       0.63      0.63      0.63    387854\n",
      "\n",
      "Fold: 7\n",
      "\n",
      "Model: Logistic Regression\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=10,\n",
      "          penalty='l2', random_state=0, solver='saga', tol=0.0001,\n",
      "          verbose=3, warm_start=False)\n",
      "\n",
      "Logistic Regression: Fit\n",
      "convergence after 15 epochs took 32 seconds\n",
      "Logistic Regression: Predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   32.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on train set: 0.63\n",
      "Accuracy of logistic regression classifier on validation set: 0.63\n",
      "Logistic Regression: Intercept\n",
      "[0.04773842]\n",
      "Logistic Regression: Coefficients\n",
      "[[ 0.001064   -0.01030355 -0.06071626 -0.43114926 -0.00335213 -0.04235468\n",
      "   0.03101758  0.0447755   0.19447677  0.04112738 -0.55285522  0.17621883\n",
      "  -0.1458242   0.75154912]]\n",
      "Logistic Regression: Confusion Matrix\n",
      "[[128785  65142]\n",
      " [ 79284 114643]]\n",
      "Logistic Regression: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.66      0.64    193927\n",
      "          1       0.64      0.59      0.61    193927\n",
      "\n",
      "avg / total       0.63      0.63      0.63    387854\n",
      "\n",
      "Fold: 8\n",
      "\n",
      "Model: Logistic Regression\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=10,\n",
      "          penalty='l2', random_state=0, solver='saga', tol=0.0001,\n",
      "          verbose=3, warm_start=False)\n",
      "\n",
      "Logistic Regression: Fit\n",
      "convergence after 14 epochs took 29 seconds\n",
      "Logistic Regression: Predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   29.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on train set: 0.63\n",
      "Accuracy of logistic regression classifier on validation set: 0.63\n",
      "Logistic Regression: Intercept\n",
      "[0.04382782]\n",
      "Logistic Regression: Coefficients\n",
      "[[ 0.00113226 -0.01038706 -0.06085607 -0.42984322 -0.00330198 -0.04164114\n",
      "   0.03099876  0.04532493  0.19323669  0.0411025  -0.55387355  0.17648542\n",
      "  -0.14229189  0.7490564 ]]\n",
      "Logistic Regression: Confusion Matrix\n",
      "[[129435  64492]\n",
      " [ 79241 114686]]\n",
      "Logistic Regression: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.67      0.64    193927\n",
      "          1       0.64      0.59      0.61    193927\n",
      "\n",
      "avg / total       0.63      0.63      0.63    387854\n",
      "\n",
      "Fold: 9\n",
      "\n",
      "Model: Logistic Regression\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=10,\n",
      "          penalty='l2', random_state=0, solver='saga', tol=0.0001,\n",
      "          verbose=3, warm_start=False)\n",
      "\n",
      "Logistic Regression: Fit\n",
      "convergence after 14 epochs took 29 seconds\n",
      "Logistic Regression: Predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   29.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on train set: 0.63\n",
      "Accuracy of logistic regression classifier on validation set: 0.63\n",
      "Logistic Regression: Intercept\n",
      "[0.04627982]\n",
      "Logistic Regression: Coefficients\n",
      "[[ 0.00096166 -0.01036014 -0.06157487 -0.42962562 -0.00335257 -0.04228044\n",
      "   0.03163171  0.04472327  0.1932632   0.04093215 -0.55163691  0.17630661\n",
      "  -0.14343212  0.75020885]]\n",
      "Logistic Regression: Confusion Matrix\n",
      "[[129560  64366]\n",
      " [ 79391 114535]]\n",
      "Logistic Regression: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.67      0.64    193926\n",
      "          1       0.64      0.59      0.61    193926\n",
      "\n",
      "avg / total       0.63      0.63      0.63    387852\n",
      "\n",
      "Fold: 10\n",
      "\n",
      "Model: Logistic Regression\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=10,\n",
      "          penalty='l2', random_state=0, solver='saga', tol=0.0001,\n",
      "          verbose=3, warm_start=False)\n",
      "\n",
      "Logistic Regression: Fit\n",
      "convergence after 15 epochs took 32 seconds\n",
      "Logistic Regression: Predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   31.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on train set: 0.63\n",
      "Accuracy of logistic regression classifier on validation set: 0.63\n",
      "Logistic Regression: Intercept\n",
      "[0.04714239]\n",
      "Logistic Regression: Coefficients\n",
      "[[ 6.93809325e-04 -1.04109404e-02 -6.11208849e-02 -4.30097449e-01\n",
      "  -3.38960347e-03 -4.02136947e-02  3.15704008e-02  4.51577526e-02\n",
      "   1.93960781e-01  4.08899195e-02 -5.52811195e-01  1.76115812e-01\n",
      "  -1.43057777e-01  7.49398909e-01]]\n",
      "Logistic Regression: Confusion Matrix\n",
      "[[129312  64614]\n",
      " [ 79387 114539]]\n",
      "Logistic Regression: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.67      0.64    193926\n",
      "          1       0.64      0.59      0.61    193926\n",
      "\n",
      "avg / total       0.63      0.63      0.63    387852\n",
      "\n",
      "AVG Accuracy of logistic regression classifier on train set: 0.63\n",
      "AVG Accuracy of logistic regression classifier on validation set: 0.63\n",
      "Fri Dec  7 20:18:58 2018\n",
      "Logistic Regression: End\n"
     ]
    }
   ],
   "source": [
    "if (True):    \n",
    "    seed = 101\n",
    "    print(\"Logistic Regression: Start\")\n",
    "    t_start =  time.time()\n",
    "    print()\n",
    "    print(\"Model: Logistic Regression\")\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print()\n",
    "    print(\"Using Stratified Kfold: {}\".format(nfold))\n",
    "    \n",
    "    models = []\n",
    "    model_scores_train = []\n",
    "    model_scores_val = []\n",
    "    \n",
    "    X_kfold = np.array(X)\n",
    "    Y_kfold = np.array(Y)\n",
    "    \n",
    "    skf = model_selection.StratifiedKFold(n_splits=nfold, shuffle=True, random_state=seed)    \n",
    "    i = 0\n",
    "    for train_index, val_index in skf.split(X_kfold, Y_kfold):\n",
    "        i = i+1\n",
    "        print(\"Fold: {}\".format(i))\n",
    "        \n",
    "        X_train, X_val = X_kfold[train_index], X_kfold[val_index]\n",
    "        y_train, y_val = Y_kfold[train_index], Y_kfold[val_index]\n",
    "        \n",
    "        lr = LogisticRegression(C=1, random_state=0, solver='saga', multi_class='ovr', \n",
    "                            verbose=verbose_level, n_jobs=10, max_iter=model_max_iter)\n",
    "        print()\n",
    "        print(\"Model: Logistic Regression\")\n",
    "        print(lr)\n",
    "        print()\n",
    "        print(\"Logistic Regression: Fit\")\n",
    "        lr.fit(X_train, y_train)\n",
    "\n",
    "        #add model for list\n",
    "        models.append(lr)\n",
    "\n",
    "        print(\"Logistic Regression: Predict\")\n",
    "        y_pred = lr.predict(X_val)\n",
    "\n",
    "        mst = lr.score(X_train, y_train)\n",
    "        model_scores_train.append(mst)\n",
    "        \n",
    "        msv = lr.score(X_val, y_val)\n",
    "        model_scores_val.append(msv)\n",
    "        \n",
    "        print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(mst))\n",
    "        print('Accuracy of logistic regression classifier on validation set: {:.2f}'.format(msv))\n",
    "\n",
    "        # print the intercept (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "        print(\"Logistic Regression: Intercept\")\n",
    "        print(lr.intercept_)\n",
    "\n",
    "        # print the coeficients (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "        print(\"Logistic Regression: Coefficients\")\n",
    "        print(lr.coef_)\n",
    "\n",
    "        print(\"Logistic Regression: Confusion Matrix\")\n",
    "        cnf_matrix_lg = confusion_matrix(y_val, y_pred)\n",
    "        print(cnf_matrix_lg)\n",
    "    \n",
    "        print(\"Logistic Regression: Classification Report\")\n",
    "        print(classification_report(y_val, y_pred))\n",
    "\n",
    "    print('AVG Accuracy of logistic regression classifier on train set: {:.2f}'.format(np.mean(model_scores_train)))\n",
    "    print('AVG Accuracy of logistic regression classifier on validation set: {:.2f}'.format(np.mean(model_scores_val)))\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "    # save model to file\n",
    "    pickle.dump(models, open(file_lr, \"wb\"))\n",
    "    print(\"Logistic Regression: End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Predict on test set\n",
      "Accuracy of logistic regression classifier on test set: 0.62\n",
      "Logistic Regression: Intercept\n",
      "[0.04576488]\n",
      "Logistic Regression: Coefficients\n",
      "[[ 0.00095438 -0.00998305 -0.06217297 -0.42946142 -0.00333273 -0.04236027\n",
      "   0.0315637   0.0450024   0.19386947  0.04082231 -0.55242555  0.17658465\n",
      "  -0.14325497  0.7504041 ]]\n",
      "Logistic Regression: Confusion Matrix\n",
      "[[406751 206980]\n",
      " [339165 491950]]\n",
      "Logistic Regression: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.66      0.60    613731\n",
      "          1       0.70      0.59      0.64    831115\n",
      "\n",
      "avg / total       0.64      0.62      0.62   1444846\n",
      "\n",
      "Accuracy of logistic regression classifier on test set: 0.62\n",
      "Logistic Regression: Intercept\n",
      "[0.05013813]\n",
      "Logistic Regression: Coefficients\n",
      "[[ 0.00089065 -0.01029917 -0.06168978 -0.43099227 -0.00336988 -0.0415294\n",
      "   0.03150169  0.04472478  0.19434951  0.04111407 -0.55317587  0.17637422\n",
      "  -0.14284058  0.74935495]]\n",
      "Logistic Regression: Confusion Matrix\n",
      "[[406663 207068]\n",
      " [338885 492230]]\n",
      "Logistic Regression: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.66      0.60    613731\n",
      "          1       0.70      0.59      0.64    831115\n",
      "\n",
      "avg / total       0.64      0.62      0.62   1444846\n",
      "\n",
      "Accuracy of logistic regression classifier on test set: 0.62\n",
      "Logistic Regression: Intercept\n",
      "[0.04985382]\n",
      "Logistic Regression: Coefficients\n",
      "[[ 0.00108901 -0.0102931  -0.06145372 -0.43102029 -0.00333513 -0.04127671\n",
      "   0.0311159   0.04519123  0.1933699   0.04105674 -0.55343716  0.17619402\n",
      "  -0.14220419  0.74829508]]\n",
      "Logistic Regression: Confusion Matrix\n",
      "[[406614 207117]\n",
      " [338846 492269]]\n",
      "Logistic Regression: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.66      0.60    613731\n",
      "          1       0.70      0.59      0.64    831115\n",
      "\n",
      "avg / total       0.64      0.62      0.62   1444846\n",
      "\n",
      "Accuracy of logistic regression classifier on test set: 0.62\n",
      "Logistic Regression: Intercept\n",
      "[0.05302057]\n",
      "Logistic Regression: Coefficients\n",
      "[[ 0.00102491 -0.01010956 -0.06149766 -0.43092898 -0.00335661 -0.04208629\n",
      "   0.03149519  0.04512186  0.19263745  0.04099241 -0.55332555  0.17628237\n",
      "  -0.1438324   0.74862796]]\n",
      "Logistic Regression: Confusion Matrix\n",
      "[[406726 207005]\n",
      " [338914 492201]]\n",
      "Logistic Regression: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.66      0.60    613731\n",
      "          1       0.70      0.59      0.64    831115\n",
      "\n",
      "avg / total       0.64      0.62      0.62   1444846\n",
      "\n",
      "Accuracy of logistic regression classifier on test set: 0.62\n",
      "Logistic Regression: Intercept\n",
      "[0.0506881]\n",
      "Logistic Regression: Coefficients\n",
      "[[ 0.00098631 -0.00989385 -0.06156148 -0.43117492 -0.00337184 -0.04114844\n",
      "   0.03086232  0.0454345   0.19401041  0.04098624 -0.55361211  0.17581114\n",
      "  -0.14291931  0.74912311]]\n",
      "Logistic Regression: Confusion Matrix\n",
      "[[406808 206923]\n",
      " [339093 492022]]\n",
      "Logistic Regression: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.66      0.60    613731\n",
      "          1       0.70      0.59      0.64    831115\n",
      "\n",
      "avg / total       0.64      0.62      0.62   1444846\n",
      "\n",
      "Accuracy of logistic regression classifier on test set: 0.62\n",
      "Logistic Regression: Intercept\n",
      "[0.05157121]\n",
      "Logistic Regression: Coefficients\n",
      "[[ 0.00105357 -0.00964278 -0.06169014 -0.42987344 -0.00336007 -0.04157123\n",
      "   0.03121015  0.04514742  0.19245648  0.04097728 -0.55380319  0.17576076\n",
      "  -0.1440211   0.748921  ]]\n",
      "Logistic Regression: Confusion Matrix\n",
      "[[406839 206892]\n",
      " [339048 492067]]\n",
      "Logistic Regression: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.66      0.60    613731\n",
      "          1       0.70      0.59      0.64    831115\n",
      "\n",
      "avg / total       0.64      0.62      0.62   1444846\n",
      "\n",
      "Accuracy of logistic regression classifier on test set: 0.62\n",
      "Logistic Regression: Intercept\n",
      "[0.04773842]\n",
      "Logistic Regression: Coefficients\n",
      "[[ 0.001064   -0.01030355 -0.06071626 -0.43114926 -0.00335213 -0.04235468\n",
      "   0.03101758  0.0447755   0.19447677  0.04112738 -0.55285522  0.17621883\n",
      "  -0.1458242   0.75154912]]\n",
      "Logistic Regression: Confusion Matrix\n",
      "[[406802 206929]\n",
      " [339099 492016]]\n",
      "Logistic Regression: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.66      0.60    613731\n",
      "          1       0.70      0.59      0.64    831115\n",
      "\n",
      "avg / total       0.64      0.62      0.62   1444846\n",
      "\n",
      "Accuracy of logistic regression classifier on test set: 0.62\n",
      "Logistic Regression: Intercept\n",
      "[0.04382782]\n",
      "Logistic Regression: Coefficients\n",
      "[[ 0.00113226 -0.01038706 -0.06085607 -0.42984322 -0.00330198 -0.04164114\n",
      "   0.03099876  0.04532493  0.19323669  0.0411025  -0.55387355  0.17648542\n",
      "  -0.14229189  0.7490564 ]]\n",
      "Logistic Regression: Confusion Matrix\n",
      "[[406701 207030]\n",
      " [338968 492147]]\n",
      "Logistic Regression: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.66      0.60    613731\n",
      "          1       0.70      0.59      0.64    831115\n",
      "\n",
      "avg / total       0.64      0.62      0.62   1444846\n",
      "\n",
      "Accuracy of logistic regression classifier on test set: 0.62\n",
      "Logistic Regression: Intercept\n",
      "[0.04627982]\n",
      "Logistic Regression: Coefficients\n",
      "[[ 0.00096166 -0.01036014 -0.06157487 -0.42962562 -0.00335257 -0.04228044\n",
      "   0.03163171  0.04472327  0.1932632   0.04093215 -0.55163691  0.17630661\n",
      "  -0.14343212  0.75020885]]\n",
      "Logistic Regression: Confusion Matrix\n",
      "[[406956 206775]\n",
      " [339425 491690]]\n",
      "Logistic Regression: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.66      0.60    613731\n",
      "          1       0.70      0.59      0.64    831115\n",
      "\n",
      "avg / total       0.64      0.62      0.62   1444846\n",
      "\n",
      "Accuracy of logistic regression classifier on test set: 0.62\n",
      "Logistic Regression: Intercept\n",
      "[0.04714239]\n",
      "Logistic Regression: Coefficients\n",
      "[[ 6.93809325e-04 -1.04109404e-02 -6.11208849e-02 -4.30097449e-01\n",
      "  -3.38960347e-03 -4.02136947e-02  3.15704008e-02  4.51577526e-02\n",
      "   1.93960781e-01  4.08899195e-02 -5.52811195e-01  1.76115812e-01\n",
      "  -1.43057777e-01  7.49398909e-01]]\n",
      "Logistic Regression: Confusion Matrix\n",
      "[[406829 206902]\n",
      " [339156 491959]]\n",
      "Logistic Regression: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.66      0.60    613731\n",
      "          1       0.70      0.59      0.64    831115\n",
      "\n",
      "avg / total       0.64      0.62      0.62   1444846\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## for each model generated, lets predict the on test set\n",
    "## note, this is the first time any of these observations are seen by the model\n",
    "# load model from file\n",
    "loaded_model = pickle.load(open(file_lr, \"rb\"))\n",
    "print(\"Logistic Regression: Predict on test set\")\n",
    "\n",
    "i = 0\n",
    "for model in loaded_model:\n",
    "    i = i + 1\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(model.score(X_test, Y_test)))\n",
    "\n",
    "    # print the intercept (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "    print(\"Logistic Regression: Intercept\")\n",
    "    print(model.intercept_)\n",
    "\n",
    "    # print the coeficients (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "    print(\"Logistic Regression: Coefficients\")\n",
    "    print(model.coef_)\n",
    "\n",
    "    print(\"Logistic Regression: Confusion Matrix\")\n",
    "    cnf_matrix_lg = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_lg)\n",
    "    \n",
    "    print(\"Logistic Regression: Classification Report\")\n",
    "    print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Start\n",
      "\n",
      "Model: Logistic Regression\n",
      "Fri Dec  7 20:19:27 2018\n",
      "\n",
      "Using Kfold: 10\n",
      "\n",
      "Model: Logistic Regression\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=10,\n",
      "          penalty='l2', random_state=0, solver='saga', tol=0.0001,\n",
      "          verbose=3, warm_start=False)\n",
      "\n",
      "Logistic Regression: Fit\n",
      "convergence after 15 epochs took 31 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   31.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 16 epochs took 34 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   33.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 15 epochs took 32 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   31.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 15 epochs took 33 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   32.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 15 epochs took 32 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   31.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 15 epochs took 32 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   31.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 15 epochs took 31 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   31.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 16 epochs took 34 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   34.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 15 epochs took 31 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   31.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 15 epochs took 32 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   31.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6099698316722773\n",
      "[0.6178923  0.61885142 0.61766025 0.61714975 0.61933614 0.61787425\n",
      " 0.61912116 0.61704563 0.63146862 0.52329878]\n",
      "Fri Dec  7 20:25:17 2018\n",
      "Logistic Regression: End\n"
     ]
    }
   ],
   "source": [
    "if enable_lr:\n",
    "    seed = 101\n",
    "    print(\"Logistic Regression: Start\")\n",
    "    t_start =  time.time()\n",
    "    print()\n",
    "    print(\"Model: Logistic Regression\")\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print()\n",
    "    print(\"Using Kfold: {}\".format(nfold))\n",
    "    kfold = model_selection.KFold(n_splits=nfold, random_state=seed)\n",
    "    \n",
    "    lr = LogisticRegression(C=1, random_state=0, solver='saga', multi_class='ovr', \n",
    "                            verbose=verbose_level, n_jobs=10, max_iter=model_max_iter)\n",
    "    print()\n",
    "    print(\"Model: Logistic Regression\")\n",
    "    print(lr)\n",
    "    print()\n",
    "    print(\"Logistic Regression: Fit\")\n",
    "    results = model_selection.cross_val_score(lr, X, Y, cv=kfold)\n",
    "    #lr.fit(X_train, Y_train)\n",
    "    \n",
    "    print(results.mean())\n",
    "    print(results)\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"Logistic Regression: End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
