{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CKME136X10 2018 Initial Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import requried libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rand\n",
    "\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns=25\n",
    "\n",
    "inputfile = 'NCDB_1999_to_2016.csv'\n",
    "outputfile = 'CKME136X10_2018_Initial_Data_Cleaned.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(inputfile, engine = 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## inspect the imported data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display the first few rows of the data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_YEAR</th>\n",
       "      <th>C_MNTH</th>\n",
       "      <th>C_WDAY</th>\n",
       "      <th>C_HOUR</th>\n",
       "      <th>C_SEV</th>\n",
       "      <th>C_VEHS</th>\n",
       "      <th>C_CONF</th>\n",
       "      <th>C_RCFG</th>\n",
       "      <th>C_WTHR</th>\n",
       "      <th>C_RSUR</th>\n",
       "      <th>C_RALN</th>\n",
       "      <th>C_TRAF</th>\n",
       "      <th>V_ID</th>\n",
       "      <th>V_TYPE</th>\n",
       "      <th>V_YEAR</th>\n",
       "      <th>P_ID</th>\n",
       "      <th>P_SEX</th>\n",
       "      <th>P_AGE</th>\n",
       "      <th>P_PSN</th>\n",
       "      <th>P_ISEV</th>\n",
       "      <th>P_SAFE</th>\n",
       "      <th>P_USER</th>\n",
       "      <th>C_CASE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>02</td>\n",
       "      <td>34</td>\n",
       "      <td>UU</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>03</td>\n",
       "      <td>01</td>\n",
       "      <td>06</td>\n",
       "      <td>1990</td>\n",
       "      <td>01</td>\n",
       "      <td>M</td>\n",
       "      <td>41</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>UU</td>\n",
       "      <td>1</td>\n",
       "      <td>752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>02</td>\n",
       "      <td>34</td>\n",
       "      <td>UU</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>03</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>1987</td>\n",
       "      <td>01</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>UU</td>\n",
       "      <td>1</td>\n",
       "      <td>752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>02</td>\n",
       "      <td>34</td>\n",
       "      <td>UU</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>03</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>1987</td>\n",
       "      <td>02</td>\n",
       "      <td>F</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>02</td>\n",
       "      <td>2</td>\n",
       "      <td>752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>08</td>\n",
       "      <td>2</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>UU</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>1986</td>\n",
       "      <td>01</td>\n",
       "      <td>M</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>UU</td>\n",
       "      <td>1</td>\n",
       "      <td>753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>08</td>\n",
       "      <td>2</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>UU</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>99</td>\n",
       "      <td>NN</td>\n",
       "      <td>NNNN</td>\n",
       "      <td>01</td>\n",
       "      <td>M</td>\n",
       "      <td>05</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>UU</td>\n",
       "      <td>3</td>\n",
       "      <td>753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_YEAR C_MNTH C_WDAY C_HOUR  C_SEV C_VEHS C_CONF C_RCFG C_WTHR C_RSUR  \\\n",
       "0    1999     01      1     20      2     02     34     UU      1      5   \n",
       "1    1999     01      1     20      2     02     34     UU      1      5   \n",
       "2    1999     01      1     20      2     02     34     UU      1      5   \n",
       "3    1999     01      1     08      2     01     01     UU      5      3   \n",
       "4    1999     01      1     08      2     01     01     UU      5      3   \n",
       "\n",
       "  C_RALN C_TRAF V_ID V_TYPE V_YEAR P_ID P_SEX P_AGE P_PSN P_ISEV P_SAFE  \\\n",
       "0      3     03   01     06   1990   01     M    41    11      1     UU   \n",
       "1      3     03   02     01   1987   01     M    19    11      1     UU   \n",
       "2      3     03   02     01   1987   02     F    20    13      2     02   \n",
       "3      6     18   01     01   1986   01     M    46    11      1     UU   \n",
       "4      6     18   99     NN   NNNN   01     M    05    99      2     UU   \n",
       "\n",
       "  P_USER  C_CASE  \n",
       "0      1     752  \n",
       "1      1     752  \n",
       "2      2     752  \n",
       "3      1     753  \n",
       "4      3     753  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Rows: 6486831\n",
      "Number of Columns: 23\n",
      "\n",
      "Column Names: ['C_YEAR' 'C_MNTH' 'C_WDAY' 'C_HOUR' 'C_SEV' 'C_VEHS' 'C_CONF' 'C_RCFG'\n",
      " 'C_WTHR' 'C_RSUR' 'C_RALN' 'C_TRAF' 'V_ID' 'V_TYPE' 'V_YEAR' 'P_ID'\n",
      " 'P_SEX' 'P_AGE' 'P_PSN' 'P_ISEV' 'P_SAFE' 'P_USER' 'C_CASE']\n",
      "\n",
      "Information on the imported data\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6486831 entries, 0 to 6486830\n",
      "Data columns (total 23 columns):\n",
      "C_YEAR    int64\n",
      "C_MNTH    object\n",
      "C_WDAY    object\n",
      "C_HOUR    object\n",
      "C_SEV     int64\n",
      "C_VEHS    object\n",
      "C_CONF    object\n",
      "C_RCFG    object\n",
      "C_WTHR    object\n",
      "C_RSUR    object\n",
      "C_RALN    object\n",
      "C_TRAF    object\n",
      "V_ID      object\n",
      "V_TYPE    object\n",
      "V_YEAR    object\n",
      "P_ID      object\n",
      "P_SEX     object\n",
      "P_AGE     object\n",
      "P_PSN     object\n",
      "P_ISEV    object\n",
      "P_SAFE    object\n",
      "P_USER    object\n",
      "C_CASE    int64\n",
      "dtypes: int64(3), object(20)\n",
      "memory usage: 1.1+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Display the first few rows of the data')\n",
    "display(df.head())\n",
    "print()\n",
    "print('Number of Rows: {}'.format(df.shape[0]))\n",
    "print('Number of Columns: {}'.format(df.shape[1]))\n",
    "print()\n",
    "print('Column Names: {}'.format(df.columns.values))\n",
    "print()\n",
    "print('Information on the imported data')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify and drop variables which will not add values to our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop Collition Serverity\n",
    "#For future prediction, this value will not be available. Thus remove it.\n",
    "df.drop(columns = ['C_SEV'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop Collition Case number\n",
    "#For future prediction, this value will not be available. Thus remove it.\n",
    "df.drop(columns = ['C_CASE'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop Vehicle Sequence Number\n",
    "#We have no means to determine how the order of the vehicles were determined.\n",
    "df.drop(columns = ['V_ID'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop Person Sequence Number\n",
    "#We have no means to determine how the sequence number was identified.\n",
    "df.drop(columns = ['P_ID'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping V_YEAR, it will be dropped after EDA, as it should not add value for future prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move Dependent variable to the end of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move the dependent variable to the outside and drop C_CASE column\n",
    "P_ISEV = df['P_ISEV']\n",
    "df.drop(columns = ['P_ISEV'], inplace = True)\n",
    "df['P_ISEV'] = P_ISEV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check the number of missing values for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column name and the number of missing values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "C_YEAR          0\n",
       "C_MNTH        403\n",
       "C_WDAY       1342\n",
       "C_HOUR      64175\n",
       "C_VEHS        541\n",
       "C_CONF     516941\n",
       "C_RCFG     697843\n",
       "C_WTHR     111905\n",
       "C_RSUR     267289\n",
       "C_RALN     495711\n",
       "C_TRAF     342634\n",
       "V_TYPE     316543\n",
       "V_YEAR     641842\n",
       "P_SEX     6486831\n",
       "P_AGE      440815\n",
       "P_PSN      128099\n",
       "P_SAFE    1371966\n",
       "P_USER     210115\n",
       "P_ISEV     417421\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note, in our dataset, missing values will be non numeric\n",
    "print('Column name and the number of missing values')\n",
    "\n",
    "df[df.columns].apply(lambda x: x.astype(str).str.contains('[^0-9]')).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify non human entries and remove them from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Person Injury Severity is what we are predicting.  Lets treat the missing values for this column first\n",
    "# lets remove all missing values from this column, as this is what we are trying to predict.\n",
    "to_drop = df['P_ISEV'].isin(['N', 'U', 'X'])\n",
    "df.drop(df.index[to_drop], inplace = True)\n",
    "df = df.reset_index(drop=True)\n",
    "df['P_ISEV'].isin(['N', 'U', 'X']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P_SEX, we are concerned with injuries to people.  Assuming all human beings have been classified as\n",
    "# male or female, we will remove all rows which does not match male or female.\n",
    "to_drop = df['P_SEX'].isin(['N', 'U', 'X'])\n",
    "df.drop(df.index[to_drop], inplace = True)\n",
    "df = df.reset_index(drop=True)\n",
    "df['P_SEX'].isin(['N', 'U', 'X']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P_AGE, Lets assume anyone without age assigned is non-human and remove it from the dataset\n",
    "to_drop = df['P_AGE'].isin(['NN', 'UU', 'XX'])\n",
    "df.drop(df.index[to_drop], inplace = True)\n",
    "df = df.reset_index(drop=True)\n",
    "df['P_AGE'].isin(['NN', 'UU', 'XX']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Person's possition P_PSN, an other good indicator to identify non humman objects\n",
    "# first replace QQ to other categor (Choice is other than the preceding value), map to 100\n",
    "df['P_PSN'].replace(to_replace = 'QQ', value = '100', inplace = True)\n",
    "# drop the remaining missing values\n",
    "to_drop = df['P_PSN'].isin(['NN', 'UU', 'XX'])\n",
    "df.drop(df.index[to_drop], inplace = True)\n",
    "df = df.reset_index(drop=True)\n",
    "df['P_PSN'].isin(['NN', 'UU', 'XX']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Road User Class (P_USER), an other good indicator for non human objects\n",
    "to_drop = df['P_USER'].isin(['U'])\n",
    "df.drop(df.index[to_drop], inplace = True)\n",
    "df = df.reset_index(drop=True)\n",
    "df['P_USER'].isin(['U']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-340808401b61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# P_SAFE, safty device used provides a good indicaiton if an observation was user or dummy variable.  Lets remove the dummy variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mto_drop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'P_SAFE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'UU'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'XX'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mto_drop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'P_SAFE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'UU'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'XX'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# P_SAFE, safty device used provides a good indicaiton if an observation was user or dummy variable.  Lets remove the dummy variables\n",
    "to_drop = df['P_SAFE'].isin(['UU', 'NN', 'XX'])\n",
    "df.drop(df.index[to_drop], inplace = True)\n",
    "df = df.reset_index(drop=True)\n",
    "df['P_SAFE'].isin(['UU', 'NN', 'XX']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Missing vs Other categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C_YEAR has no non-numeric values, nothing to do here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collision Month (C_MNTH), True unknowns, handle later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collision Weekady (C_WDAY), True unknowns, handle later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collision Hour (C_HOUR), True unknowns, handle later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Vehicle in a collision (V_VEHS), True unknowns, handle later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collision Configuration (C_CONF)\n",
    "# QQ - Choice is other than the preceding values = Mark as 51 - 'Other configuraiton'\n",
    "df['C_CONF'].replace(to_replace = 'QQ', value = '51', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non numeric values in Collision Road Configuration C_RCFG is high, lets investigate\n",
    "# QQ, Choice is other than the preceding values.  Lets add this as other configuration\n",
    "# map to 13\n",
    "df['C_RCFG'].replace(to_replace = 'QQ', value = '13', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather condition (C_WTHR)\n",
    "# Q - Choice is other than the preceding values\n",
    "# Add a new category 8 for Choice is other than the preceding values\n",
    "df['C_WTHR'].replace(to_replace = 'Q', value = '8', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Road Surface Configuration C_RSUR\n",
    "# Q - Choice is other than the preceding values, map to 10\n",
    "df['C_RSUR'].replace(to_replace = 'Q', value = '10', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Road Alignmetn C_RALN\n",
    "# Q - Choice is other than the preceding values, map to 7\n",
    "df['C_RALN'].replace(to_replace = 'Q', value = '7', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traffic Control (C_TRAF)\n",
    "# QQ - Choice is other than the preceding values, map to 19\n",
    "df['C_TRAF'].replace(to_replace = 'QQ', value = '19', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vehicle Type (V_TYPE)\n",
    "# NN - Data element is not applicable, map to 24\n",
    "# QQ - Choice is other than the preceding values, map to 25\n",
    "df['V_TYPE'].replace(to_replace = 'NN', value = '24', inplace = True)\n",
    "df['V_TYPE'].replace(to_replace = 'QQ', value = '25', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900\n"
     ]
    }
   ],
   "source": [
    "# Vehicle Year (V_YEAR)\n",
    "# this variable needs to be handled with better care.  \n",
    "# NNNN - this would be for non_vehicles (people (maybe we can impute by the person age), maybe for bikes, ... )\n",
    "# lets keep this simple for now and impute the lowest value\n",
    "minYear = int(df['V_YEAR'].min()) - 1\n",
    "print(minYear)\n",
    "df['V_YEAR'].replace(to_replace = 'NNNN', value = minYear, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P_SEX, already taken care above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P_AGE, already taken care above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P_PSN, already taken care above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P_ISEV, already taken care above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column P_SAFE - Safety Device Used contains the most missing values\n",
    "# Based on the data dictionary, \n",
    "# QQ => matches non of the categories\n",
    "# NN => not applicable for the varaible\n",
    "# Both of these are not missing values and we will map them to values 15 and 16 respectably\n",
    "df['P_SAFE'].replace(to_replace = 'QQ', value = '15', inplace = True)\n",
    "df['P_SAFE'].replace(to_replace = 'NN', value = '16', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P_USER, already taken care above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map F = 0 and M = 1\n",
    "df['P_SEX'].replace(to_replace = 'F', value = '0', inplace = True)\n",
    "df['P_SEX'].replace(to_replace = 'M', value = '1', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column name and the number of missing values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "C_YEAR         0\n",
       "C_MNTH       257\n",
       "C_WDAY      1002\n",
       "C_HOUR     52732\n",
       "C_VEHS       266\n",
       "C_CONF    153958\n",
       "C_RCFG    472938\n",
       "C_WTHR     74661\n",
       "C_RSUR     67277\n",
       "C_RALN    421284\n",
       "C_TRAF    202555\n",
       "V_TYPE         0\n",
       "V_YEAR    195057\n",
       "P_SEX          0\n",
       "P_AGE          0\n",
       "P_PSN          0\n",
       "P_SAFE    460784\n",
       "P_USER         0\n",
       "P_ISEV         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note, in our dataset, missing values will be non numeric\n",
    "print('Column name and the number of missing values')\n",
    "\n",
    "df[df.columns].apply(lambda x: x.astype(str).str.contains('[^0-9]')).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_YEAR\n",
      "[1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012\n",
      " 2013 2014 2015 2016]\n",
      "C_MNTH\n",
      "['01' '02' '03' '04' '05' '06' '07' '08' '09' '10' '11' '12' 'UU']\n",
      "C_WDAY\n",
      "['1' '2' '3' '4' '5' '6' '7' 'U']\n",
      "C_HOUR\n",
      "['20' '08' '17' '15' '14' '01' '11' '13' '19' '16' '09' '02' '18' '12'\n",
      " '10' '23' '00' '06' '07' 'UU' '05' '22' '03' '21' '04']\n",
      "C_VEHS\n",
      "['02' '01' '03' '04' '07' '06' '09' '05' 'UU' '13' '08' '12' '14' '10'\n",
      " '16' '26' '71' '19' '25' '11' '21' '27' '15' '35' '22' '41' '46' '31'\n",
      " '18' '56' '23' '36' '17' '20' '29' '77' '28' '38' '32' '33' '54' '72'\n",
      " '40' '44' '58' '30' '24' '34' '39' '51' '57' '43' '37' '47']\n",
      "C_CONF\n",
      "['34' '01' '51' '04' '31' '21' '23' '03' '02' '33' 'UU' '24' '35' '41'\n",
      " '06' '32' '36' '05' '22' '25']\n",
      "C_RCFG\n",
      "['UU' '13' '01' '02' '03' '05' '04' '06' '08' '07' '09' '10']\n",
      "C_WTHR\n",
      "['1' '5' '3' '4' '7' '2' 'U' '6' '8']\n",
      "C_RSUR\n",
      "['5' '3' '2' '4' '1' '6' 'U' '10' '7' '9' '8']\n",
      "C_RALN\n",
      "['3' '6' '1' 'U' '2' '5' '4' '7']\n",
      "C_TRAF\n",
      "['03' '18' '01' 'UU' '06' '10' '05' '04' '11' '19' '07' '08' '16' '17'\n",
      " '02' '13' '15' '09' '12']\n",
      "V_TYPE\n",
      "['06' '01' '24' '11' '07' '17' '08' '09' '14' '23' '05' '18' '10' '21']\n",
      "V_YEAR\n",
      "['1990' '1987' '1986' 1900 '1984' '1991' '1997' '1993' '1985' '1988'\n",
      " '1994' '1995' '1992' '1998' '1989' 'UUUU' '1996' '1983' '1999' '1965'\n",
      " '1981' '1977' '1979' '1982' '1976' '1978' '1974' '1980' '1973' '1970'\n",
      " '1975' '1971' '1962' '1968' '1969' '2000' '1972' '1966' '1967' '1945'\n",
      " '1963' '1960' '1950' '1964' '1959' '1955' '1958' '1903' '1909' '1949'\n",
      " '1923' '1961' '1914' '1908' '1953' '1906' '1939' '1925' '1948' '1938'\n",
      " '1907' '1904' '1917' '1912' '1944' '1956' '1930' '1931' '1951' '1946'\n",
      " '1952' '1947' '1957' '1954' '1943' '1901' '1937' '1905' '1935' '1926'\n",
      " '1941' '1932' '1920' '1933' '1919' '2001' '1913' '1940' '1927' '2002'\n",
      " '1916' '1929' '1928' '1942' '1918' '2003' '1924' '1922' '1915' '1934'\n",
      " '2004' '2005' '2006' '2007' '2008' '1911' '2009' '2010' '2011' '1936'\n",
      " '2012' '1910' '1921' '2013' '2014' '2015' '2016']\n",
      "P_SEX\n",
      "['1' '0']\n",
      "P_AGE\n",
      "['41' '19' '20' '46' '05' '28' '21' '61' '56' '34' '22' '30' '49' '32'\n",
      " '31' '68' '08' '45' '17' '33' '82' '39' '37' '55' '38' '43' '35' '23'\n",
      " '25' '65' '44' '36' '70' '50' '40' '27' '26' '15' '53' '16' '13' '14'\n",
      " '18' '77' '86' '42' '24' '47' '62' '06' '57' '83' '74' '67' '51' '29'\n",
      " '01' '02' '71' '10' '63' '60' '07' '75' '64' '79' '85' '54' '93' '92'\n",
      " '52' '72' '11' '59' '48' '09' '66' '12' '76' '73' '69' '04' '78' '80'\n",
      " '84' '58' '03' '81' '89' '87' '88' '90' '91' '95' '97' '94' '99' '98'\n",
      " '96']\n",
      "P_PSN\n",
      "['11' '13' '99' '23' '21' '22' '12' '96' '32' '31' '33' '98' '97' '100']\n",
      "P_SAFE\n",
      "['UU' '02' '16' '01' '13' '12' '09' '15' '10']\n",
      "P_USER\n",
      "['1' '2' '3' '4' '5']\n",
      "P_ISEV\n",
      "['1' '2' '3']\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(col)\n",
    "    print(df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets drop the remaining unkown values\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(lambda x: str(x) if str(x).isdigit() else np.nan)\n",
    "\n",
    "df.dropna(inplace = True)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4336558, 19)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column name and the number of missing values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "C_YEAR    0\n",
       "C_MNTH    0\n",
       "C_WDAY    0\n",
       "C_HOUR    0\n",
       "C_VEHS    0\n",
       "C_CONF    0\n",
       "C_RCFG    0\n",
       "C_WTHR    0\n",
       "C_RSUR    0\n",
       "C_RALN    0\n",
       "C_TRAF    0\n",
       "V_TYPE    0\n",
       "V_YEAR    0\n",
       "P_SEX     0\n",
       "P_AGE     0\n",
       "P_PSN     0\n",
       "P_SAFE    0\n",
       "P_USER    0\n",
       "P_ISEV    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note, in our dataset, missing values will be non numeric\n",
    "print('Column name and the number of missing values')\n",
    "\n",
    "df[df.columns].apply(lambda x: x.astype(str).str.contains('[^0-9]')).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(outputfile, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
