{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 25\n",
    "pd.options.display.max_columns  = 25\n",
    "\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enable/disable feature selection\n",
    "enable_rf_features = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "datafile = 'NCDB_FULL_Removed_All_Missing_Values_Binary_Class_Transformed.csv'\n",
    "df = pd.read_csv(datafile, engine = 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3655334 entries, 0 to 3655333\n",
      "Data columns (total 17 columns):\n",
      "C_YEAR    category\n",
      "C_MNTH    category\n",
      "C_WDAY    category\n",
      "C_HOUR    category\n",
      "C_VEHS    category\n",
      "C_CONF    category\n",
      "C_RCFG    category\n",
      "C_WTHR    category\n",
      "C_RSUR    category\n",
      "C_RALN    category\n",
      "C_TRAF    category\n",
      "V_YEAR    category\n",
      "P_SEX     category\n",
      "P_AGE     int32\n",
      "P_PSN     category\n",
      "P_USER    category\n",
      "P_ISEV    category\n",
      "dtypes: category(16), int32(1)\n",
      "memory usage: 69.7 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# convert to the correct type\n",
    "df = df.astype('category')\n",
    "df['C_YEAR'] = df['C_YEAR'].astype(CategoricalDtype(ordered=True))\n",
    "df['C_MNTH'] = df['C_MNTH'].astype(CategoricalDtype(ordered=True))\n",
    "df['C_WDAY'] = df['C_WDAY'].astype(CategoricalDtype(ordered=True))\n",
    "df['C_HOUR'] = df['C_HOUR'].astype(CategoricalDtype(ordered=True))\n",
    "df['V_YEAR'] = df['V_YEAR'].astype(CategoricalDtype(ordered=True))\n",
    "df['P_AGE'] = df['P_AGE'].astype('int')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split between data and class\n",
    "# leaking data here, need to split between test and train.  TBD\n",
    "Y_ = df[df.columns[-1]]\n",
    "X_ = df[df.columns[0:df.columns.size -1]]\n",
    "\n",
    "#sprint into train and test 70/30\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection by Chi Squre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1954.24907601    322.28755297    459.50289494   5433.78874556\n",
      "  23709.83745052 173018.38553879   5373.5707024    4428.12342496\n",
      "  11645.96187121  12554.83844127  62895.38506861   1159.95293739\n",
      "  40816.98463318 105952.64089518   2213.69538156    543.39109637]\n",
      "['C_CONF', 'P_AGE', 'C_TRAF', 'P_SEX', 'C_VEHS', 'C_RALN', 'C_RSUR', 'C_HOUR', 'C_RCFG', 'C_WTHR', 'P_PSN', 'C_YEAR']\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction with Univariate Statistical Tests (Chi-squared for classification)\n",
    "# Ref: https://machinelearningmastery.com/feature-selection-machine-learning-python/\n",
    "np.set_printoptions(edgeitems=12)\n",
    "tcd_as_array = df.values\n",
    "X = tcd_as_array[:,0:tcd_as_array.shape[1] -1]\n",
    "Y = tcd_as_array[:,tcd_as_array.shape[1] -1]\n",
    "Y=Y.astype('int')\n",
    "\n",
    "# feature extraction\n",
    "test = SelectKBest(score_func=chi2, k=12)\n",
    "fit = test.fit(X, Y)\n",
    "\n",
    "# summarize scores\n",
    "#np.set_printoptions(precision=3)\n",
    "print(fit.scores_)\n",
    "t1 = np.array(fit.scores_).tolist()\n",
    "t2 = t1.copy()\n",
    "#t2 = [ '%.3f' % elem for elem in t2 ]\n",
    "t2.sort(reverse=True)\n",
    "\n",
    "chi_feature = []\n",
    "for i in range(0, X.shape[1]):\n",
    "    chi_feature.append(df.columns[t1.index(t2[i])])\n",
    "    #print(\"{}\".format(df.columns[t1.index(t2[i])]))\n",
    "\n",
    "#np.set_printoptions(precision=3)\n",
    "features = fit.transform(X)\n",
    "# summarize selected features\n",
    "#print(features[0:11,:])\n",
    "print(chi_feature[0:12])\n",
    "\n",
    "#[C_HOUR, C_VEHS, C_CONF, C_RCFG, C_WTHR, C_RSUR, C_RALN, C_TRAF, P_SEX, P_AGE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction: Recursive Feature Elimination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 12\n",
      "Selected Features: [False False  True  True  True False  True  True  True  True  True  True\n",
      "  True False  True  True]\n",
      "Selected Features: Index(['C_WDAY', 'C_HOUR', 'C_VEHS', 'C_RCFG', 'C_WTHR', 'C_RSUR', 'C_RALN',\n",
      "       'C_TRAF', 'V_YEAR', 'P_SEX', 'P_PSN', 'P_USER'],\n",
      "      dtype='object')\n",
      "Feature Ranking: [5 4 1 1 1 2 1 1 1 1 1 1 1 3 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction with RFE\n",
    "\n",
    "# feature extraction\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 12)\n",
    "fit = rfe.fit(X_, Y_)\n",
    "print(\"Num Features: {}\".format(fit.n_features_))\n",
    "print(\"Selected Features: {}\".format(fit.support_))\n",
    "print(\"Selected Features: {}\".format(X_.columns[fit.support_]))\n",
    "print(\"Feature Ranking: {}\".format(fit.ranking_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction: Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15093099 0.12915253 0.09491015 0.04921887 0.02688118 0.07549055\n",
      " 0.02297781 0.02534752 0.02230674 0.02775081 0.03268589 0.02954307\n",
      " 0.02928058 0.2546498  0.00921362 0.01965989]\n",
      "[13  0  1  2  5  3 10 11 12  9  4  7  6  8 15 14]\n",
      "Index(['C_YEAR', 'C_MNTH', 'C_WDAY', 'C_HOUR', 'C_VEHS', 'C_CONF', 'C_RCFG',\n",
      "       'C_WTHR', 'C_RSUR', 'C_RALN', 'C_TRAF', 'V_YEAR', 'P_SEX', 'P_AGE',\n",
      "       'P_PSN', 'P_USER'],\n",
      "      dtype='object')\n",
      " 1) P_AGE                          0.254650\n",
      " 2) C_YEAR                         0.150931\n",
      " 3) C_MNTH                         0.129153\n",
      " 4) C_WDAY                         0.094910\n",
      " 5) C_CONF                         0.075491\n",
      " 6) C_HOUR                         0.049219\n",
      " 7) C_TRAF                         0.032686\n",
      " 8) V_YEAR                         0.029543\n",
      " 9) P_SEX                          0.029281\n",
      "10) C_RALN                         0.027751\n",
      "11) C_VEHS                         0.026881\n",
      "12) C_WTHR                         0.025348\n",
      "13) C_RCFG                         0.022978\n",
      "14) C_RSUR                         0.022307\n",
      "15) P_USER                         0.019660\n",
      "16) P_PSN                          0.009214\n",
      "['P_AGE', 'C_YEAR', 'C_MNTH', 'C_WDAY', 'C_CONF', 'C_HOUR', 'C_TRAF', 'V_YEAR', 'P_SEX', 'C_RALN', 'C_VEHS', 'C_WTHR']\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance with Extra Trees Classifier\n",
    "\n",
    "# feature extraction\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X_, Y_)\n",
    "print(model.feature_importances_)\n",
    "\n",
    "indices = np.argsort(model.feature_importances_)[::-1]\n",
    "print(indices)\n",
    "featureLabel = X_.columns[0:]\n",
    "print(featureLabel)\n",
    "rankedFeature = []\n",
    "for f in range(X_.shape[1]):\n",
    "    rankedFeature.append(featureLabel[indices[f]])\n",
    "    print(\"%2d) %-*s %f\" % (f+1, 30,  featureLabel[indices[f]], model.feature_importances_[indices[f]]))\n",
    "print(rankedFeature[0:12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction: RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Selection: Start\n",
      "Thu Nov 29 18:53:13 2018\n",
      "Random Forest Feature Selection: Fit Start\n",
      "Random Forest Feature Selection: Fit\n",
      "Random Forest Feature Selection: Feature Importance\n",
      "[0.14991917 0.12922359 0.09493915 0.0603878  0.02668629 0.06213154\n",
      " 0.0228237  0.02552461 0.02380172 0.02883489 0.03181076 0.03314014\n",
      " 0.02821974 0.2481038  0.00936773 0.02508539]\n",
      "[13  0  1  2  5  3 11 10  9 12  4  7 15  8  6 14]\n",
      "Index(['C_YEAR', 'C_MNTH', 'C_WDAY', 'C_HOUR', 'C_VEHS', 'C_CONF', 'C_RCFG',\n",
      "       'C_WTHR', 'C_RSUR', 'C_RALN', 'C_TRAF', 'V_YEAR', 'P_SEX', 'P_AGE',\n",
      "       'P_PSN', 'P_USER'],\n",
      "      dtype='object')\n",
      " 1) P_AGE                          0.248104\n",
      " 2) C_YEAR                         0.149919\n",
      " 3) C_MNTH                         0.129224\n",
      " 4) C_WDAY                         0.094939\n",
      " 5) C_CONF                         0.062132\n",
      " 6) C_HOUR                         0.060388\n",
      " 7) V_YEAR                         0.033140\n",
      " 8) C_TRAF                         0.031811\n",
      " 9) C_RALN                         0.028835\n",
      "10) P_SEX                          0.028220\n",
      "11) C_VEHS                         0.026686\n",
      "12) C_WTHR                         0.025525\n",
      "13) P_USER                         0.025085\n",
      "14) C_RSUR                         0.023802\n",
      "15) C_RCFG                         0.022824\n",
      "16) P_PSN                          0.009368\n",
      "['P_AGE', 'C_YEAR', 'C_MNTH', 'C_WDAY', 'C_CONF', 'C_HOUR', 'V_YEAR', 'C_TRAF', 'C_RALN', 'P_SEX', 'C_VEHS', 'C_WTHR']\n"
     ]
    }
   ],
   "source": [
    "verbose_level = 0\n",
    "if enable_rf_features:\n",
    "    print(\"Random Forest Feature Selection: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    forest = RandomForestClassifier(n_estimators=50, random_state=0, n_jobs=-1, verbose=verbose_level)\n",
    "    print(\"Random Forest Feature Selection: Fit Start\")\n",
    "    forest.fit(X_, Y_)\n",
    "    print(\"Random Forest Feature Selection: Fit\")\n",
    "\n",
    "    importFeatures = forest.feature_importances_\n",
    "    print(\"Random Forest Feature Selection: Feature Importance\")\n",
    "    print(importFeatures)\n",
    "    \n",
    "    indices = np.argsort(importFeatures)[::-1]\n",
    "    print(indices)\n",
    "    featureLabel = X_.columns[0:]\n",
    "    print(featureLabel)\n",
    "    rankedFeature = []\n",
    "    for f in range(X_.shape[1]):\n",
    "        rankedFeature.append(featureLabel[indices[f]])\n",
    "        print(\"%2d) %-*s %f\" % (f+1, 30,  featureLabel[indices[f]], importFeatures[indices[f]]))\n",
    "    print(rankedFeature[0:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('NCDB_FULL_Removed_All_Missing_Values_Binary_Class_Feature_Selected.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
