{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#in case we need to repeat experiment\n",
    "#np.random.seed(255)\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 22\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('classic')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "#sklearn imports\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pickle # allows for model to be saved/load to file\n",
    "import time\n",
    "\n",
    "#Use print instead of display when run as python script\n",
    "pyscript = True\n",
    "\n",
    "#Classifier verborsity where supported\n",
    "verbose_level=3\n",
    "\n",
    "#sampleN = 4300000\n",
    "\n",
    "#Multiclass classification, binary if falase\n",
    "multiclass = False\n",
    "over_sample = True\n",
    "\n",
    "#inputfile = 'CKME136X10_2018_Data_CTF.csv'\n",
    "if multiclass:\n",
    "    inputfile_train_O = 'CKME136X10_2018_Data_CTFB_M_O_Train.csv'\n",
    "    inputfile_train_U = 'CKME136X10_2018_Data_CTFB_M_U_Train.csv'\n",
    "    inputfile_test = 'CKME136X10_2018_Data_CTFB_M_Test.csv'\n",
    "else:\n",
    "    inputfile_train_O = 'CKME136X10_2018_Data_CTFB_B_O_Train.csv'\n",
    "    inputfile_train_U = 'CKME136X10_2018_Data_CTFB_B_U_Train.csv'\n",
    "    inputfile_test = 'CKME136X10_2018_Data_CTFB_B_Test.csv'\n",
    "\n",
    "if over_sample:\n",
    "    datafile_train = inputfile_train_O\n",
    "else:\n",
    "    datafile_train = inputfile_train_U\n",
    "\n",
    "datafile_test = inputfile_test\n",
    "    \n",
    "model_max_iter = 1000\n",
    "datestr = 'dec_07_binary_run_1000_BU'\n",
    "\n",
    "#Model Store\n",
    "file_lr = 'lr_' + datestr + '.model'\n",
    "file_lr_l1 = 'lr_l2_' + datestr + '.model'\n",
    "file_dt = 'dt_' + datestr + '.model'\n",
    "file_svm = 'svm_' + datestr + '.model'\n",
    "file_knn = 'knn_' + datestr + '.model'\n",
    "file_mlp = 'mlp_' + datestr + '.model'\n",
    "file_kmean = 'kmean_' + datestr + '.model'\n",
    "file_nbayes = 'nbayes_' + datestr + '.model'\n",
    "\n",
    "file_final_train = 'final_train_' + datestr + '.csv'\n",
    "file_final_test = 'final_test_' + datestr + '.csv'\n",
    "\n",
    "#Enable Optimization Algorithms\n",
    "enable_grid_search = False\n",
    "svm_c = 1\n",
    "svm_gamma = 1\n",
    "feature_all = True\n",
    "defaultFeatures = ['P_AGE', 'V_YEAR', 'C_HOUR', 'C_YEAR', 'C_MNTH', 'C_CONF', 'C_WDAY', 'C_VEHS', 'P_USER', 'P_SEX']\n",
    "\n",
    "enable_lr_l1 = False\n",
    "predict_lr_l1 = False\n",
    "\n",
    "# Enable Algorithms\n",
    "enable_lr = True\n",
    "enable_dt = True\n",
    "enable_svm = True\n",
    "enable_knn = True\n",
    "enable_mlp = True\n",
    "enable_kmean = True\n",
    "enable_nbayes = True\n",
    "\n",
    "predict_lr = True\n",
    "predict_dt = True\n",
    "predict_svm = True\n",
    "predict_knn = True\n",
    "predict_mlp = True\n",
    "predict_nbayes = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function converts the data frame to the appropriate data type\n",
    "def convert_type(data):\n",
    "    data = data.astype('category')\n",
    "    data['C_MNTH'] = data['C_MNTH'].astype(CategoricalDtype(ordered=True))\n",
    "    data['C_WDAY'] = data['C_WDAY'].astype(CategoricalDtype(ordered=True))\n",
    "    data['C_HOUR'] = data['C_HOUR'].astype(CategoricalDtype(ordered=True))\n",
    "    data['C_VEHS'] = data['C_VEHS'].astype(CategoricalDtype(ordered=True))\n",
    "    data['P_AGE'] = data['P_AGE'].astype(CategoricalDtype(ordered=True))\n",
    "    data['P_PSN'] = data['P_PSN'].astype(CategoricalDtype(ordered=True))\n",
    "    data['P_ISEV'] = data['P_ISEV'].astype('int')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Class Classification: Disabled\n",
      "Grid Search: Disabled\n",
      "All Features: Enabled\n",
      "K-means: Enabled\n",
      "Logistic Regression: Disabled\n",
      "Decision Tree: Enabled\n",
      "Support Vector Machines: Enabled\n",
      "KNN: Enabled\n",
      "MLP: Enabled\n"
     ]
    }
   ],
   "source": [
    "#print(\"Sample size: {}\".format(sampleN))\n",
    "\n",
    "if multiclass:\n",
    "    print(\"Multi-Class Classification: Enabled\")\n",
    "else:\n",
    "    print(\"Multi-Class Classification: Disabled\")\n",
    "\n",
    "if enable_grid_search:\n",
    "    print(\"Grid Search: Enabled\")\n",
    "else:\n",
    "    print(\"Grid Search: Disabled\")\n",
    "\n",
    "if feature_all:\n",
    "    print(\"All Features: Enabled\")\n",
    "else:\n",
    "    print(\"All Features: Disabled\")\n",
    "    \n",
    "if enable_kmean:\n",
    "    print(\"K-means: Enabled\")\n",
    "else:\n",
    "    print(\"K-means: Disabled\")\n",
    "\n",
    "if enable_lr_l1:\n",
    "    print(\"Logistic Regression: Enabled\")\n",
    "else:\n",
    "    print(\"Logistic Regression: Disabled\")\n",
    "    \n",
    "if enable_dt:\n",
    "    print(\"Decision Tree: Enabled\")\n",
    "else:\n",
    "    print(\"Decision Tree: Disabled\")\n",
    "    \n",
    "if enable_svm:\n",
    "    print(\"Support Vector Machines: Enabled\")\n",
    "else:\n",
    "    print(\"Support Vector Machines: Disabled\")\n",
    "\n",
    "if  enable_knn:\n",
    "    print(\"KNN: Enabled\")\n",
    "else:\n",
    "    print(\"KNN: Disabled\")\n",
    "    \n",
    "if enable_mlp:\n",
    "    print(\"MLP: Enabled\")\n",
    "else:\n",
    "    print(\"MLP: Disabled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec  7 15:00:42 2018\n"
     ]
    }
   ],
   "source": [
    "t_start =  time.time()\n",
    "print(time.asctime( time.localtime(t_start) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C_MNTH  C_WDAY  C_HOUR  C_VEHS  C_CONF  C_RCFG  C_WTHR  C_RSUR  C_RALN  \\\n",
      "0       8       5       2       2      36       2       1       1       1   \n",
      "1       6       5       2       2      33       2       1       1       1   \n",
      "\n",
      "   C_TRAF  P_SEX  P_AGE  P_PSN  P_USER  P_ISEV  \n",
      "0       2      2      1      1       3       1  \n",
      "1       1      1      4      1       2       0  \n",
      "   C_MNTH  C_WDAY  C_HOUR  C_VEHS  C_CONF  C_RCFG  C_WTHR  C_RSUR  C_RALN  \\\n",
      "0       6       2       4       2      23       1       1       1       1   \n",
      "1       2       6       1       1       3       1       4       6       1   \n",
      "\n",
      "   C_TRAF  P_SEX  P_AGE  P_PSN  P_USER  P_ISEV  \n",
      "0       7      2      4      1       1       1  \n",
      "1       7      1      4      1       1       1  \n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "df_test = pd.read_csv(datafile_test, engine = 'python')\n",
    "df_train = pd.read_csv(datafile_train, engine = 'python')\n",
    "df = df_train.copy()\n",
    "\n",
    "print(df_test.head(2))\n",
    "print(df_train.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df_test.isnull().sum().sum())\n",
    "print(df_train.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df_test[df_test.columns].apply(lambda x: x.astype(str).str.contains('[^0-9]')).sum().sum())\n",
    "print(df_train[df_train.columns].apply(lambda x: x.astype(str).str.contains('[^0-9]')).sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_cat = df_test.astype('category').copy()\n",
    "df_train_cat = df_train.astype('category').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows in test data: 1444846\n",
      "Number of Rows in train data: 3878536\n"
     ]
    }
   ],
   "source": [
    "total_test_Rows = df_test_cat.index.size\n",
    "print(\"Number of Rows in test data: {}\".format(total_test_Rows))\n",
    "\n",
    "total_train_Rows = df_train_cat.index.size\n",
    "print(\"Number of Rows in train data: {}\".format(total_train_Rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['C_MNTH', 'C_WDAY', 'C_HOUR', 'C_VEHS', 'C_CONF', 'C_RCFG', 'C_WTHR',\n",
      "       'C_RSUR', 'C_RALN', 'C_TRAF', 'P_SEX', 'P_AGE', 'P_PSN', 'P_USER',\n",
      "       'P_ISEV'],\n",
      "      dtype='object')\n",
      "C_MNTH    category\n",
      "C_WDAY    category\n",
      "C_HOUR    category\n",
      "C_VEHS    category\n",
      "C_CONF    category\n",
      "C_RCFG    category\n",
      "C_WTHR    category\n",
      "C_RSUR    category\n",
      "C_RALN    category\n",
      "C_TRAF    category\n",
      "P_SEX     category\n",
      "P_AGE     category\n",
      "P_PSN     category\n",
      "P_USER    category\n",
      "P_ISEV    category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_train_cat.columns)\n",
    "print(df_train_cat.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-Hot-Encoding of categorical\n",
    "#TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_test_cat[df_test_cat.columns].apply(lambda x: x.astype(str).str.contains('[^0-9]')).sum().sum())\n",
    "#print(df_train_cat[df_train_cat.columns].apply(lambda x: x.astype(str).str.contains('[^0-9]')).sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### type cast train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3878536 entries, 0 to 3878535\n",
      "Data columns (total 15 columns):\n",
      "C_MNTH    category\n",
      "C_WDAY    category\n",
      "C_HOUR    category\n",
      "C_VEHS    category\n",
      "C_CONF    category\n",
      "C_RCFG    category\n",
      "C_WTHR    category\n",
      "C_RSUR    category\n",
      "C_RALN    category\n",
      "C_TRAF    category\n",
      "P_SEX     category\n",
      "P_AGE     category\n",
      "P_PSN     category\n",
      "P_USER    category\n",
      "P_ISEV    int32\n",
      "dtypes: category(14), int32(1)\n",
      "memory usage: 66.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# convert to the correct type\n",
    "df_train_cat = convert_type(df_train_cat)\n",
    "print(df_train_cat.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### type cast test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1444846 entries, 0 to 1444845\n",
      "Data columns (total 15 columns):\n",
      "C_MNTH    1444846 non-null category\n",
      "C_WDAY    1444846 non-null category\n",
      "C_HOUR    1444846 non-null category\n",
      "C_VEHS    1444846 non-null category\n",
      "C_CONF    1444846 non-null category\n",
      "C_RCFG    1444846 non-null category\n",
      "C_WTHR    1444846 non-null category\n",
      "C_RSUR    1444846 non-null category\n",
      "C_RALN    1444846 non-null category\n",
      "C_TRAF    1444846 non-null category\n",
      "P_SEX     1444846 non-null category\n",
      "P_AGE     1444846 non-null category\n",
      "P_PSN     1444846 non-null category\n",
      "P_USER    1444846 non-null category\n",
      "P_ISEV    1444846 non-null int32\n",
      "dtypes: category(14), int32(1)\n",
      "memory usage: 24.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# convert to the correct type\n",
    "df_test_cat = convert_type(df_test_cat)\n",
    "print(df_test_cat.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training and Testing for Binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split between data and class for training\n",
    "Y_train = df_train_cat[df_train_cat.columns[-1]]\n",
    "X_train = df_train_cat[df_train_cat.columns[0:df_train_cat.columns.size -1]]\n",
    "\n",
    "Y_test = df_test_cat[df_test_cat.columns[-1]]\n",
    "X_test = df_test_cat[df_test_cat.columns[0:df_test_cat.columns.size -1]]\n",
    "\n",
    "# split data into X and y\n",
    "#X = df_sample.iloc[:,0:16]\n",
    "#Y = df_sample.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "P_ISEV\n",
      "0    1939268\n",
      "1    1939268\n",
      "Name: P_ISEV, dtype: int64\n",
      "\n",
      "[1 0]\n",
      "P_ISEV\n",
      "0    613731\n",
      "1    831115\n",
      "Name: P_ISEV, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.unique())\n",
    "print(Y_train.groupby(Y_train).size())\n",
    "print()\n",
    "print(Y_test.unique())\n",
    "print(Y_test.groupby(Y_test).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  C_MNTH C_WDAY C_HOUR C_VEHS C_CONF C_RCFG C_WTHR C_RSUR C_RALN C_TRAF P_SEX  \\\n",
      "0      6      2      4      2     23      1      1      1      1      7     2   \n",
      "1      2      6      1      1      3      1      4      6      1      7     1   \n",
      "2      4      4      2      2     36      2      4      4      1      2     2   \n",
      "\n",
      "  P_AGE P_PSN P_USER  \n",
      "0     4     1      1  \n",
      "1     4     1      1  \n",
      "2     4     1      1  \n"
     ]
    }
   ],
   "source": [
    "print(X_train.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering based on K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec  7 15:05:33 2018\n",
      "K-Means Clustering: Start\n",
      "KMeans(algorithm='auto', copy_x=True, init='random', max_iter=1000,\n",
      "    n_clusters=3, n_init=10, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=3)\n",
      "K-Means Clustering: Build\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 167068053.3027511\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 166703455.34141898\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 166703455.34141898\n",
      "center shift 0.000000e+00 within tolerance 1.336739e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 406007160.27997893\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 294937014.9780891\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 294031801.72951967\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 293488156.74550515\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 292808743.4022314\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 291015596.4467301\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 285568107.42284364\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 270013248.1921249\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 268918264.9124098\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 268918239.4255761\n",
      "center shift 2.303414e-04 within tolerance 1.336739e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 299962398.6815291\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 282557567.02510065\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 269979004.7317004\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 268918262.36062187\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 268918239.4255761\n",
      "center shift 2.198390e-04 within tolerance 1.336739e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 307038515.94867057\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 278957819.6890701\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 166703455.34141898\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 166703455.34141898\n",
      "center shift 0.000000e+00 within tolerance 1.336739e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 269230616.86312115\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 268918239.4255761\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 268918239.4255761\n",
      "center shift 0.000000e+00 within tolerance 1.336739e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 191120145.64021417\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 166703455.34141898\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 166703455.34141898\n",
      "center shift 0.000000e+00 within tolerance 1.336739e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 366275084.2078987\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 325028916.6155962\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 173568074.34329328\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 166703455.34141898\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 166703455.34141898\n",
      "center shift 0.000000e+00 within tolerance 1.336739e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 166760273.427304\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 166703455.34141898\n",
      "center shift 6.131897e-03 within tolerance 1.336739e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 320026837.3375308\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 313964838.14106035\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 275300390.8993748\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 169314807.68654674\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 166703455.34141898\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 166703455.34141898\n",
      "center shift 0.000000e+00 within tolerance 1.336739e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 314242630.2614237\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 293429204.46095395\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 291118747.4709909\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 280201603.8942963\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 175697235.35107905\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 166703455.34141898\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 166703455.34141898\n",
      "center shift 0.000000e+00 within tolerance 1.336739e-03\n",
      "[[ 6.67583364  3.9970538   3.36929682  2.10689089 36.25726803  1.92506766\n",
      "   1.57390258  1.53137065  1.28598884  3.62573187  1.55822511  3.62716665\n",
      "   1.15121675  1.40243905]\n",
      " [ 6.78693877  4.14527375  3.17348881  1.0978746   4.38229168  1.5137046\n",
      "   1.74725569  1.85775175  1.5921152   5.74506598  1.58049877  3.46035858\n",
      "   1.40849277  1.61585058]\n",
      " [ 6.70828277  3.9394404   3.35611464  2.41221387 21.23612774  1.62535324\n",
      "   1.51734687  1.47802836  1.25460414  4.77927993  1.55141873  3.61297716\n",
      "   1.13397542  1.33523745]]\n",
      "[2 1 0 ... 1 2 2]\n",
      "K-Means Clustering: End\n",
      "Fri Dec  7 15:06:32 2018\n"
     ]
    }
   ],
   "source": [
    "if enable_kmean:\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print(\"K-Means Clustering: Start\")\n",
    "    kmeans = KMeans(n_clusters=3, init='random', n_init=10, tol=1e-04, verbose= verbose_level, max_iter=model_max_iter)\n",
    "    print(kmeans)\n",
    "    \n",
    "    print(\"K-Means Clustering: Build\")\n",
    "    ykm = kmeans.fit(X_train)\n",
    "    \n",
    "    if pyscript:\n",
    "        print(ykm.cluster_centers_)\n",
    "        print(ykm.labels_)\n",
    "    else:\n",
    "        display(ykm.cluster_centers_)\n",
    "        display(ykm.labels_)\n",
    "    \n",
    "    # save model to file\n",
    "    pickle.dump(ykm, open(file_kmean, \"wb\"))\n",
    "    \n",
    "    print(\"K-Means Clustering: End\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM GridSearch for Optimal Parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This operation is computationaly expensive.\n",
    "if enable_grid_search:\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    param_grid = {'C':[0.1, 1, 10, 100, 1000], 'gamma':[1, 0.1, 0.01, 0.001, 0.0001]}\n",
    "    grid = GridSearchCV(SVC(), param_grid, verbose=verbose_level, n_jobs = 10)\n",
    "    print(grid)\n",
    "    grid.fit(X_train, Y_train)\n",
    "    print(grid.best_params_)\n",
    "    svm_c = grid.best_params_.get('C')\n",
    "    svm_gamma = grid.best_params_.get('gamma')\n",
    "    print(grid.best_estimator_)\n",
    "    grid_predictions = grid.predict(X_test)\n",
    "    cfn_matrix_grid = confusion_matrix(Y_test, grid_predictions)\n",
    "    print(cfn_matrix_grid)\n",
    "    print(classification_report(Y_test,grid_predictions))\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Start\n",
      "Fri Dec  7 15:06:32 2018\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=10,\n",
      "          penalty='l2', random_state=0, solver='saga', tol=0.0001,\n",
      "          verbose=3, warm_start=False)\n",
      "Logistic Regression: Fit\n",
      "convergence after 16 epochs took 38 seconds\n",
      "Logistic Regression: Predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   38.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on train set: 0.63\n",
      "Accuracy of logistic regression classifier on test set: 0.62\n",
      "Logistic Regression: Intercept\n",
      "[0.04860613]\n",
      "Logistic Regression: Coefficients\n",
      "[[ 0.00098316 -0.01014891 -0.06143472 -0.43042533 -0.00334904 -0.04163138\n",
      "   0.03130093  0.04506247  0.19355885  0.04099924 -0.55311215  0.17620858\n",
      "  -0.14335797  0.74947889]]\n",
      "Logistic Regression: Confusion Matrix\n",
      "[[406721 207010]\n",
      " [339015 492100]]\n",
      "Logistic Regression: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.66      0.60    613731\n",
      "          1       0.70      0.59      0.64    831115\n",
      "\n",
      "avg / total       0.64      0.62      0.62   1444846\n",
      "\n",
      "Fri Dec  7 15:07:19 2018\n",
      "Logistic Regression: End\n"
     ]
    }
   ],
   "source": [
    "if enable_lr:\n",
    "    print(\"Logistic Regression: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    lr = LogisticRegression(C=1, random_state=0, solver='saga', multi_class='ovr', \n",
    "                            verbose=verbose_level, n_jobs=10, max_iter=model_max_iter)\n",
    "    print(lr)\n",
    "    print(\"Logistic Regression: Fit\")\n",
    "    lr.fit(X_train, Y_train)\n",
    "    \n",
    "    # save model to file\n",
    "    pickle.dump(lr, open(file_lr, \"wb\"))\n",
    "    \n",
    "    \n",
    "if predict_lr:\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_lr, \"rb\"))\n",
    "    print(\"Logistic Regression: Predict\")\n",
    "    y_pred = lr.predict(X_test)\n",
    "\n",
    "    print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(lr.score(X_train, Y_train)))\n",
    "    print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(lr.score(X_test, Y_test)))\n",
    "\n",
    "    # print the intercept (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "    print(\"Logistic Regression: Intercept\")\n",
    "    print(lr.intercept_)\n",
    "\n",
    "    # print the coeficients (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "    print(\"Logistic Regression: Coefficients\")\n",
    "    print(lr.coef_)\n",
    "\n",
    "    print(\"Logistic Regression: Confusion Matrix\")\n",
    "    cnf_matrix_lg = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_lg)\n",
    "    \n",
    "    print(\"Logistic Regression: Classification Report\")\n",
    "    print(classification_report(Y_test, y_pred))\n",
    "\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"Logistic Regression: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with L1 Regularization: End\n"
     ]
    }
   ],
   "source": [
    "if (enable_lr_l1):\n",
    "    # with L1 regularization\n",
    "    print(\"Logistic Regression with L1 Regularization: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    lr = LogisticRegression(penalty='l1', C=1, solver='saga', multi_class='ovr', \n",
    "                            verbose=verbose_level, n_jobs = 10, max_iter=model_max_iter)\n",
    "    print(lr)\n",
    "    print(\"Logistic Regression with L1 Regularization: Fit\")\n",
    "    lr.fit(X_train, Y_train)\n",
    "    \n",
    "    # save model to file\n",
    "    pickle.dump(lr, open(file_lr_l1, \"wb\"))\n",
    "\n",
    "if (predict_lr_l1):\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_lr_l1, \"rb\"))\n",
    "    print(\"Logistic Regression with L1 Regularization: Predict\")\n",
    "    y_pred = lr.predict(X_test)\n",
    "    \n",
    "    print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(lr.score(X_train, Y_train)))\n",
    "    print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(lr.score(X_test, Y_test)))\n",
    "\n",
    "    print(\"Logistic Regression with L1 Regularization: Confusion Matrix\")\n",
    "    cnf_matrix_lg_l1 = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_lg_l1)\n",
    "    \n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    print(\"Logistic Regression with L1 Regularization: Classification Report\")\n",
    "\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"Logistic Regression with L1 Regularization: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes: Start\n",
      "Fri Dec  7 15:07:19 2018\n",
      "GaussianNB(priors=None)\n",
      "Naive Bayes: Fit\n",
      "Naive Bayes: Predict\n",
      "Accuracy of Naive Bayes classifier on train set: 0.60\n",
      "Accuracy of Naove Nayes classifier on test set: 0.58\n",
      "Naive Bayes: Confusion Matrix\n",
      "[[440315 173416]\n",
      " [436948 394167]]\n",
      "Naive Bayes: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.72      0.59    613731\n",
      "          1       0.69      0.47      0.56    831115\n",
      "\n",
      "avg / total       0.61      0.58      0.58   1444846\n",
      "\n",
      "Fri Dec  7 15:07:30 2018\n",
      "Naive Bayes: End\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes Classification\n",
    "if enable_nbayes:\n",
    "    print(\"Naive Bayes: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    nbayes = GaussianNB()\n",
    "    print(nbayes)\n",
    "    print(\"Naive Bayes: Fit\")\n",
    "    nbayes.fit(X_train, Y_train)\n",
    "    # save model to file\n",
    "    pickle.dump(nbayes, open(file_nbayes, \"wb\"))\n",
    "\n",
    "if predict_nbayes:\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_nbayes, \"rb\"))\n",
    "    print(\"Naive Bayes: Predict\")\n",
    "    y_pred = nbayes.predict(X_test)\n",
    "    print('Accuracy of Naive Bayes classifier on train set: {:.2f}'.format(nbayes.score(X_train, Y_train)))\n",
    "    print('Accuracy of Naove Nayes classifier on test set: {:.2f}'.format(nbayes.score(X_test, Y_test)))\n",
    "    \n",
    "    cnf_matrix_dt = confusion_matrix(Y_test, y_pred)\n",
    "    print(\"Naive Bayes: Confusion Matrix\")\n",
    "    print(cnf_matrix_dt)\n",
    "    print(\"Naive Bayes: Classification Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    print(\"Naive Bayes: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: Start\n",
      "Fri Dec  7 15:07:30 2018\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=50,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "Decision Tree: Fit\n",
      "Decision Tree: Predict\n",
      "Accuracy of Decision Tree classifier on train set: 0.85\n",
      "Accuracy of Decision Tree classifier on test set: 0.61\n",
      "Decision Tree: Confusion Matrix\n",
      "[[399333 214398]\n",
      " [349316 481799]]\n",
      "Decision Tree: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.65      0.59    613731\n",
      "          1       0.69      0.58      0.63    831115\n",
      "\n",
      "avg / total       0.62      0.61      0.61   1444846\n",
      "\n",
      "Fri Dec  7 15:08:20 2018\n",
      "Decision Tree: End\n"
     ]
    }
   ],
   "source": [
    "if enable_dt:\n",
    "    print(\"Decision Tree: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    tree = DecisionTreeClassifier(criterion='entropy',max_depth=50)\n",
    "    print(tree)\n",
    "    print(\"Decision Tree: Fit\")\n",
    "    tree.fit(X_train, Y_train)\n",
    "    # save model to file\n",
    "    pickle.dump(tree, open(file_dt, \"wb\"))\n",
    "\n",
    "if predict_dt:\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_dt, \"rb\"))\n",
    "    print(\"Decision Tree: Predict\")\n",
    "    y_pred = tree.predict(X_test)\n",
    "    print('Accuracy of Decision Tree classifier on train set: {:.2f}'.format(tree.score(X_train, Y_train)))\n",
    "    print('Accuracy of Decision Tree classifier on test set: {:.2f}'.format(tree.score(X_test, Y_test)))\n",
    "    \n",
    "    cnf_matrix_dt = confusion_matrix(Y_test, y_pred)\n",
    "    print(\"Decision Tree: Confusion Matrix\")\n",
    "    print(cnf_matrix_dt)\n",
    "    print(\"Decision Tree: Classification Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    print(\"Decision Tree: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-N-N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: Start\n",
      "Fri Dec  7 15:08:21 2018\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNN: Fit\n",
      "KNN: Predict\n",
      "Accuracy of KNN classifier on train set: 0.75\n",
      "Accuracy of KNN classifier on test set: 0.62\n",
      "KNN: Confusion Matrix\n",
      "[[371943 241788]\n",
      " [302428 528687]]\n",
      "KNN: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.61      0.58    613731\n",
      "          1       0.69      0.64      0.66    831115\n",
      "\n",
      "avg / total       0.63      0.62      0.63   1444846\n",
      "\n",
      "Fri Dec  7 19:10:00 2018\n",
      "KNN: End\n"
     ]
    }
   ],
   "source": [
    "if enable_knn:\n",
    "    print(\"KNN: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    knn = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski', n_jobs = -1)\n",
    "    print(knn)\n",
    "    print(\"KNN: Fit\")\n",
    "    knn.fit(X_train, Y_train)\n",
    "\n",
    "    # save model to file\n",
    "    pickle.dump(knn, open(file_knn, \"wb\"))\n",
    "\n",
    "if predict_knn:\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_knn, \"rb\"))\n",
    "    \n",
    "    print(\"KNN: Predict\")\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print('Accuracy of KNN classifier on train set: {:.2f}'.format(knn.score(X_train, Y_train)))\n",
    "    print('Accuracy of KNN classifier on test set: {:.2f}'.format(knn.score(X_test, Y_test)))\n",
    "    \n",
    "    print(\"KNN: Confusion Matrix\")\n",
    "    cnf_matrix_knn = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_knn)\n",
    "\n",
    "    print(\"KNN: Classification Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "\n",
    "    print(\"KNN: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN - Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Preceptron: Start\n",
      "Fri Dec  7 19:10:00 2018\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(25, 25, 25), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=3, warm_start=False)\n",
      "Multilayer Preceptron: fit\n",
      "Iteration 1, loss = 0.60952858\n",
      "Iteration 2, loss = 0.60130847\n",
      "Iteration 3, loss = 0.59971440\n",
      "Iteration 4, loss = 0.59868463\n",
      "Iteration 5, loss = 0.59783590\n",
      "Iteration 6, loss = 0.59735010\n",
      "Iteration 7, loss = 0.59694356\n",
      "Iteration 8, loss = 0.59672987\n",
      "Iteration 9, loss = 0.59649496\n",
      "Iteration 10, loss = 0.59633271\n",
      "Iteration 11, loss = 0.59608516\n",
      "Iteration 12, loss = 0.59591687\n",
      "Iteration 13, loss = 0.59571882\n",
      "Iteration 14, loss = 0.59556750\n",
      "Iteration 15, loss = 0.59541483\n",
      "Iteration 16, loss = 0.59531101\n",
      "Iteration 17, loss = 0.59521798\n",
      "Iteration 18, loss = 0.59517240\n",
      "Iteration 19, loss = 0.59506245\n",
      "Iteration 20, loss = 0.59503158\n",
      "Iteration 21, loss = 0.59493064\n",
      "Iteration 22, loss = 0.59489359\n",
      "Iteration 23, loss = 0.59480769\n",
      "Iteration 24, loss = 0.59473727\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Multilayer Preceptron: Predict\n",
      "Accuracy of Multilayer Perceptron classifier on train set: 0.67\n",
      "Accuracy of Multilayer Perceptron classifier on test set: 0.66\n",
      "Multilayer Preceptron: Confusion Matrix\n",
      "[[445090 168641]\n",
      " [324711 506404]]\n",
      "Multilayer Preceptron: Classificiation Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.73      0.64    613731\n",
      "          1       0.75      0.61      0.67    831115\n",
      "\n",
      "avg / total       0.68      0.66      0.66   1444846\n",
      "\n",
      "Fri Dec  7 19:17:38 2018\n",
      "Multilayer Preceptron: End\n"
     ]
    }
   ],
   "source": [
    "if enable_mlp:\n",
    "    print(\"Multilayer Preceptron: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    \n",
    "    #mlpc = MLPClassifier(alpha=1)\n",
    "    #mlpc = MLPClassifier(hidden_layer_sizes=(12, 12, 12), max_iter=model_max_iter, verbose=verbose_level)\n",
    "    mlpc = MLPClassifier(hidden_layer_sizes=(25, 25, 25), verbose=verbose_level, max_iter=model_max_iter)\n",
    "    print(mlpc)\n",
    "    #mlp = multilayer_perceptron(n_hidden =2, activation='logistic', algorithm='sgd', random_state=3)\n",
    "    print(\"Multilayer Preceptron: fit\")\n",
    "    mlpc.fit(X_train, Y_train)\n",
    "    \n",
    "    # save model to file\n",
    "    pickle.dump(mlpc, open(file_mlp, \"wb\"))\n",
    "    \n",
    "if predict_mlp:\n",
    "    \n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_mlp, \"rb\"))\n",
    "    print(\"Multilayer Preceptron: Predict\")\n",
    "    y_pred = mlpc.predict(X_test)\n",
    "\n",
    "    print('Accuracy of Multilayer Perceptron classifier on train set: {:.2f}'.format(mlpc.score(X_train, Y_train)))\n",
    "    print('Accuracy of Multilayer Perceptron classifier on test set: {:.2f}'.format(mlpc.score(X_test, Y_test)))\n",
    "    \n",
    "    print(\"Multilayer Preceptron: Confusion Matrix\")\n",
    "    cnf_matrix_mlp = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_mlp)\n",
    "    \n",
    "    print(\"Multilayer Preceptron: Classificiation Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "    print(\"Multilayer Preceptron: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: Start\n",
      "Fri Dec  7 19:17:38 2018\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=1000, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=3)\n",
      "SVM: Fit\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: Predict\n",
      "Accuracy of SVM classifier on train set: 0.50\n",
      "Accuracy of SVM classifier on test set: 0.42\n",
      "SVM: Confusion Matrix\n",
      "[[594063  19668]\n",
      " [812153  18962]]\n",
      "SVM: Classfication Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.42      0.97      0.59    613731\n",
      "          1       0.49      0.02      0.04    831115\n",
      "\n",
      "avg / total       0.46      0.42      0.27   1444846\n",
      "\n",
      "Fri Dec  7 19:28:02 2018\n",
      "SVM: End\n"
     ]
    }
   ],
   "source": [
    "if enable_svm:\n",
    "    print(\"SVM: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    #svm = SVC(C=1, random_state=0, kernel='sigmoid', verbose=True)\n",
    "    #svm = SVC(C=1, random_state=0, kernel='linear', verbose=True, cache_size=200)\n",
    "    #svm = SVC(C=svm_c, gamma=svm_gamma, verbose = verbose_level)\n",
    "    #SVN prediction is taking for ever, limiting the max_iter to 100 instead of -1 (no limit)\n",
    "    svm = SVC(C=1, gamma = 'auto', verbose = verbose_level, max_iter=model_max_iter)\n",
    "    print(svm)\n",
    "    print(\"SVM: Fit\")\n",
    "    svm.fit(X_train, Y_train)\n",
    "\n",
    "    # save model to file\n",
    "    pickle.dump(svm, open(file_svm, \"wb\"))\n",
    "    \n",
    "if predict_svm:\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_svm, \"rb\"))\n",
    "    print(\"SVM: Predict\")\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    print('Accuracy of SVM classifier on train set: {:.2f}'.format(svm.score(X_train, Y_train)))\n",
    "    print('Accuracy of SVM classifier on test set: {:.2f}'.format(svm.score(X_test, Y_test)))\n",
    "    \n",
    "    print(\"SVM: Confusion Matrix\")\n",
    "    cnf_matrix_svm = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_svm)\n",
    "    \n",
    "    print(\"SVM: Classfication Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "    print(\"SVM: End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec  7 19:28:02 2018\n"
     ]
    }
   ],
   "source": [
    "t_end =  time.time()\n",
    "print(time.asctime( time.localtime(t_end) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
