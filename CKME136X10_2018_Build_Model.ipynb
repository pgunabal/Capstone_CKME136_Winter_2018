{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#in case we need to repeat experiment\n",
    "#np.random.seed(255)\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 22\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('classic')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "#sklearn imports\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pickle # allows for model to be saved/load to file\n",
    "import time\n",
    "\n",
    "#Use print instead of display when run as python script\n",
    "pyscript = True\n",
    "\n",
    "#Classifier verborsity where supported\n",
    "verbose_level=3\n",
    "\n",
    "sampleN = 4300000\n",
    "\n",
    "model_max_iter = 1000\n",
    "datafile = 'CKME136X10_2018_Data_CTF.csv'\n",
    "datestr = 'dec_03_binary_run_01'\n",
    "\n",
    "#Model Store\n",
    "file_lr = 'lr_' + datestr + '.model'\n",
    "file_lr_l1 = 'lr_l2_' + datestr + '.model'\n",
    "file_dt = 'dt_' + datestr + '.model'\n",
    "file_svm = 'svm_' + datestr + '.model'\n",
    "file_knn = 'knn_' + datestr + '.model'\n",
    "file_mlp = 'mlp_' + datestr + '.model'\n",
    "file_kmean = 'kmean_' + datestr + '.model'\n",
    "file_nbayes = 'nbayes_' + datestr + '.model'\n",
    "\n",
    "file_final_train = 'final_train_' + datestr + '.csv'\n",
    "file_final_test = 'final_test_' + datestr + '.csv'\n",
    "\n",
    "#Enable Optimization Algorithms\n",
    "enable_grid_search = False\n",
    "svm_c = 1\n",
    "svm_gamma = 1\n",
    "feature_all = True\n",
    "defaultFeatures = ['P_AGE', 'V_YEAR', 'C_HOUR', 'C_YEAR', 'C_MNTH', 'C_CONF', 'C_WDAY', 'C_VEHS', 'P_USER', 'P_SEX']\n",
    "\n",
    "enable_lr_l1 = True\n",
    "predict_lr_l1 = True\n",
    "\n",
    "# Enable Algorithms\n",
    "enable_lr = True\n",
    "enable_dt = True\n",
    "enable_svm = True\n",
    "enable_knn = True\n",
    "enable_mlp = True\n",
    "enable_kmean = True\n",
    "enable_nbayes = True\n",
    "\n",
    "predict_lr = True\n",
    "predict_dt = True\n",
    "predict_svm = True\n",
    "predict_knn = True\n",
    "predict_mlp = True\n",
    "predict_nbayes = True\n",
    "\n",
    "\n",
    "#Multiclass classification, binary if falase\n",
    "multiclass = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 100000\n",
      "Multi-Class Classification: Disabled\n",
      "Grid Search: Disabled\n",
      "All Features: Enabled\n",
      "K-means: Enabled\n",
      "Logistic Regression: Enabled\n",
      "Decision Tree: Enabled\n",
      "Support Vector Machines: Enabled\n",
      "KNN: Enabled\n",
      "MLP: Enabled\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample size: {}\".format(sampleN))\n",
    "\n",
    "if multiclass:\n",
    "    print(\"Multi-Class Classification: Enabled\")\n",
    "else:\n",
    "    print(\"Multi-Class Classification: Disabled\")\n",
    "\n",
    "if enable_grid_search:\n",
    "    print(\"Grid Search: Enabled\")\n",
    "else:\n",
    "    print(\"Grid Search: Disabled\")\n",
    "\n",
    "if feature_all:\n",
    "    print(\"All Features: Enabled\")\n",
    "else:\n",
    "    print(\"All Features: Disabled\")\n",
    "    \n",
    "if enable_kmean:\n",
    "    print(\"K-means: Enabled\")\n",
    "else:\n",
    "    print(\"K-means: Disabled\")\n",
    "\n",
    "if enable_lr_l1:\n",
    "    print(\"Logistic Regression: Enabled\")\n",
    "else:\n",
    "    print(\"Logistic Regression: Disabled\")\n",
    "    \n",
    "if enable_dt:\n",
    "    print(\"Decision Tree: Enabled\")\n",
    "else:\n",
    "    print(\"Decision Tree: Disabled\")\n",
    "    \n",
    "if enable_svm:\n",
    "    print(\"Support Vector Machines: Enabled\")\n",
    "else:\n",
    "    print(\"Support Vector Machines: Disabled\")\n",
    "\n",
    "if  enable_knn:\n",
    "    print(\"KNN: Enabled\")\n",
    "else:\n",
    "    print(\"KNN: Disabled\")\n",
    "    \n",
    "if enable_mlp:\n",
    "    print(\"MLP: Enabled\")\n",
    "else:\n",
    "    print(\"MLP: Disabled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec  2 18:02:17 2018\n"
     ]
    }
   ],
   "source": [
    "t_start =  time.time()\n",
    "print(time.asctime( time.localtime(t_start) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C_YEAR  C_MNTH  C_WDAY  C_HOUR  C_VEHS  C_CONF  C_RCFG  C_WTHR  C_RSUR  \\\n",
      "0       1       1       1       2       1       4       4       1       4   \n",
      "1       1       1       1       1       1       3       4       1       2   \n",
      "\n",
      "   C_RALN  C_TRAF  V_TYPE  V_YEAR  P_SEX  P_AGE  P_PSN  P_SAFE  P_USER  P_ISEV  \n",
      "0       3       7       1       3      0     25      1       2       1       2  \n",
      "1       1       7       1       3      1     65      1       2       1       2  \n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "df = pd.read_csv(datafile, engine = 'python')\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df[df.columns].apply(lambda x: x.astype(str).str.contains('[^0-9]')).sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = df.astype('category').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows in the dataset: 4336558\n"
     ]
    }
   ],
   "source": [
    "totalRows = df_cat.index.size\n",
    "print(\"Number of Rows in the dataset: {}\".format(totalRows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['C_YEAR', 'C_MNTH', 'C_WDAY', 'C_HOUR', 'C_VEHS', 'C_CONF', 'C_RCFG',\n",
      "       'C_WTHR', 'C_RSUR', 'C_RALN', 'C_TRAF', 'V_TYPE', 'V_YEAR', 'P_SEX',\n",
      "       'P_AGE', 'P_PSN', 'P_SAFE', 'P_USER', 'P_ISEV'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_cat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-Hot-Encoding of categorical\n",
    "#TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Class Variable to Binary if multi class disabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1812162\n",
      "2524396\n",
      "['1' '0']\n",
      "Size of dataframe for modeling: 100000\n"
     ]
    }
   ],
   "source": [
    "## Convert Class Variable to Binary\n",
    "### Merge Injury and Fatality as a single class\n",
    "### we will compare the results.\n",
    "if multiclass:\n",
    "    #Undersample the majority for the 3 class evaluation\n",
    "    \n",
    "    df_class = df_cat.copy()\n",
    "    \n",
    "    # subset fatal class\n",
    "    is_fatal =  df_class['P_ISEV']==3\n",
    "    is_fatal_count = is_fatal.sum()\n",
    "    print(\"Number of Fatal: {}\".format(is_fatal_count))\n",
    "    df_class_fatal = df_class[is_fatal]\n",
    "    print(df_class_fatal.head(2))\n",
    "    \n",
    "    # subset injury class\n",
    "    is_injury =  df_class['P_ISEV']==2\n",
    "    is_injury_count = is_injury.sum()\n",
    "    print(\"Number of Injury: {}\".format(is_injury_count))\n",
    "    df_class_injury = df_class[is_injury]\n",
    "    print(df_class_injury.head(2))\n",
    "    \n",
    "    # subset non_injury class\n",
    "    is_safe =  df_class['P_ISEV']==1\n",
    "    is_safe_count = is_safe.sum()\n",
    "    print(\"Number of Non-Injury: {}\".format(is_safe_count))\n",
    "    df_class_safe = df_class[is_safe]\n",
    "    print(df_class_safe.head(2))\n",
    "    \n",
    "    # get the size of fatal datafram\n",
    "    min_size = df_class_fatal.index.size\n",
    "    print(\"Size of Fatal Subset: {}\".format(min_size))\n",
    "    \n",
    "    # get size of injury\n",
    "    print(\"Size of injury Subset: {}\".format(df_class_injury.index.size))\n",
    "    \n",
    "    # size of non-fatal\n",
    "    print(\"Size of non-fatal Subset: {}\".format(df_class_safe.index.size))\n",
    "    \n",
    "    # randomly sample n number of injury and no injury and append to fatal\n",
    "    df_class_injury_select = df_class_injury.sample(n=min_size)\n",
    "    print(\"Shape of injury sampled dataframe: {}\".format(df_class_injury_select.shape))\n",
    "    df_class_safe_select = df_class_safe.sample(n=min_size)\n",
    "    print(\"Shape of nom-injury sampled dataframe: {}\".format(df_class_safe_select.shape))\n",
    "    \n",
    "    #concat the three dataframes\n",
    "    df_underSample = pd.concat([df_class_fatal, df_class_injury_select, df_class_safe_select])\n",
    "    print(df_underSample.shape)\n",
    "    \n",
    "    #TBD\n",
    "    if sampleN < df_underSample.index.size:\n",
    "        df_sample = df_underSample.sample(n=sampleN)\n",
    "    else:\n",
    "        df_sample = df_underSample.sample(n=df_underSample.index.size)\n",
    "    \n",
    "    #perform the conversion in two steps to avoid any unwanted side effects\n",
    "    df_sample['P_ISEV'] = df_sample['P_ISEV'].map({1: 'safe', 2: 'injury', 3:'fatal'})\n",
    "    df_sample['P_ISEV'] = df_sample['P_ISEV'].map({'safe': '0', 'injury': '1', 'fatal':'2'})\n",
    "    print((df_sample['P_ISEV']=='0').sum())\n",
    "    print((df_sample['P_ISEV']=='1').sum())\n",
    "    print((df_sample['P_ISEV']=='2').sum())\n",
    "    print(df_sample['P_ISEV'].unique())\n",
    "else:\n",
    "    df_class = df_cat.copy()\n",
    "\n",
    "    #perform the conversion in two steps to avoid any unwanted side effects\n",
    "    df_class['P_ISEV'] = df_class['P_ISEV'].map({1: 'safe', 2: 'injury', 3:'fatal'})\n",
    "    df_class['P_ISEV'] = df_class['P_ISEV'].map({'safe': '0', 'injury': '1', 'fatal':'1'})\n",
    "    print((df_class['P_ISEV']=='0').sum())\n",
    "    print((df_class['P_ISEV']=='1').sum())\n",
    "    print(df_class['P_ISEV'].unique())\n",
    "    \n",
    "    df_sample = df_class.sample(n=sampleN)\n",
    "\n",
    "print(\"Size of dataframe for modeling: {}\".format(df_sample.index.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df_sample[df_sample.columns].apply(lambda x: x.astype(str).str.contains('[^0-9]')).sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100000 entries, 4035669 to 2943292\n",
      "Data columns (total 19 columns):\n",
      "C_YEAR    100000 non-null category\n",
      "C_MNTH    100000 non-null category\n",
      "C_WDAY    100000 non-null category\n",
      "C_HOUR    100000 non-null category\n",
      "C_VEHS    100000 non-null category\n",
      "C_CONF    100000 non-null category\n",
      "C_RCFG    100000 non-null category\n",
      "C_WTHR    100000 non-null category\n",
      "C_RSUR    100000 non-null category\n",
      "C_RALN    100000 non-null category\n",
      "C_TRAF    100000 non-null category\n",
      "V_TYPE    100000 non-null category\n",
      "V_YEAR    100000 non-null category\n",
      "P_SEX     100000 non-null category\n",
      "P_AGE     100000 non-null category\n",
      "P_PSN     100000 non-null category\n",
      "P_SAFE    100000 non-null category\n",
      "P_USER    100000 non-null category\n",
      "P_ISEV    100000 non-null int32\n",
      "dtypes: category(18), int32(1)\n",
      "memory usage: 2.9 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# convert to the correct type\n",
    "df['C_YEAR'] = df['C_YEAR'].astype(CategoricalDtype(ordered=True))\n",
    "df['C_MNTH'] = df['C_MNTH'].astype(CategoricalDtype(ordered=True))\n",
    "df['C_WDAY'] = df['C_WDAY'].astype(CategoricalDtype(ordered=True))\n",
    "df['C_HOUR'] = df['C_HOUR'].astype(CategoricalDtype(ordered=True))\n",
    "df['C_VEHS'] = df['C_VEHS'].astype('int')\n",
    "df['V_YEAR'] = df['V_YEAR'].astype(CategoricalDtype(ordered=True))\n",
    "df['P_PSN'] = df['P_PSN'].astype(CategoricalDtype(ordered=True))\n",
    "df['P_AGE'] = df['P_AGE'].astype('int')\n",
    "df_sample['P_ISEV'] = df_sample['P_ISEV'].astype('int')\n",
    "print(df_sample.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training and Testing for Binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split between data and class\n",
    "Y = df_sample[df_sample.columns[-1]]\n",
    "X = df_sample[df_sample.columns[0:df_sample.columns.size -1]]\n",
    "\n",
    "# split data into X and y\n",
    "#X = df_sample.iloc[:,0:16]\n",
    "#Y = df_sample.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "print(Y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C_YEAR C_MNTH C_WDAY C_HOUR C_VEHS C_CONF C_RCFG C_WTHR C_RSUR C_RALN  \\\n",
      "4035669     17      8      2      1      2     35      2      1      1      1   \n",
      "1374245      6      1      5      2      1      4      2      5      4      2   \n",
      "1646812      7      2      1      1      1      6      2      3      2      1   \n",
      "\n",
      "        C_TRAF V_TYPE V_YEAR P_SEX P_AGE P_PSN P_SAFE P_USER  \n",
      "4035669      7      1      5     0    72     1      2      1  \n",
      "1374245      7      1      4     0    19     1      2      1  \n",
      "1646812      1      1      4     0    79     1      2      1  \n"
     ]
    }
   ],
   "source": [
    "print(X.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Test(70%) and Train (30%) for Bianry class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sprint into train and test 70/30\n",
    "#X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the final train and test data for future model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C_YEAR C_MNTH C_WDAY C_HOUR C_VEHS C_CONF C_RCFG C_WTHR C_RSUR C_RALN  \\\n",
      "3947516     17      2      6      0      2     21      2      4      4      1   \n",
      "4283057     18     10      2      1      2     21      4      1      1      1   \n",
      "2821978     11     12      4      2      2     21      1      1      2      1   \n",
      "870475       4      4      1      3      4     21      1      1      1      1   \n",
      "2481189     10      6      4      2      2     21      1      1      1      3   \n",
      "3059730     13      1      1      3      2     22      1      1      2      1   \n",
      "3951136     17      3      1      2      2     22      1      1      1      1   \n",
      "1564522      6     10      5      1      3     51      2      3      2      1   \n",
      "2713785     11      7      1      1      2     36      2      1      1      1   \n",
      "1429235      6      4      4      3      2      6      2      1      1      1   \n",
      "\n",
      "        C_TRAF V_TYPE V_YEAR P_SEX P_AGE P_PSN P_SAFE P_USER  P_ISEV  \n",
      "3947516      2      1      5     0    76     1      4      1       1  \n",
      "4283057      5     14      5     1    15     1      3      3       1  \n",
      "2821978      7      1      4     1    36     1      2      1       0  \n",
      "870475       1      1      4     1    75     1      2      1       0  \n",
      "2481189      7      1      3     0    70     1      2      1       0  \n",
      "3059730      7      1      4     0    45     1      2      1       0  \n",
      "3951136      7      1      4     0    42     1      2      1       1  \n",
      "1564522      1      1      4     0    46     1      2      1       1  \n",
      "2713785      2      1      4     1    46     1      2      1       0  \n",
      "1429235      5      1      4     1    41     1      7      1       0  \n",
      "        C_YEAR C_MNTH C_WDAY C_HOUR C_VEHS C_CONF C_RCFG C_WTHR C_RSUR C_RALN  \\\n",
      "781866       3     12      1      3      2     21      2      1      2      1   \n",
      "2290780      9      8      5      1      3     21      1      1      1      1   \n",
      "1997673      8      6      6      3      2     21      1      1      1      1   \n",
      "1140722      5      3      3      2      2     21      1      1      1      1   \n",
      "72113        1      5      1      3      2     21      1      3      2      2   \n",
      "2639666     11      2      5      4      2     35      2      1      1      1   \n",
      "339575       2      5      2      1      2     21      3      2      1      1   \n",
      "3628808     15      8      5      3      2     35      2      1      1      2   \n",
      "2303086      9      9      2      3      3     21      2      1      1      1   \n",
      "736416       3     10      2      3      2     22      2      1      1      1   \n",
      "\n",
      "        C_TRAF V_TYPE V_YEAR P_SEX P_AGE P_PSN P_SAFE P_USER  P_ISEV  \n",
      "781866       1      1      3     0    44     1      2      1       0  \n",
      "2290780      7      1      4     1     8     2      2      2       0  \n",
      "1997673      7      7      4     1    41     1      2      1       0  \n",
      "1140722      7      1      3     0    34     1      2      1       1  \n",
      "72113        7      1      2     0    32     1      2      1       0  \n",
      "2639666      2      1      4     1    55     1      2      1       0  \n",
      "339575       7      1      2     1    52     1      2      1       0  \n",
      "3628808      2      1      3     1    42     1      5      1       1  \n",
      "2303086      1      1      4     1    29     1      2      1       0  \n",
      "736416       1      5      4     1    26     1      2      1       0  \n"
     ]
    }
   ],
   "source": [
    "FullTrain = X_train.copy()\n",
    "FullTrain['P_ISEV'] = Y_train.copy()\n",
    "FullTrain.to_csv(file_final_train, encoding='utf-8', index=False)\n",
    "print(FullTrain.head(10))\n",
    "\n",
    "FullTest = X_test.copy()\n",
    "FullTest['P_ISEV'] = Y_test.copy()\n",
    "FullTest.to_csv(file_final_test, encoding='utf-8', index=False)\n",
    "print(FullTest.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering based on K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec  2 18:04:42 2018\n",
      "K-Means Clustering: Start\n",
      "KMeans(algorithm='auto', copy_x=True, init='random', max_iter=1000,\n",
      "    n_clusters=3, n_init=10, n_jobs=None, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=3)\n",
      "K-Means Clustering: Build\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 32964405.23405784\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 30940639.987917688\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 27718188.16631597\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 23290693.974585395\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 21475979.090534598\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 21072001.62830391\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 20895201.509040337\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 20772379.50239139\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 20689614.351417188\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 20625675.91941027\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 20579256.537631042\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 20538173.347095057\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 20496752.620887615\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 20464033.859788332\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 20430774.48703181\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 20403395.89550167\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 20377368.117019143\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 20351630.016753495\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 20322996.60357928\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 19, inertia 20282408.001565333\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 20, inertia 20219271.924852766\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 21, inertia 20115836.15617711\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 22, inertia 20015900.58441452\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 23, inertia 19941291.082164947\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 24, inertia 19882073.87170918\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 25, inertia 19827836.53124642\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 26, inertia 19759199.784052555\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 27, inertia 19728516.93910222\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 28, inertia 19716490.424454536\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 29, inertia 19707370.898116767\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 30, inertia 19702010.139438268\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 31, inertia 19693595.11086002\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 32, inertia 19671853.983441453\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 33, inertia 19582164.090388145\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 34, inertia 19451986.84366526\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 35, inertia 19438183.07847686\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 36, inertia 19433617.627680667\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 37, inertia 19432213.339337982\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 38, inertia 19431959.584860288\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 39, inertia 19431909.241216425\n",
      "center shift 4.179718e-02 within tolerance 3.292257e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 19623345.50776408\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 19447922.708575245\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 19430506.235104423\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 19422022.63791196\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 19420098.419628285\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 19419822.067310177\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 19419685.302902494\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 19419650.879460342\n",
      "center shift 2.728856e-02 within tolerance 3.292257e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 21235375.20143092\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 20719751.778392795\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 20644663.76072188\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 20616304.851880506\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 20602860.111791026\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 20593667.331040993\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 20588136.446974386\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 20586240.78691983\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 20585749.163480148\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 20585381.72268272\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 20585068.581025634\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 20584796.854441274\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 20584463.876109492\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 20584156.904248226\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 20583890.669022053\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 20583431.307833053\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 20582806.28496827\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 20582082.223270617\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 20581739.24955711\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 19, inertia 20581654.84351075\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 20, inertia 20581626.44452797\n",
      "center shift 4.129008e-02 within tolerance 3.292257e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 21518010.433459952\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 20794231.061737806\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 20709481.086985275\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 20680746.676062047\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 20660856.140767965\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 20643031.278906733\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 20627741.073665097\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 20618573.648914997\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 20608501.058783974\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 20603211.505994122\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 20600396.40145882\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 20596621.256733395\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 20594608.33673423\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 20592271.61670315\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 20589645.835468743\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 20589142.238212723\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 20588671.583853554\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 20587977.464838702\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 20587187.683838625\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 19, inertia 20585730.725735135\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 20, inertia 20584999.58625301\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 21, inertia 20584670.668842427\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22, inertia 20584449.121372543\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 23, inertia 20584393.384840738\n",
      "center shift 4.405765e-02 within tolerance 3.292257e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 21675337.480296824\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 19527059.073517162\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 19441721.614632636\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 19428435.96533936\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 19421594.104213234\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 19420069.436835904\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 19419795.788651336\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 19419672.555205423\n",
      "center shift 5.707385e-02 within tolerance 3.292257e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 24013863.51299679\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 23119267.34602635\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 21796582.04317157\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 19627084.066261403\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 19456894.34651218\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 19431128.48725266\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 19421518.762837213\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 19420104.520401224\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 19419805.140508194\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 19419672.555205423\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 19419643.737910427\n",
      "center shift 3.092659e-02 within tolerance 3.292257e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 21996585.454091743\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 20626471.779853884\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 20117012.85641188\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 19911628.1400348\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 19826509.38186365\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 19761830.044229567\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 19730283.72181117\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 19721131.792087022\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 19713912.004618365\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 19708987.98609557\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 19705813.336016074\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 19701579.25980121\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 19692258.28238028\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 19664770.365439072\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 19540757.033607926\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 19446131.295847654\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 19437020.00607227\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 19433250.278013114\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 19432162.571780622\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 19, inertia 19431946.369014177\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 20, inertia 19431907.848792102\n",
      "center shift 3.434816e-02 within tolerance 3.292257e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 27249228.32566466\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 22158658.941472914\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 20696225.965383593\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 20307744.741984803\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 20109453.166035894\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 19989581.189880762\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 19912450.400564555\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 19855411.91293675\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 19789677.822691917\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 19739650.803992413\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 19721101.11402943\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 19709423.183385525\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 19703724.65657676\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 19698114.342890967\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 19682968.335782774\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 19638660.824805286\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 19477357.86457104\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 19440950.77137179\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 19434894.30925974\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 19, inertia 19432493.516843453\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 20, inertia 19431995.01144059\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 21, inertia 19431911.913769435\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 22, inertia 19431904.0661679\n",
      "center shift 1.619291e-02 within tolerance 3.292257e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 19916034.1467574\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 19644662.295329694\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 19599440.86890394\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 19584439.508115675\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 19573623.28101197\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 19562665.206350744\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 19528968.030094646\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 19455827.74253775\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 19434511.48603504\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 19432091.514914557\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 19431933.429909382\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 19431910.96323444\n",
      "center shift 3.004737e-02 within tolerance 3.292257e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 22703507.045795113\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 21621278.165403347\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 21281939.40705639\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 21060263.556840878\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 20862373.532789037\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 20567893.839601375\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 20201876.995378867\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 19775510.66617821\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 19613435.287400685\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 19582965.52742472\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 19573651.068486147\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 19570576.782682706\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 19570242.171850555\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 19570200.29091601\n",
      "center shift 3.605545e-02 within tolerance 3.292257e-03\n",
      "[[ 9.43957658  6.68978377  3.90213215  2.3006856   2.11930234 25.89749868\n",
      "   1.76312815  1.56603631  1.53209523  1.30437731  4.28188804  2.58347774\n",
      "   3.59899797  0.53981767 56.31601748  1.10656973  2.3583214   1.31112032]\n",
      " [ 8.68371178  6.74530663  4.24843554  2.13481137  1.10137672  4.3133381\n",
      "   1.4648668   1.78812802  1.9156088   1.65331665  5.9824781   4.93268371\n",
      "   3.21759342  0.57554085 26.32209905  1.40801001  2.60611479  1.62828536]\n",
      " [ 8.66660469  6.70267758  4.04143424  2.41710053  2.24916326 29.37185447\n",
      "   1.78467832  1.57474898  1.53303582  1.28579398  4.18739928  2.071433\n",
      "   3.52820131  0.53421346 24.06225982  1.21209867  2.29487418  1.45856576]]\n",
      "[0 2 2 ... 0 0 0]\n",
      "K-Means Clustering: End\n",
      "Sun Dec  2 18:04:47 2018\n"
     ]
    }
   ],
   "source": [
    "if enable_kmean:\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print(\"K-Means Clustering: Start\")\n",
    "    kmeans = KMeans(n_clusters=3, init='random', n_init=10, tol=1e-04, verbose= verbose_level, max_iter=model_max_iter)\n",
    "    print(kmeans)\n",
    "    \n",
    "    print(\"K-Means Clustering: Build\")\n",
    "    ykm = kmeans.fit(X_train)\n",
    "    \n",
    "    if pyscript:\n",
    "        print(ykm.cluster_centers_)\n",
    "        print(ykm.labels_)\n",
    "    else:\n",
    "        display(ykm.cluster_centers_)\n",
    "        display(ykm.labels_)\n",
    "    \n",
    "    # save model to file\n",
    "    pickle.dump(ykm, open(file_kmean, \"wb\"))\n",
    "    \n",
    "    print(\"K-Means Clustering: End\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM GridSearch for Optimal Parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This operation is computationaly expensive.\n",
    "if enable_grid_search:\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    param_grid = {'C':[0.1, 1, 10, 100, 1000], 'gamma':[1, 0.1, 0.01, 0.001, 0.0001]}\n",
    "    grid = GridSearchCV(SVC(), param_grid, verbose=verbose_level)\n",
    "    print(grid)\n",
    "    grid.fit(X_train, Y_train)\n",
    "    print(grid.best_params_)\n",
    "    svm_c = grid.best_params_.get('C')\n",
    "    svm_gamma = grid.best_params_.get('gamma')\n",
    "    print(grid.best_estimator_)\n",
    "    grid_predictions = grid.predict(X_test)\n",
    "    cfn_matrix_grid = confusion_matrix(Y_test, grid_predictions)\n",
    "    print(cfn_matrix_grid)\n",
    "    print(classification_report(Y_test,grid_predictions))\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Start\n",
      "Sun Dec  2 18:04:47 2018\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='auto',\n",
      "          n_jobs=10, penalty='l2', random_state=0, solver='saga',\n",
      "          tol=0.0001, verbose=3, warm_start=False)\n",
      "Logistic Regression: Fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 171 epochs took 5 seconds\n",
      "Logistic Regression: Predict\n",
      "Accuracy of logistic regression classifier on train set: 0.64\n",
      "Accuracy of logistic regression classifier on test set: 0.64\n",
      "Logistic Regression: Intercept\n",
      "[2.10892553]\n",
      "Logistic Regression: Coefficients\n",
      "[[ 9.96489692e-03 -9.70543762e-05 -5.86507754e-03 -7.54283526e-02\n",
      "  -4.13065329e-01 -1.34949777e-03 -9.19852451e-02  1.43856304e-02\n",
      "   4.90666864e-02  1.30873663e-01  3.83137071e-02  8.49061163e-02\n",
      "  -2.01051559e-01 -7.29137075e-01  6.84988089e-03 -3.90707993e-01\n",
      "  -1.55474309e-01  3.02406883e-01]]\n",
      "Logistic Regression: Confusion Matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5649  7031]\n",
      " [ 3879 13441]]\n",
      "Logistic Regression: Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.45      0.51     12680\n",
      "           1       0.66      0.78      0.71     17320\n",
      "\n",
      "   micro avg       0.64      0.64      0.64     30000\n",
      "   macro avg       0.62      0.61      0.61     30000\n",
      "weighted avg       0.63      0.64      0.63     30000\n",
      "\n",
      "Sun Dec  2 18:04:53 2018\n",
      "Logistic Regression: End\n"
     ]
    }
   ],
   "source": [
    "if enable_lr:\n",
    "    print(\"Logistic Regression: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    lr = LogisticRegression(C=1, random_state=0, solver='saga', multi_class='auto', \n",
    "                            verbose=verbose_level, n_jobs=10, max_iter=model_max_iter)\n",
    "    print(lr)\n",
    "    print(\"Logistic Regression: Fit\")\n",
    "    lr.fit(X_train, Y_train)\n",
    "    \n",
    "    # save model to file\n",
    "    pickle.dump(lr, open(file_lr, \"wb\"))\n",
    "    \n",
    "    \n",
    "if predict_lr:\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_lr, \"rb\"))\n",
    "    print(\"Logistic Regression: Predict\")\n",
    "    y_pred = lr.predict(X_test)\n",
    "\n",
    "    print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(lr.score(X_train, Y_train)))\n",
    "    print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(lr.score(X_test, Y_test)))\n",
    "\n",
    "    # print the intercept (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "    print(\"Logistic Regression: Intercept\")\n",
    "    print(lr.intercept_)\n",
    "\n",
    "    # print the coeficients (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "    print(\"Logistic Regression: Coefficients\")\n",
    "    print(lr.coef_)\n",
    "\n",
    "    print(\"Logistic Regression: Confusion Matrix\")\n",
    "    cnf_matrix_lg = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_lg)\n",
    "    \n",
    "    print(\"Logistic Regression: Classification Report\")\n",
    "    print(classification_report(Y_test, y_pred))\n",
    "\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"Logistic Regression: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with L1 Regularization: Start\n",
      "Sun Dec  2 18:04:53 2018\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='auto',\n",
      "          n_jobs=10, penalty='l1', random_state=None, solver='saga',\n",
      "          tol=0.0001, verbose=3, warm_start=False)\n",
      "Logistic Regression with L1 Regularization: Fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 168 epochs took 6 seconds\n",
      "Logistic Regression with L1 Regularization: Predict\n",
      "Accuracy of logistic regression classifier on train set: 0.64\n",
      "Accuracy of logistic regression classifier on test set: 0.64\n",
      "Logistic Regression with L1 Regularization: Confusion Matrix\n",
      "[[ 5648  7032]\n",
      " [ 3878 13442]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:    6.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.45      0.51     12680\n",
      "           1       0.66      0.78      0.71     17320\n",
      "\n",
      "   micro avg       0.64      0.64      0.64     30000\n",
      "   macro avg       0.62      0.61      0.61     30000\n",
      "weighted avg       0.63      0.64      0.63     30000\n",
      "\n",
      "Logistic Regression with L1 Regularization: Classification Report\n",
      "Sun Dec  2 18:04:59 2018\n",
      "Logistic Regression with L1 Regularization: End\n"
     ]
    }
   ],
   "source": [
    "if (enable_lr_l1):\n",
    "    # with L1 regularization\n",
    "    print(\"Logistic Regression with L1 Regularization: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    lr = LogisticRegression(penalty='l1', C=1, solver='saga', multi_class='auto', \n",
    "                            verbose=verbose_level, n_jobs = 10, max_iter=model_max_iter)\n",
    "    print(lr)\n",
    "    print(\"Logistic Regression with L1 Regularization: Fit\")\n",
    "    lr.fit(X_train, Y_train)\n",
    "    \n",
    "    # save model to file\n",
    "    pickle.dump(lr, open(file_lr_l1, \"wb\"))\n",
    "\n",
    "if (predict_lr_l1):\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_lr_l1, \"rb\"))\n",
    "    print(\"Logistic Regression with L1 Regularization: Predict\")\n",
    "    y_pred = lr.predict(X_test)\n",
    "    \n",
    "    print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(lr.score(X_train, Y_train)))\n",
    "    print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(lr.score(X_test, Y_test)))\n",
    "\n",
    "    print(\"Logistic Regression with L1 Regularization: Confusion Matrix\")\n",
    "    cnf_matrix_lg_l1 = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_lg_l1)\n",
    "    \n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    print(\"Logistic Regression with L1 Regularization: Classification Report\")\n",
    "\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"Logistic Regression with L1 Regularization: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes: Start\n",
      "Sun Dec  2 18:04:59 2018\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "Naive Bayes: Fit\n",
      "Naive Bayes: Predict\n",
      "Accuracy of Naive Bayes classifier on train set: 0.54\n",
      "Accuracy of Naove Nayes classifier on test set: 0.55\n",
      "Naive Bayes: Confusion Matrix\n",
      "[[10076  2604]\n",
      " [10957  6363]]\n",
      "Naive Bayes: Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.79      0.60     12680\n",
      "           1       0.71      0.37      0.48     17320\n",
      "\n",
      "   micro avg       0.55      0.55      0.55     30000\n",
      "   macro avg       0.59      0.58      0.54     30000\n",
      "weighted avg       0.61      0.55      0.53     30000\n",
      "\n",
      "Sun Dec  2 18:04:59 2018\n",
      "Naive Bayes: End\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes Classification\n",
    "if enable_nbayes:\n",
    "    print(\"Naive Bayes: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    nbayes = GaussianNB()\n",
    "    print(nbayes)\n",
    "    print(\"Naive Bayes: Fit\")\n",
    "    nbayes.fit(X_train, Y_train)\n",
    "    # save model to file\n",
    "    pickle.dump(nbayes, open(file_nbayes, \"wb\"))\n",
    "\n",
    "if predict_nbayes:\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_nbayes, \"rb\"))\n",
    "    print(\"Naive Bayes: Predict\")\n",
    "    y_pred = nbayes.predict(X_test)\n",
    "    print('Accuracy of Naive Bayes classifier on train set: {:.2f}'.format(nbayes.score(X_train, Y_train)))\n",
    "    print('Accuracy of Naove Nayes classifier on test set: {:.2f}'.format(nbayes.score(X_test, Y_test)))\n",
    "    \n",
    "    cnf_matrix_dt = confusion_matrix(Y_test, y_pred)\n",
    "    print(\"Naive Bayes: Confusion Matrix\")\n",
    "    print(cnf_matrix_dt)\n",
    "    print(\"Naive Bayes: Classification Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    print(\"Naive Bayes: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: Start\n",
      "Sun Dec  2 18:04:59 2018\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=50,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "Decision Tree: Fit\n",
      "Decision Tree: Predict\n",
      "Accuracy of Decision Tree classifier on train set: 1.00\n",
      "Accuracy of Decision Tree classifier on test set: 0.61\n",
      "Decision Tree: Confusion Matrix\n",
      "[[ 6760  5920]\n",
      " [ 5891 11429]]\n",
      "Decision Tree: Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.53      0.53     12680\n",
      "           1       0.66      0.66      0.66     17320\n",
      "\n",
      "   micro avg       0.61      0.61      0.61     30000\n",
      "   macro avg       0.60      0.60      0.60     30000\n",
      "weighted avg       0.61      0.61      0.61     30000\n",
      "\n",
      "Sun Dec  2 18:05:00 2018\n",
      "Decision Tree: End\n"
     ]
    }
   ],
   "source": [
    "if enable_dt:\n",
    "    print(\"Decision Tree: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    tree = DecisionTreeClassifier(criterion='entropy',max_depth=50)\n",
    "    print(tree)\n",
    "    print(\"Decision Tree: Fit\")\n",
    "    tree.fit(X_train, Y_train)\n",
    "    # save model to file\n",
    "    pickle.dump(tree, open(file_dt, \"wb\"))\n",
    "\n",
    "if predict_dt:\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_dt, \"rb\"))\n",
    "    print(\"Decision Tree: Predict\")\n",
    "    y_pred = tree.predict(X_test)\n",
    "    print('Accuracy of Decision Tree classifier on train set: {:.2f}'.format(tree.score(X_train, Y_train)))\n",
    "    print('Accuracy of Decision Tree classifier on test set: {:.2f}'.format(tree.score(X_test, Y_test)))\n",
    "    \n",
    "    cnf_matrix_dt = confusion_matrix(Y_test, y_pred)\n",
    "    print(\"Decision Tree: Confusion Matrix\")\n",
    "    print(cnf_matrix_dt)\n",
    "    print(\"Decision Tree: Classification Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    print(\"Decision Tree: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-N-N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: Start\n",
      "Sun Dec  2 18:05:00 2018\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=10, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNN: Fit\n",
      "KNN: Predict\n",
      "Accuracy of KNN classifier on train set: 0.75\n",
      "Accuracy of KNN classifier on test set: 0.61\n",
      "KNN: Confusion Matrix\n",
      "[[ 6098  6582]\n",
      " [ 5162 12158]]\n",
      "KNN: Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.48      0.51     12680\n",
      "           1       0.65      0.70      0.67     17320\n",
      "\n",
      "   micro avg       0.61      0.61      0.61     30000\n",
      "   macro avg       0.60      0.59      0.59     30000\n",
      "weighted avg       0.60      0.61      0.60     30000\n",
      "\n",
      "Sun Dec  2 18:05:05 2018\n",
      "KNN: End\n"
     ]
    }
   ],
   "source": [
    "if enable_knn:\n",
    "    print(\"KNN: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    knn = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski', n_jobs = 10)\n",
    "    print(knn)\n",
    "    print(\"KNN: Fit\")\n",
    "    knn.fit(X_train, Y_train)\n",
    "\n",
    "    # save model to file\n",
    "    pickle.dump(knn, open(file_knn, \"wb\"))\n",
    "\n",
    "if predict_knn:\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_knn, \"rb\"))\n",
    "    \n",
    "    print(\"KNN: Predict\")\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print('Accuracy of KNN classifier on train set: {:.2f}'.format(knn.score(X_train, Y_train)))\n",
    "    print('Accuracy of KNN classifier on test set: {:.2f}'.format(knn.score(X_test, Y_test)))\n",
    "    \n",
    "    print(\"KNN: Confusion Matrix\")\n",
    "    cnf_matrix_knn = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_knn)\n",
    "\n",
    "    print(\"KNN: Classification Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "\n",
    "    print(\"KNN: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN - Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Preceptron: Start\n",
      "Sun Dec  2 18:05:05 2018\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(25, 25, 25), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=3, warm_start=False)\n",
      "Multilayer Preceptron: fit\n",
      "Iteration 1, loss = 0.64593347\n",
      "Iteration 2, loss = 0.61854109\n",
      "Iteration 3, loss = 0.60661035\n",
      "Iteration 4, loss = 0.60251818\n",
      "Iteration 5, loss = 0.59998747\n",
      "Iteration 6, loss = 0.59884675\n",
      "Iteration 7, loss = 0.59768068\n",
      "Iteration 8, loss = 0.59704098\n",
      "Iteration 9, loss = 0.59627915\n",
      "Iteration 10, loss = 0.59407944\n",
      "Iteration 11, loss = 0.59440428\n",
      "Iteration 12, loss = 0.59310135\n",
      "Iteration 13, loss = 0.59289441\n",
      "Iteration 14, loss = 0.59213067\n",
      "Iteration 15, loss = 0.59195872\n",
      "Iteration 16, loss = 0.59116581\n",
      "Iteration 17, loss = 0.59082053\n",
      "Iteration 18, loss = 0.59032702\n",
      "Iteration 19, loss = 0.59053137\n",
      "Iteration 20, loss = 0.58946059\n",
      "Iteration 21, loss = 0.58941369\n",
      "Iteration 22, loss = 0.58921438\n",
      "Iteration 23, loss = 0.58901301\n",
      "Iteration 24, loss = 0.58856862\n",
      "Iteration 25, loss = 0.58851231\n",
      "Iteration 26, loss = 0.58820212\n",
      "Iteration 27, loss = 0.58778976\n",
      "Iteration 28, loss = 0.58714823\n",
      "Iteration 29, loss = 0.58745089\n",
      "Iteration 30, loss = 0.58689979\n",
      "Iteration 31, loss = 0.58682273\n",
      "Iteration 32, loss = 0.58675133\n",
      "Iteration 33, loss = 0.58655388\n",
      "Iteration 34, loss = 0.58630614\n",
      "Iteration 35, loss = 0.58587106\n",
      "Iteration 36, loss = 0.58603851\n",
      "Iteration 37, loss = 0.58531238\n",
      "Iteration 38, loss = 0.58542436\n",
      "Iteration 39, loss = 0.58582458\n",
      "Iteration 40, loss = 0.58440496\n",
      "Iteration 41, loss = 0.58488616\n",
      "Iteration 42, loss = 0.58460183\n",
      "Iteration 43, loss = 0.58378307\n",
      "Iteration 44, loss = 0.58432650\n",
      "Iteration 45, loss = 0.58384384\n",
      "Iteration 46, loss = 0.58357541\n",
      "Iteration 47, loss = 0.58361978\n",
      "Iteration 48, loss = 0.58273840\n",
      "Iteration 49, loss = 0.58283708\n",
      "Iteration 50, loss = 0.58282922\n",
      "Iteration 51, loss = 0.58299536\n",
      "Iteration 52, loss = 0.58238598\n",
      "Iteration 53, loss = 0.58211654\n",
      "Iteration 54, loss = 0.58300026\n",
      "Iteration 55, loss = 0.58216315\n",
      "Iteration 56, loss = 0.58147423\n",
      "Iteration 57, loss = 0.58139732\n",
      "Iteration 58, loss = 0.58203630\n",
      "Iteration 59, loss = 0.58121545\n",
      "Iteration 60, loss = 0.58092064\n",
      "Iteration 61, loss = 0.58031379\n",
      "Iteration 62, loss = 0.58156768\n",
      "Iteration 63, loss = 0.58036632\n",
      "Iteration 64, loss = 0.58014515\n",
      "Iteration 65, loss = 0.58061974\n",
      "Iteration 66, loss = 0.57993814\n",
      "Iteration 67, loss = 0.58008514\n",
      "Iteration 68, loss = 0.57958359\n",
      "Iteration 69, loss = 0.57947082\n",
      "Iteration 70, loss = 0.57912392\n",
      "Iteration 71, loss = 0.57937710\n",
      "Iteration 72, loss = 0.57886943\n",
      "Iteration 73, loss = 0.57909622\n",
      "Iteration 74, loss = 0.57868987\n",
      "Iteration 75, loss = 0.57861445\n",
      "Iteration 76, loss = 0.57870402\n",
      "Iteration 77, loss = 0.57909244\n",
      "Iteration 78, loss = 0.57844087\n",
      "Iteration 79, loss = 0.57797214\n",
      "Iteration 80, loss = 0.57756672\n",
      "Iteration 81, loss = 0.57785477\n",
      "Iteration 82, loss = 0.57760465\n",
      "Iteration 83, loss = 0.57691286\n",
      "Iteration 84, loss = 0.57748056\n",
      "Iteration 85, loss = 0.57708820\n",
      "Iteration 86, loss = 0.57707657\n",
      "Iteration 87, loss = 0.57656458\n",
      "Iteration 88, loss = 0.57680877\n",
      "Iteration 89, loss = 0.57666799\n",
      "Iteration 90, loss = 0.57654189\n",
      "Iteration 91, loss = 0.57611910\n",
      "Iteration 92, loss = 0.57615162\n",
      "Iteration 93, loss = 0.57662323\n",
      "Iteration 94, loss = 0.57617938\n",
      "Iteration 95, loss = 0.57623417\n",
      "Iteration 96, loss = 0.57578651\n",
      "Iteration 97, loss = 0.57650238\n",
      "Iteration 98, loss = 0.57609453\n",
      "Iteration 99, loss = 0.57603850\n",
      "Iteration 100, loss = 0.57546506\n",
      "Iteration 101, loss = 0.57521215\n",
      "Iteration 102, loss = 0.57511220\n",
      "Iteration 103, loss = 0.57525303\n",
      "Iteration 104, loss = 0.57523330\n",
      "Iteration 105, loss = 0.57509969\n",
      "Iteration 106, loss = 0.57513989\n",
      "Iteration 107, loss = 0.57421989\n",
      "Iteration 108, loss = 0.57543670\n",
      "Iteration 109, loss = 0.57436116\n",
      "Iteration 110, loss = 0.57462440\n",
      "Iteration 111, loss = 0.57458308\n",
      "Iteration 112, loss = 0.57454387\n",
      "Iteration 113, loss = 0.57457667\n",
      "Iteration 114, loss = 0.57412338\n",
      "Iteration 115, loss = 0.57443345\n",
      "Iteration 116, loss = 0.57383912\n",
      "Iteration 117, loss = 0.57371081\n",
      "Iteration 118, loss = 0.57460655\n",
      "Iteration 119, loss = 0.57344939\n",
      "Iteration 120, loss = 0.57410891\n",
      "Iteration 121, loss = 0.57388524\n",
      "Iteration 122, loss = 0.57386170\n",
      "Iteration 123, loss = 0.57314878\n",
      "Iteration 124, loss = 0.57365553\n",
      "Iteration 125, loss = 0.57349178\n",
      "Iteration 126, loss = 0.57344395\n",
      "Iteration 127, loss = 0.57302750\n",
      "Iteration 128, loss = 0.57329791\n",
      "Iteration 129, loss = 0.57301732\n",
      "Iteration 130, loss = 0.57287224\n",
      "Iteration 131, loss = 0.57265365\n",
      "Iteration 132, loss = 0.57280915\n",
      "Iteration 133, loss = 0.57258486\n",
      "Iteration 134, loss = 0.57308322\n",
      "Iteration 135, loss = 0.57226884\n",
      "Iteration 136, loss = 0.57265922\n",
      "Iteration 137, loss = 0.57237227\n",
      "Iteration 138, loss = 0.57233749\n",
      "Iteration 139, loss = 0.57204580\n",
      "Iteration 140, loss = 0.57217199\n",
      "Iteration 141, loss = 0.57243707\n",
      "Iteration 142, loss = 0.57133972\n",
      "Iteration 143, loss = 0.57157401\n",
      "Iteration 144, loss = 0.57170631\n",
      "Iteration 145, loss = 0.57171313\n",
      "Iteration 146, loss = 0.57161005\n",
      "Iteration 147, loss = 0.57195898\n",
      "Iteration 148, loss = 0.57131217\n",
      "Iteration 149, loss = 0.57137999\n",
      "Iteration 150, loss = 0.57116351\n",
      "Iteration 151, loss = 0.57123130\n",
      "Iteration 152, loss = 0.57094570\n",
      "Iteration 153, loss = 0.57084665\n",
      "Iteration 154, loss = 0.57124950\n",
      "Iteration 155, loss = 0.57098568\n",
      "Iteration 156, loss = 0.57094080\n",
      "Iteration 157, loss = 0.57029989\n",
      "Iteration 158, loss = 0.57061439\n",
      "Iteration 159, loss = 0.57085425\n",
      "Iteration 160, loss = 0.57095785\n",
      "Iteration 161, loss = 0.57028393\n",
      "Iteration 162, loss = 0.57054281\n",
      "Iteration 163, loss = 0.56993576\n",
      "Iteration 164, loss = 0.56985778\n",
      "Iteration 165, loss = 0.57076183\n",
      "Iteration 166, loss = 0.56974822\n",
      "Iteration 167, loss = 0.56988266\n",
      "Iteration 168, loss = 0.57006140\n",
      "Iteration 169, loss = 0.56964033\n",
      "Iteration 170, loss = 0.56929416\n",
      "Iteration 171, loss = 0.56974260\n",
      "Iteration 172, loss = 0.56986777\n",
      "Iteration 173, loss = 0.56978031\n",
      "Iteration 174, loss = 0.56987662\n",
      "Iteration 175, loss = 0.56966844\n",
      "Iteration 176, loss = 0.56954343\n",
      "Iteration 177, loss = 0.56958069\n",
      "Iteration 178, loss = 0.56848941\n",
      "Iteration 179, loss = 0.56915523\n",
      "Iteration 180, loss = 0.56912372\n",
      "Iteration 181, loss = 0.56954468\n",
      "Iteration 182, loss = 0.56932323\n",
      "Iteration 183, loss = 0.56927911\n",
      "Iteration 184, loss = 0.56827198\n",
      "Iteration 185, loss = 0.56868168\n",
      "Iteration 186, loss = 0.56901415\n",
      "Iteration 187, loss = 0.56853512\n",
      "Iteration 188, loss = 0.56869773\n",
      "Iteration 189, loss = 0.56841266\n",
      "Iteration 190, loss = 0.56852606\n",
      "Iteration 191, loss = 0.56881027\n",
      "Iteration 192, loss = 0.56852367\n",
      "Iteration 193, loss = 0.56888138\n",
      "Iteration 194, loss = 0.56856955\n",
      "Iteration 195, loss = 0.56791334\n",
      "Iteration 196, loss = 0.56835060\n",
      "Iteration 197, loss = 0.56784965\n",
      "Iteration 198, loss = 0.56832718\n",
      "Iteration 199, loss = 0.56818585\n",
      "Iteration 200, loss = 0.56748873\n",
      "Iteration 201, loss = 0.56806636\n",
      "Iteration 202, loss = 0.56779757\n",
      "Iteration 203, loss = 0.56805176\n",
      "Iteration 204, loss = 0.56788222\n",
      "Iteration 205, loss = 0.56831928\n",
      "Iteration 206, loss = 0.56738606\n",
      "Iteration 207, loss = 0.56731802\n",
      "Iteration 208, loss = 0.56763723\n",
      "Iteration 209, loss = 0.56725338\n",
      "Iteration 210, loss = 0.56720556\n",
      "Iteration 211, loss = 0.56746100\n",
      "Iteration 212, loss = 0.56717954\n",
      "Iteration 213, loss = 0.56759348\n",
      "Iteration 214, loss = 0.56707762\n",
      "Iteration 215, loss = 0.56742655\n",
      "Iteration 216, loss = 0.56709613\n",
      "Iteration 217, loss = 0.56665781\n",
      "Iteration 218, loss = 0.56624986\n",
      "Iteration 219, loss = 0.56687532\n",
      "Iteration 220, loss = 0.56717220\n",
      "Iteration 221, loss = 0.56677150\n",
      "Iteration 222, loss = 0.56661535\n",
      "Iteration 223, loss = 0.56686743\n",
      "Iteration 224, loss = 0.56623415\n",
      "Iteration 225, loss = 0.56658740\n",
      "Iteration 226, loss = 0.56637751\n",
      "Iteration 227, loss = 0.56635940\n",
      "Iteration 228, loss = 0.56686991\n",
      "Iteration 229, loss = 0.56578777\n",
      "Iteration 230, loss = 0.56585149\n",
      "Iteration 231, loss = 0.56632627\n",
      "Iteration 232, loss = 0.56601871\n",
      "Iteration 233, loss = 0.56553350\n",
      "Iteration 234, loss = 0.56615704\n",
      "Iteration 235, loss = 0.56595361\n",
      "Iteration 236, loss = 0.56577798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 237, loss = 0.56534169\n",
      "Iteration 238, loss = 0.56530701\n",
      "Iteration 239, loss = 0.56573264\n",
      "Iteration 240, loss = 0.56556008\n",
      "Iteration 241, loss = 0.56581817\n",
      "Iteration 242, loss = 0.56538968\n",
      "Iteration 243, loss = 0.56567726\n",
      "Iteration 244, loss = 0.56522010\n",
      "Iteration 245, loss = 0.56565549\n",
      "Iteration 246, loss = 0.56511486\n",
      "Iteration 247, loss = 0.56564569\n",
      "Iteration 248, loss = 0.56476852\n",
      "Iteration 249, loss = 0.56448517\n",
      "Iteration 250, loss = 0.56501485\n",
      "Iteration 251, loss = 0.56560523\n",
      "Iteration 252, loss = 0.56507850\n",
      "Iteration 253, loss = 0.56494024\n",
      "Iteration 254, loss = 0.56535923\n",
      "Iteration 255, loss = 0.56477252\n",
      "Iteration 256, loss = 0.56444147\n",
      "Iteration 257, loss = 0.56528696\n",
      "Iteration 258, loss = 0.56436637\n",
      "Iteration 259, loss = 0.56485252\n",
      "Iteration 260, loss = 0.56436304\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Multilayer Preceptron: Predict\n",
      "Accuracy of Multilayer Perceptron classifier on train set: 0.68\n",
      "Accuracy of Multilayer Perceptron classifier on test set: 0.66\n",
      "Multilayer Preceptron: Confusion Matrix\n",
      "[[ 7982  4698]\n",
      " [ 5378 11942]]\n",
      "Multilayer Preceptron: Classificiation Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.63      0.61     12680\n",
      "           1       0.72      0.69      0.70     17320\n",
      "\n",
      "   micro avg       0.66      0.66      0.66     30000\n",
      "   macro avg       0.66      0.66      0.66     30000\n",
      "weighted avg       0.67      0.66      0.67     30000\n",
      "\n",
      "Sun Dec  2 18:06:11 2018\n",
      "Multilayer Preceptron: End\n"
     ]
    }
   ],
   "source": [
    "if enable_mlp:\n",
    "    print(\"Multilayer Preceptron: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    \n",
    "    #mlpc = MLPClassifier(alpha=1)\n",
    "    #mlpc = MLPClassifier(hidden_layer_sizes=(12, 12, 12), max_iter=model_max_iter, verbose=verbose_level)\n",
    "    mlpc = MLPClassifier(hidden_layer_sizes=(25, 25, 25), verbose=verbose_level, max_iter=model_max_iter)\n",
    "    print(mlpc)\n",
    "    #mlp = multilayer_perceptron(n_hidden =2, activation='logistic', algorithm='sgd', random_state=3)\n",
    "    print(\"Multilayer Preceptron: fit\")\n",
    "    mlpc.fit(X_train, Y_train)\n",
    "    \n",
    "    # save model to file\n",
    "    pickle.dump(mlpc, open(file_mlp, \"wb\"))\n",
    "    \n",
    "if predict_mlp:\n",
    "    \n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_mlp, \"rb\"))\n",
    "    print(\"Multilayer Preceptron: Predict\")\n",
    "    y_pred = mlpc.predict(X_test)\n",
    "\n",
    "    print('Accuracy of Multilayer Perceptron classifier on train set: {:.2f}'.format(mlpc.score(X_train, Y_train)))\n",
    "    print('Accuracy of Multilayer Perceptron classifier on test set: {:.2f}'.format(mlpc.score(X_test, Y_test)))\n",
    "    \n",
    "    print(\"Multilayer Preceptron: Confusion Matrix\")\n",
    "    cnf_matrix_mlp = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_mlp)\n",
    "    \n",
    "    print(\"Multilayer Preceptron: Classificiation Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "    print(\"Multilayer Preceptron: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: Start\n",
      "Sun Dec  2 18:06:11 2018\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=1000, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=3)\n",
      "SVM: Fit\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:244: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: Predict\n",
      "Accuracy of SVM classifier on train set: 0.43\n",
      "Accuracy of SVM classifier on test set: 0.43\n",
      "SVM: Confusion Matrix\n",
      "[[11680  1000]\n",
      " [16186  1134]]\n",
      "SVM: Classfication Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.92      0.58     12680\n",
      "           1       0.53      0.07      0.12     17320\n",
      "\n",
      "   micro avg       0.43      0.43      0.43     30000\n",
      "   macro avg       0.48      0.49      0.35     30000\n",
      "weighted avg       0.48      0.43      0.31     30000\n",
      "\n",
      "Sun Dec  2 18:06:22 2018\n",
      "SVM: End\n"
     ]
    }
   ],
   "source": [
    "if enable_svm:\n",
    "    print(\"SVM: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    #svm = SVC(C=1, random_state=0, kernel='sigmoid', verbose=True)\n",
    "    #svm = SVC(C=1, random_state=0, kernel='linear', verbose=True, cache_size=200)\n",
    "    #svm = SVC(C=svm_c, gamma=svm_gamma, verbose = verbose_level)\n",
    "    #SVN prediction is taking for ever, limiting the max_iter to 100 instead of -1 (no limit)\n",
    "    svm = SVC(C=1, gamma = 'auto', verbose = verbose_level, max_iter=model_max_iter)\n",
    "    print(svm)\n",
    "    print(\"SVM: Fit\")\n",
    "    svm.fit(X_train, Y_train)\n",
    "\n",
    "    # save model to file\n",
    "    pickle.dump(svm, open(file_svm, \"wb\"))\n",
    "    \n",
    "if predict_svm:\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_svm, \"rb\"))\n",
    "    print(\"SVM: Predict\")\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    print('Accuracy of SVM classifier on train set: {:.2f}'.format(svm.score(X_train, Y_train)))\n",
    "    print('Accuracy of SVM classifier on test set: {:.2f}'.format(svm.score(X_test, Y_test)))\n",
    "    \n",
    "    print(\"SVM: Confusion Matrix\")\n",
    "    cnf_matrix_svm = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_svm)\n",
    "    \n",
    "    print(\"SVM: Classfication Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "    print(\"SVM: End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec  2 18:06:22 2018\n"
     ]
    }
   ],
   "source": [
    "t_end =  time.time()\n",
    "print(time.asctime( time.localtime(t_end) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
