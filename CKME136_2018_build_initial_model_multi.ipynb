{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activating auto-logging. Current session state plus future input saved.\n",
      "Filename       : ipython_log.py\n",
      "Mode           : rotate\n",
      "Output logging : True\n",
      "Raw input log  : False\n",
      "Timestamping   : True\n",
      "State          : active\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%logstart -o -t\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "#in case we need to repeat experiment\n",
    "np.random.seed(255)\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 22\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('classic')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "#sklearn imports\n",
    "from sklearn.cluster import KMeans\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "#Use print instead of display when run as python script\n",
    "pyscript = True\n",
    "\n",
    "#Classifier verborsity where supported\n",
    "verbose_level=4\n",
    "\n",
    "#Sample Size\n",
    "sampleN = 2000\n",
    "\n",
    "import time\n",
    "\n",
    "#Enable Optimization Algorithms\n",
    "enable_grid_search = False\n",
    "svm_c = 1\n",
    "svm_gamma = 1\n",
    "enable_rf_features = True\n",
    "feature_all = False\n",
    "defaultFeatures = ['P_AGE', 'V_YEAR', 'C_HOUR', 'C_YEAR', 'C_MNTH', 'C_CONF', 'C_WDAY', 'C_VEHS', 'P_USER', 'P_SEX']\n",
    "enable_kmeans = True\n",
    "enable_logistic_regression_l1 = True\n",
    "\n",
    "# Enable Algorithms\n",
    "enable_logistic_regression = True\n",
    "enable_decision_tree = True\n",
    "enable_svm = True\n",
    "enable_knn = True\n",
    "enable_mlp = True\n",
    "enable_rf = True\n",
    "\n",
    "#Multiclass classification, binary if falase\n",
    "multiclass = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 2000\n",
      "Multi-Class Classification: Enabled\n",
      "Grid Search: Disabled\n",
      "Feature Selection by RandomForest: Enabled\n",
      "All Features: Disabled\n",
      "K-means: Enabled\n",
      "Logistic Regression: Enabled\n",
      "Decision Tree: Enabled\n",
      "Support Vector Machines: Enabled\n",
      "KNN: Enabled\n",
      "MLP: Enabled\n",
      "Random Forest: Enabeld\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample size: {}\".format(sampleN))\n",
    "\n",
    "if multiclass:\n",
    "    print(\"Multi-Class Classification: Enabled\")\n",
    "else:\n",
    "    print(\"Multi-Class Classification: Disabled\")\n",
    "\n",
    "if enable_grid_search:\n",
    "    print(\"Grid Search: Enabled\")\n",
    "else:\n",
    "    print(\"Grid Search: Disabled\")\n",
    "\n",
    "if enable_rf_features:\n",
    "    print(\"Feature Selection by RandomForest: Enabled\")\n",
    "else:\n",
    "    print(\"Feature Selection by RandomForest: Disabled\")\n",
    "    print(\"Default Feature: {}\".format(defaultFeatures))\n",
    "\n",
    "if feature_all:\n",
    "    print(\"All Features: Enabled\")\n",
    "else:\n",
    "    print(\"All Features: Disabled\")\n",
    "    \n",
    "if enable_kmeans:\n",
    "    print(\"K-means: Enabled\")\n",
    "else:\n",
    "    print(\"K-means: Disabled\")\n",
    "\n",
    "if enable_logistic_regression:\n",
    "    print(\"Logistic Regression: Enabled\")\n",
    "else:\n",
    "    print(\"Logistic Regression: Disabled\")\n",
    "    \n",
    "if enable_decision_tree:\n",
    "    print(\"Decision Tree: Enabled\")\n",
    "else:\n",
    "    print(\"Decision Tree: Disabled\")\n",
    "    \n",
    "if enable_svm:\n",
    "    print(\"Support Vector Machines: Enabled\")\n",
    "else:\n",
    "    print(\"Support Vector Machines: Disabled\")\n",
    "\n",
    "if  enable_knn:\n",
    "    print(\"KNN: Enabled\")\n",
    "else:\n",
    "    print(\"KNN: Disabled\")\n",
    "    \n",
    "if enable_mlp:\n",
    "    print(\"MLP: Enabled\")\n",
    "else:\n",
    "    print(\"MLP: Disabled\")\n",
    "    \n",
    "if enable_rf:\n",
    "    print(\"Random Forest: Enabeld\")\n",
    "else:\n",
    "    print(\"Random Forest: Disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.stdout=open(\"Initial_Binary_Model2.out\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 11 14:45:29 2018\n"
     ]
    }
   ],
   "source": [
    "t_start =  time.time()\n",
    "print(time.asctime( time.localtime(t_start) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C_YEAR  C_MNTH  C_WDAY  C_HOUR  C_VEHS  C_CONF  C_RCFG  C_WTHR  C_RSUR  \\\n",
      "0    1999       1       1      20       2      34       8       1       5   \n",
      "1    1999       1       1      20       2      34       2       1       5   \n",
      "\n",
      "   C_RALN   ...    V_ID  V_TYPE  V_YEAR  P_ID  P_SEX  P_AGE  P_PSN  P_SAFE  \\\n",
      "0       3   ...       1       6    1990     1      1     41     11       2   \n",
      "1       3   ...       2       1    1987     1      1     19     11       2   \n",
      "\n",
      "   P_USER  P_ISEV  \n",
      "0       1       1  \n",
      "1       1       1  \n",
      "\n",
      "[2 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv('data01_simple.csv', engine = 'python')\n",
    "df = pd.read_csv('data01_clean.csv', engine = 'python')\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df[df.columns].apply(lambda x: x.astype(str).str.contains('[^0-9]')).sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = df.astype('category').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_int = df.astype('int').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['C_YEAR', 'C_MNTH', 'C_WDAY', 'C_HOUR', 'C_VEHS', 'C_CONF', 'C_RCFG',\n",
      "       'C_WTHR', 'C_RSUR', 'C_RALN', 'C_TRAF', 'V_ID', 'V_TYPE', 'V_YEAR',\n",
      "       'P_ID', 'P_SEX', 'P_AGE', 'P_PSN', 'P_SAFE', 'P_USER', 'P_ISEV'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Class Variable to Binary if multi class disabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Fatal: 43559\n",
      "    C_YEAR C_MNTH C_WDAY C_HOUR C_VEHS C_CONF C_RCFG C_WTHR C_RSUR C_RALN  \\\n",
      "47    1999      1      1     23      1      4      2      1      1      4   \n",
      "151   1999      1      1     12      1      1      2      1      1      1   \n",
      "\n",
      "     ...   V_ID V_TYPE V_YEAR P_ID P_SEX P_AGE P_PSN P_SAFE P_USER P_ISEV  \n",
      "47   ...      1      6   1997    1     1    44    11      2      1      3  \n",
      "151  ...     99      1   2017    1     1    15    99      2      3      3  \n",
      "\n",
      "[2 rows x 21 columns]\n",
      "Number of Injury: 3351616\n",
      "  C_YEAR C_MNTH C_WDAY C_HOUR C_VEHS C_CONF C_RCFG C_WTHR C_RSUR C_RALN  \\\n",
      "2   1999      1      1     20      2     34      2      1      5      3   \n",
      "4   1999      1      1      8      1      1      2      5      3      6   \n",
      "\n",
      "   ...   V_ID V_TYPE V_YEAR P_ID P_SEX P_AGE P_PSN P_SAFE P_USER P_ISEV  \n",
      "2  ...      2      1   1987    2     0    20    13      2      2      2  \n",
      "4  ...     99      1   2017    1     1     5    99      2      3      2  \n",
      "\n",
      "[2 rows x 21 columns]\n",
      "Number of Non-Injury: 2568097\n",
      "  C_YEAR C_MNTH C_WDAY C_HOUR C_VEHS C_CONF C_RCFG C_WTHR C_RSUR C_RALN  \\\n",
      "0   1999      1      1     20      2     34      8      1      5      3   \n",
      "1   1999      1      1     20      2     34      2      1      5      3   \n",
      "\n",
      "   ...   V_ID V_TYPE V_YEAR P_ID P_SEX P_AGE P_PSN P_SAFE P_USER P_ISEV  \n",
      "0  ...      1      6   1990    1     1    41    11      2      1      1  \n",
      "1  ...      2      1   1987    1     1    19    11      2      1      1  \n",
      "\n",
      "[2 rows x 21 columns]\n",
      "Size of Fatal Subset: 43559\n",
      "Size of injury Subset: 3351616\n",
      "Size of non-fatal Subset: 2568097\n",
      "Shape of injury sampled dataframe: (43559, 21)\n",
      "Shape of nom-injury sampled dataframe: (43559, 21)\n",
      "(130677, 21)\n",
      "658\n",
      "674\n",
      "668\n",
      "['1' '2' '0']\n",
      "Size of dataframe for modeling: 2000\n"
     ]
    }
   ],
   "source": [
    "## Convert Class Variable to Binary\n",
    "### Merge Injury and Fatality as a single class\n",
    "### we will compare the results.\n",
    "if multiclass:\n",
    "    #Undersample the majority for the 3 class evaluation\n",
    "    \n",
    "    df_class = df_cat.copy()\n",
    "    \n",
    "    # subset fatal class\n",
    "    is_fatal =  df_class['P_ISEV']==3\n",
    "    is_fatal_count = is_fatal.sum()\n",
    "    print(\"Number of Fatal: {}\".format(is_fatal_count))\n",
    "    df_class_fatal = df_class[is_fatal]\n",
    "    print(df_class_fatal.head(2))\n",
    "    \n",
    "    # subset injury class\n",
    "    is_injury =  df_class['P_ISEV']==2\n",
    "    is_injury_count = is_injury.sum()\n",
    "    print(\"Number of Injury: {}\".format(is_injury_count))\n",
    "    df_class_injury = df_class[is_injury]\n",
    "    print(df_class_injury.head(2))\n",
    "    \n",
    "    # subset non_injury class\n",
    "    is_safe =  df_class['P_ISEV']==1\n",
    "    is_safe_count = is_safe.sum()\n",
    "    print(\"Number of Non-Injury: {}\".format(is_safe_count))\n",
    "    df_class_safe = df_class[is_safe]\n",
    "    print(df_class_safe.head(2))\n",
    "    \n",
    "    # get the size of fatal datafram\n",
    "    min_size = df_class_fatal.index.size\n",
    "    print(\"Size of Fatal Subset: {}\".format(min_size))\n",
    "    \n",
    "    # get size of injury\n",
    "    print(\"Size of injury Subset: {}\".format(df_class_injury.index.size))\n",
    "    \n",
    "    # size of non-fatal\n",
    "    print(\"Size of non-fatal Subset: {}\".format(df_class_safe.index.size))\n",
    "    \n",
    "    # randomly sample n number of injury and no injury and append to fatal\n",
    "    df_class_injury_select = df_class_injury.sample(n=min_size)\n",
    "    print(\"Shape of injury sampled dataframe: {}\".format(df_class_injury_select.shape))\n",
    "    df_class_safe_select = df_class_safe.sample(n=min_size)\n",
    "    print(\"Shape of nom-injury sampled dataframe: {}\".format(df_class_safe_select.shape))\n",
    "    \n",
    "    #concat the three dataframes\n",
    "    df_underSample = pd.concat([df_class_fatal, df_class_injury_select, df_class_safe_select])\n",
    "    print(df_underSample.shape)\n",
    "    \n",
    "    #TBD\n",
    "    if sampleN < df_underSample.index.size:\n",
    "        df_sample = df_underSample.sample(n=sampleN)\n",
    "    else:\n",
    "        df_sample = df_underSample.sample(n=df_underSample.index.size)\n",
    "    \n",
    "    #perform the conversion in two steps to avoid any unwanted side effects\n",
    "    df_sample['P_ISEV'] = df_sample['P_ISEV'].map({1: 'safe', 2: 'injury', 3:'fatal'})\n",
    "    df_sample['P_ISEV'] = df_sample['P_ISEV'].map({'safe': '0', 'injury': '1', 'fatal':'2'})\n",
    "    print((df_sample['P_ISEV']=='0').sum())\n",
    "    print((df_sample['P_ISEV']=='1').sum())\n",
    "    print((df_sample['P_ISEV']=='2').sum())\n",
    "    print(df_sample['P_ISEV'].unique())\n",
    "else:\n",
    "    df_class = df_cat.copy()\n",
    "\n",
    "    #perform the conversion in two steps to avoid any unwanted side effects\n",
    "    df_class['P_ISEV'] = df_class['P_ISEV'].map({1: 'safe', 2: 'injury', 3:'fatal'})\n",
    "    df_class['P_ISEV'] = df_class['P_ISEV'].map({'safe': '0', 'injury': '1', 'fatal':'1'})\n",
    "    print((df_class['P_ISEV']=='0').sum())\n",
    "    print((df_class['P_ISEV']=='1').sum())\n",
    "    print(df_class['P_ISEV'].unique())\n",
    "    \n",
    "    df_sample = df_class.sample(n=sampleN)\n",
    "\n",
    "print(\"Size of dataframe for modeling: {}\".format(df_sample.index.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df_sample[df_sample.columns].apply(lambda x: x.astype(str).str.contains('[^0-9]')).sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training and Testing for Binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split between data and class\n",
    "Y = df_sample[df_sample.columns[-1]]\n",
    "X = df_sample[df_sample.columns[0:df_sample.columns.size -1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Test(70%) and Train (30%) for Bianry class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sprint into train and test 70/30\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Xbinary_train, Xbinary_test, Ybinary_train, Ybinary_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write cleaned data to file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets write the datafile for future use\n",
    "df_sample.to_csv('cleansimple_binary.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering based on K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 11 14:49:09 2018\n",
      "K-Means Clustering: Start\n",
      "K-Means Clustering: Build\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 3557244.3270334112\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 1438155.1824569283\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 1255652.1626794364\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 1236503.6056553617\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 1236189.9994617817\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 1236049.4758006847\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 1235973.482263704\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 1235962.4750990884\n",
      "center shift 8.675758e-02 within tolerance 1.059320e-02\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 3596982.8179497942\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 3320032.231936822\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 2775275.212842328\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 1288545.885125532\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 1238730.1237540985\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 1236078.883762957\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 1235982.6824329433\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 1235962.4750990884\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 1235959.4079794646\n",
      "center shift 4.354451e-02 within tolerance 1.059320e-02\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 3470307.3364968006\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 1387534.6722032519\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 1250480.4176142733\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 1236171.336186077\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 1236021.4558620856\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 1235973.482263704\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 1235962.4750990884\n",
      "center shift 8.675758e-02 within tolerance 1.059320e-02\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 3833362.0138693443\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 3324444.296386553\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 2750550.3204713166\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 1352603.4132584007\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 1256313.5289769366\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 1239165.3925086958\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 1237117.7592637376\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 1236436.2463670408\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 1236161.4565929465\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 1236021.4558620856\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 1235973.482263704\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 1235962.4750990884\n",
      "center shift 8.675758e-02 within tolerance 1.059320e-02\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 3389970.1754115806\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 1300876.2455246963\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 1238938.3676354352\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 1236031.05674562\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 1235963.273552806\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 1235956.1204097501\n",
      "center shift 8.906050e-02 within tolerance 1.059320e-02\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 3497228.527611383\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 3205807.2978634816\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 1932362.7039018678\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 1309059.151780267\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 1250234.603423215\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 1240137.344548505\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 1237211.5756493506\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 1236259.4121611624\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 1235997.130243721\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 1235957.331295818\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 1235957.331295818\n",
      "center shift 0.000000e+00 within tolerance 1.059320e-02\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 3697991.4198142453\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 2881701.1257132096\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 1290387.333379337\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 1238373.1901490064\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 1236061.5073132908\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 1235969.3849482099\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 1235957.331295818\n",
      "center shift 6.149437e-02 within tolerance 1.059320e-02\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 1551343.3941060335\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 1506704.4845535788\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 1449314.147301906\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 1321500.9804807566\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 1249720.1937579948\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 1238466.5172994817\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 1236839.0289157266\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 1236355.189054884\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 1236161.4565929465\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 1236021.4558620856\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 1235973.482263704\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 1235962.4750990884\n",
      "center shift 8.675758e-02 within tolerance 1.059320e-02\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 3616828.969834613\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 3231075.690630296\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 1314591.0719939626\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 1246124.1662485315\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 1236084.4820920317\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 1235982.6824329433\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 1235962.4750990884\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 1235959.4079794646\n",
      "center shift 4.354451e-02 within tolerance 1.059320e-02\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 3267283.697330082\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 1295626.6318624662\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 1239911.580902143\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 1236544.3607988057\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 1236085.6413576226\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 1235983.8223384244\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 1235957.331295818\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 1235957.331295818\n",
      "center shift 0.000000e+00 within tolerance 1.059320e-02\n",
      "[[2.00722463e+03 6.86738836e+00 3.98376184e+00 1.40947226e+01\n",
      "  2.02435724e+00 2.41894452e+01 1.65223275e+00 1.65899865e+00\n",
      "  1.54262517e+00 1.52503383e+00 1.20771313e+01 1.47361299e+00\n",
      "  2.76589986e+00 2.00081597e+03 1.34370771e+00 5.80514208e-01\n",
      "  5.77036536e+01 1.30040595e+01 2.44113667e+00 1.49255751e+00]\n",
      " [2.00661810e+03 6.68778281e+00 4.13122172e+00 1.33855204e+01\n",
      "  2.11855204e+00 2.19330317e+01 1.63981900e+00 1.67782805e+00\n",
      "  1.61900452e+00 1.56380090e+00 1.19384615e+01 1.55113122e+00\n",
      "  2.63438914e+00 1.99992760e+03 1.62714932e+00 6.02714932e-01\n",
      "  2.42144796e+01 1.42099548e+01 2.43348416e+00 1.61357466e+00]\n",
      " [2.00764103e+03 7.02564103e+00 3.92307692e+00 1.40320513e+01\n",
      "  1.10256410e+00 8.86538462e+00 1.70512821e+00 1.59615385e+00\n",
      "  1.44230769e+00 1.39102564e+00 1.16025641e+01 9.90000000e+01\n",
      "  2.76923077e+00 2.01700000e+03 1.02564103e+00 5.83333333e-01\n",
      "  4.90192308e+01 9.90000000e+01 4.78846154e+00 3.00000000e+00]]\n",
      "[0 0 0 ... 0 1 1]\n",
      "K-Means Clustering: End\n",
      "Sun Nov 11 14:49:09 2018\n"
     ]
    }
   ],
   "source": [
    "if enable_kmeans:\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print(\"K-Means Clustering: Start\")\n",
    "    kmeans = KMeans(n_clusters=3, init='random', n_init=10, max_iter=100, tol=1e-04, verbose= verbose_level)\n",
    "    print(\"K-Means Clustering: Build\")\n",
    "    ykm = kmeans.fit(X)\n",
    "    \n",
    "    if pyscript:\n",
    "        print(ykm.cluster_centers_)\n",
    "        print(ykm.labels_)\n",
    "    else:\n",
    "        display(ykm.cluster_centers_)\n",
    "        display(ykm.labels_)\n",
    "    \n",
    "    print(\"K-Means Clustering: End\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection using Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the inportant features from random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Selection: Start\n",
      "Sun Nov 11 14:49:09 2018\n",
      "Random Forest Feature Selection: Fit Start\n",
      "building tree 1 of 250building tree 2 of 250\n",
      "\n",
      "building tree 3 of 250\n",
      "building tree 4 of 250\n",
      "building tree 5 of 250\n",
      "building tree 6 of 250\n",
      "building tree 7 of 250building tree 8 of 250\n",
      "\n",
      "building tree 9 of 250\n",
      "building tree 10 of 250\n",
      "building tree 11 of 250\n",
      "building tree 12 of 250\n",
      "building tree 13 of 250building tree 14 of 250\n",
      "building tree 15 of 250\n",
      "\n",
      "building tree 16 of 250\n",
      "building tree 17 of 250\n",
      "building tree 18 of 250\n",
      "building tree 19 of 250\n",
      "building tree 20 of 250\n",
      "building tree 21 of 250\n",
      "building tree 22 of 250\n",
      "building tree 23 of 250\n",
      "building tree 24 of 250\n",
      "building tree 25 of 250building tree 26 of 250building tree 27 of 250\n",
      "\n",
      "\n",
      "building tree 28 of 250\n",
      "building tree 29 of 250\n",
      "building tree 30 of 250building tree 31 of 250\n",
      "\n",
      "building tree 32 of 250\n",
      "building tree 33 of 250\n",
      "building tree 34 of 250building tree 35 of 250\n",
      "building tree 36 of 250\n",
      "building tree 37 of 250\n",
      "\n",
      "building tree 38 of 250\n",
      "building tree 39 of 250\n",
      "building tree 40 of 250\n",
      "building tree 41 of 250building tree 42 of 250\n",
      "\n",
      "building tree 43 of 250\n",
      "building tree 44 of 250\n",
      "building tree 45 of 250building tree 46 of 250\n",
      "\n",
      "building tree 47 of 250\n",
      "building tree 48 of 250\n",
      "building tree 49 of 250\n",
      "building tree 50 of 250\n",
      "building tree 51 of 250building tree 52 of 250\n",
      "building tree 53 of 250\n",
      "building tree 54 of 250\n",
      "\n",
      "building tree 55 of 250\n",
      "building tree 56 of 250\n",
      "building tree 57 of 250\n",
      "building tree 58 of 250\n",
      "building tree 59 of 250building tree 60 of 250building tree 61 of 250building tree 62 of 250\n",
      "building tree 63 of 250\n",
      "\n",
      "\n",
      "building tree 64 of 250\n",
      "\n",
      "building tree 65 of 250building tree 66 of 250\n",
      "\n",
      "building tree 67 of 250building tree 68 of 250\n",
      "building tree 69 of 250\n",
      "\n",
      "building tree 70 of 250\n",
      "building tree 71 of 250\n",
      "building tree 72 of 250\n",
      "building tree 73 of 250building tree 74 of 250\n",
      "\n",
      "building tree 75 of 250building tree 76 of 250building tree 77 of 250\n",
      "\n",
      "\n",
      "building tree 78 of 250\n",
      "building tree 79 of 250\n",
      "building tree 80 of 250\n",
      "building tree 81 of 250\n",
      "building tree 82 of 250building tree 83 of 250\n",
      "building tree 84 of 250\n",
      "building tree 85 of 250\n",
      "\n",
      "building tree 86 of 250building tree 87 of 250\n",
      "\n",
      "building tree 88 of 250\n",
      "building tree 89 of 250building tree 90 of 250building tree 91 of 250\n",
      "\n",
      "\n",
      "building tree 92 of 250building tree 93 of 250building tree 94 of 250\n",
      "\n",
      "\n",
      "building tree 95 of 250\n",
      "building tree 96 of 250\n",
      "building tree 97 of 250\n",
      "building tree 98 of 250\n",
      "building tree 99 of 250\n",
      "building tree 100 of 250\n",
      "building tree 101 of 250\n",
      "building tree 102 of 250\n",
      "building tree 103 of 250\n",
      "building tree 104 of 250\n",
      "building tree 105 of 250\n",
      "building tree 106 of 250\n",
      "building tree 107 of 250\n",
      "building tree 108 of 250building tree 109 of 250\n",
      "building tree 110 of 250\n",
      "\n",
      "building tree 111 of 250building tree 112 of 250\n",
      "\n",
      "building tree 113 of 250\n",
      "building tree 114 of 250building tree 115 of 250\n",
      "building tree 116 of 250\n",
      "building tree 117 of 250building tree 118 of 250\n",
      "building tree 119 of 250\n",
      "\n",
      "\n",
      "building tree 120 of 250\n",
      "building tree 121 of 250building tree 122 of 250\n",
      "\n",
      "building tree 123 of 250\n",
      "building tree 124 of 250building tree 125 of 250building tree 126 of 250\n",
      "\n",
      "\n",
      "building tree 127 of 250building tree 128 of 250\n",
      "\n",
      "building tree 129 of 250\n",
      "building tree 130 of 250building tree 131 of 250\n",
      "building tree 132 of 250\n",
      "building tree 133 of 250\n",
      "building tree 134 of 250\n",
      "\n",
      "building tree 135 of 250\n",
      "building tree 136 of 250\n",
      "building tree 137 of 250\n",
      "building tree 138 of 250\n",
      "building tree 139 of 250\n",
      "building tree 140 of 250\n",
      "building tree 141 of 250building tree 142 of 250\n",
      "building tree 143 of 250\n",
      "building tree 144 of 250\n",
      "\n",
      "building tree 145 of 250\n",
      "building tree 146 of 250\n",
      "building tree 147 of 250\n",
      "building tree 148 of 250building tree 149 of 250\n",
      "building tree 150 of 250\n",
      "building tree 151 of 250\n",
      "\n",
      "building tree 152 of 250\n",
      "building tree 153 of 250building tree 154 of 250\n",
      "\n",
      "building tree 155 of 250\n",
      "building tree 156 of 250building tree 157 of 250\n",
      "building tree 158 of 250\n",
      "building tree 159 of 250\n",
      "\n",
      "building tree 160 of 250\n",
      "building tree 161 of 250\n",
      "building tree 162 of 250building tree 163 of 250\n",
      "building tree 164 of 250building tree 165 of 250\n",
      "building tree 166 of 250\n",
      "\n",
      "\n",
      "building tree 167 of 250\n",
      "building tree 168 of 250\n",
      "building tree 169 of 250building tree 170 of 250\n",
      "\n",
      "building tree 171 of 250\n",
      "building tree 172 of 250building tree 173 of 250\n",
      "building tree 174 of 250\n",
      "\n",
      "building tree 175 of 250\n",
      "building tree 176 of 250\n",
      "building tree 177 of 250\n",
      "building tree 178 of 250\n",
      "building tree 179 of 250building tree 180 of 250\n",
      "building tree 181 of 250\n",
      "\n",
      "building tree 182 of 250building tree 183 of 250\n",
      "\n",
      "building tree 184 of 250\n",
      "building tree 185 of 250\n",
      "building tree 186 of 250\n",
      "building tree 187 of 250building tree 188 of 250building tree 189 of 250\n",
      "\n",
      "\n",
      "building tree 190 of 250\n",
      "building tree 191 of 250\n",
      "building tree 192 of 250\n",
      "building tree 193 of 250\n",
      "building tree 194 of 250building tree 195 of 250\n",
      "building tree 196 of 250\n",
      "building tree 197 of 250building tree 198 of 250\n",
      "\n",
      "\n",
      "building tree 199 of 250building tree 200 of 250\n",
      "\n",
      "building tree 201 of 250building tree 202 of 250\n",
      "\n",
      "building tree 203 of 250building tree 204 of 250\n",
      "building tree 205 of 250building tree 206 of 250\n",
      "\n",
      "\n",
      "building tree 207 of 250\n",
      "building tree 208 of 250\n",
      "building tree 209 of 250building tree 210 of 250\n",
      "\n",
      "building tree 211 of 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 212 of 250building tree 213 of 250building tree 214 of 250building tree 215 of 250\n",
      "\n",
      "building tree 216 of 250\n",
      "\n",
      "\n",
      "building tree 217 of 250\n",
      "building tree 218 of 250building tree 219 of 250\n",
      "\n",
      "building tree 220 of 250building tree 221 of 250building tree 222 of 250\n",
      "\n",
      "building tree 223 of 250\n",
      "\n",
      "building tree 224 of 250\n",
      "building tree 225 of 250\n",
      "building tree 226 of 250building tree 227 of 250\n",
      "building tree 228 of 250\n",
      "\n",
      "building tree 229 of 250\n",
      "building tree 230 of 250\n",
      "building tree 231 of 250\n",
      "building tree 232 of 250\n",
      "building tree 233 of 250\n",
      "building tree 234 of 250building tree 235 of 250\n",
      "\n",
      "building tree 236 of 250\n",
      "building tree 237 of 250\n",
      "building tree 238 of 250building tree 239 of 250\n",
      "\n",
      "building tree 240 of 250\n",
      "building tree 241 of 250\n",
      "building tree 242 of 250\n",
      "building tree 243 of 250\n",
      "building tree 244 of 250\n",
      "building tree 245 of 250\n",
      "building tree 246 of 250\n",
      "building tree 247 of 250\n",
      "building tree 248 of 250\n",
      "building tree 249 of 250\n",
      "building tree 250 of 250\n",
      "Random Forest Feature Selection: Fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Selection: Feature Importance\n",
      "[0.07843242 0.06826468 0.05651582 0.08325091 0.03499562 0.0899008\n",
      " 0.03378724 0.02975744 0.02865096 0.03811772 0.03672251 0.03533453\n",
      " 0.02663645 0.0851479  0.02266789 0.02548397 0.10898781 0.03370827\n",
      " 0.04883201 0.03480504]\n",
      "[16  5 13  3  0  1  2 18  9 10 11  4 19  6 17  7  8 12 15 14]\n",
      "Index(['C_YEAR', 'C_MNTH', 'C_WDAY', 'C_HOUR', 'C_VEHS', 'C_CONF', 'C_RCFG',\n",
      "       'C_WTHR', 'C_RSUR', 'C_RALN', 'C_TRAF', 'V_ID', 'V_TYPE', 'V_YEAR',\n",
      "       'P_ID', 'P_SEX', 'P_AGE', 'P_PSN', 'P_SAFE', 'P_USER'],\n",
      "      dtype='object')\n",
      " 1) P_AGE                          0.108988\n",
      " 2) C_CONF                         0.089901\n",
      " 3) V_YEAR                         0.085148\n",
      " 4) C_HOUR                         0.083251\n",
      " 5) C_YEAR                         0.078432\n",
      " 6) C_MNTH                         0.068265\n",
      " 7) C_WDAY                         0.056516\n",
      " 8) P_SAFE                         0.048832\n",
      " 9) C_RALN                         0.038118\n",
      "10) C_TRAF                         0.036723\n",
      "11) V_ID                           0.035335\n",
      "12) C_VEHS                         0.034996\n",
      "13) P_USER                         0.034805\n",
      "14) C_RCFG                         0.033787\n",
      "15) P_PSN                          0.033708\n",
      "16) C_WTHR                         0.029757\n",
      "17) C_RSUR                         0.028651\n",
      "18) V_TYPE                         0.026636\n",
      "19) P_SEX                          0.025484\n",
      "20) P_ID                           0.022668\n",
      "['P_AGE', 'C_CONF', 'V_YEAR', 'C_HOUR', 'C_YEAR', 'C_MNTH', 'C_WDAY', 'P_SAFE', 'C_RALN', 'C_TRAF', 'V_ID', 'C_VEHS', 'P_USER', 'C_RCFG', 'P_PSN', 'C_WTHR', 'C_RSUR', 'V_TYPE', 'P_SEX', 'P_ID']\n"
     ]
    }
   ],
   "source": [
    "if enable_rf_features:\n",
    "    print(\"Random Forest Feature Selection: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    forest = RandomForestClassifier(n_estimators=250, random_state=0, n_jobs=-1, verbose=verbose_level)\n",
    "    print(\"Random Forest Feature Selection: Fit Start\")\n",
    "    forest.fit(X, Y)\n",
    "    print(\"Random Forest Feature Selection: Fit\")\n",
    "\n",
    "    importFeatures = forest.feature_importances_\n",
    "    print(\"Random Forest Feature Selection: Feature Importance\")\n",
    "    print(importFeatures)\n",
    "    \n",
    "    indices = np.argsort(importFeatures)[::-1]\n",
    "    print(indices)\n",
    "    featureLabel = X.columns[0:]\n",
    "    print(featureLabel)\n",
    "    rankedFeature = []\n",
    "    for f in range(X.shape[1]):\n",
    "        rankedFeature.append(featureLabel[indices[f]])\n",
    "        print(\"%2d) %-*s %f\" % (f+1, 30,  featureLabel[indices[f]], importFeatures[indices[f]]))\n",
    "    print(rankedFeature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce the number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        P_AGE C_CONF V_YEAR C_HOUR C_YEAR C_MNTH C_WDAY P_SAFE C_RALN C_TRAF\n",
      "2026199    57     21   1998     20   2004      4      7      2      1     18\n",
      "4747143    54      4   2010     19   2012      9      7      2      2     18\n",
      "2224428    70     35   1998      8   2004     11      2      1      1      4\n",
      "4184139    38     21   2004     16   2010     11      2      2      1      1\n",
      "1228333    87     35   2001      9   2002      3      4      2      1     18\n",
      "3993623    29      2   2002      9   2010      4      2      2      3     18\n",
      "853769     19      6   2001      0   2001      3      5      2      1     18\n",
      "381698     54     23   1994     14   1999     12      6      2      1     18\n",
      "3519943    22      6   2007      2   2008      9      1      2      2     18\n",
      "2185994    20      6   1992      2   2004     10      1      1      1     18\n",
      "4078120    49      3   2005     15   2010      7      4      1      1     18\n",
      "...       ...    ...    ...    ...    ...    ...    ...    ...    ...    ...\n",
      "5763631    35     21   2014      8   2016      5      1      2      1     18\n",
      "5094325    59     21   2008      9   2013     12      1      2      1      1\n",
      "5950       47      1   1995     16   1999      1      2      2      1     18\n",
      "893831     35     21   1998     10   2001      5      2      2      1      1\n",
      "63955      38     21   1986      8   1999      3      2      2      1      4\n",
      "2727752     8     31   2000     18   2006      4      6      2      3     18\n",
      "4584127    43     31   2018      6   2012      3      4      2      4     18\n",
      "3432745    24     35   2000      3   2008      5      6      1      1      1\n",
      "4494046    53     21   1997     19   2011     11      5      2      1     18\n",
      "2469267    30      6   2003     21   2005      7      6      2      2     18\n",
      "1219686     5     31   1992     15   2002      3      2     13      4     18\n",
      "\n",
      "[2000 rows x 10 columns]\n",
      "Sun Nov 11 14:49:09 2018\n",
      "Random Forest Feature Selection: End\n"
     ]
    }
   ],
   "source": [
    "#select features that contribute more than 0.05\n",
    "if enable_rf_features:\n",
    "    X_Selected = X[rankedFeature[0:10]]\n",
    "else:\n",
    "    if feature_all:\n",
    "        X_Selected = X\n",
    "    else:\n",
    "        X_Selected = X[defaultFeatures]\n",
    "\n",
    "if pyscript:\n",
    "    print(X_Selected)\n",
    "else:\n",
    "    display(X_Selected)\n",
    "\n",
    "t_end =  time.time()\n",
    "print(time.asctime( time.localtime(t_end) ))\n",
    "\n",
    "print(\"Random Forest Feature Selection: End\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Test and Train based on Selected Features\n"
     ]
    }
   ],
   "source": [
    "print(\"Split Test and Train based on Selected Features\")\n",
    "#sprint into train and test 70/30\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_Selected, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM GridSearch for Optimal Parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This operation is computationaly expensive.\n",
    "if enable_grid_search:\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    param_grid = {'C':[0.1, 1, 10, 100, 1000], 'gamma':[1, 0.1, 0.01, 0.001, 0.0001]}\n",
    "    grid = GridSearchCV(SVC(), param_grid, verbose=verbose_level)\n",
    "    grid.fit(X_train, Y_train)\n",
    "    print(grid.best_params_)\n",
    "    svm_c = grid.best_params_.get('C')\n",
    "    svm_gamma = grid.best_params_.get('gamma')\n",
    "    print(grid.best_estimator_)\n",
    "    grid_predictions = grid.predict(X_test)\n",
    "    cfn_matrix_grid = confusion_matrix(Y_test, grid_predictions)\n",
    "    print(cfn_matrix_grid)\n",
    "    print(classification_report(Y_test,grid_predictions))\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Start\n",
      "Sun Nov 11 14:49:09 2018\n",
      "Logistic Regression: Fit\n",
      "[LibLinear]Logistic Regression: Predict\n",
      "Accuracy of logistic regression classifier on train set: 0.48\n",
      "Accuracy of logistic regression classifier on test set: 0.42\n",
      "Logistic Regression: Intercept\n",
      "[ 0.00025833  0.00044898 -0.00062032]\n",
      "Logistic Regression: Coefficients\n",
      "[[-0.00755976  0.01528061 -0.01332646  0.01807329  0.01321654  0.03430159\n",
      "  -0.0081958  -0.09038045 -0.37187294 -0.02735422]\n",
      " [-0.00920475  0.00407754  0.01666505  0.00820617 -0.01659741 -0.01581872\n",
      "  -0.0115551   0.00808118 -0.15048614 -0.02005051]\n",
      " [ 0.01864343 -0.01963716 -0.0044911  -0.02945337  0.00339195 -0.01931243\n",
      "   0.01869046  0.07097681  0.43358791  0.05944838]]\n",
      "Logistic Regression: Confusion Matrix\n",
      "[[ 99  36  61]\n",
      " [ 84  31  88]\n",
      " [ 46  30 125]]\n",
      "Logistic Regression: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.51      0.47       196\n",
      "          1       0.32      0.15      0.21       203\n",
      "          2       0.46      0.62      0.53       201\n",
      "\n",
      "avg / total       0.40      0.42      0.40       600\n",
      "\n",
      "Sun Nov 11 14:49:09 2018\n",
      "Logistic Regression: End\n"
     ]
    }
   ],
   "source": [
    "if enable_logistic_regression:\n",
    "    print(\"Logistic Regression: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    lr = LogisticRegression(C=1, random_state=0, verbose=verbose_level)\n",
    "    print(\"Logistic Regression: Fit\")\n",
    "    lr.fit(X_train, Y_train)\n",
    "    print(\"Logistic Regression: Predict\")\n",
    "    y_pred = lr.predict(X_test)\n",
    "\n",
    "    print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(lr.score(X_train, Y_train)))\n",
    "    print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(lr.score(X_test, Y_test)))\n",
    "\n",
    "    # print the intercept (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "    print(\"Logistic Regression: Intercept\")\n",
    "    print(lr.intercept_)\n",
    "\n",
    "    # print the coeficients (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "    print(\"Logistic Regression: Coefficients\")\n",
    "    print(lr.coef_)\n",
    "\n",
    "    print(\"Logistic Regression: Confusion Matrix\")\n",
    "    cnf_matrix_lg = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_lg)\n",
    "    \n",
    "    print(\"Logistic Regression: Classification Report\")\n",
    "    print(classification_report(Y_test, y_pred))\n",
    "\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "    print(\"Logistic Regression: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with L1 Regularization: Start\n",
      "Sun Nov 11 14:49:09 2018\n",
      "Logistic Regression with L1 Regularization: Fit\n",
      "[LibLinear]Logistic Regression with L1 Regularization: Predict\n",
      "Accuracy of logistic regression classifier on train set: 0.47\n",
      "Accuracy of logistic regression classifier on test set: 0.42\n",
      "Logistic Regression with L1 Regularization: Confusion Matrix\n",
      "[[ 97  34  65]\n",
      " [ 84  30  89]\n",
      " [ 48  28 125]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.42      0.49      0.46       196\n",
      "          1       0.33      0.15      0.20       203\n",
      "          2       0.45      0.62      0.52       201\n",
      "\n",
      "avg / total       0.40      0.42      0.39       600\n",
      "\n",
      "Logistic Regression with L1 Regularization: Classification Report\n",
      "Sun Nov 11 14:49:13 2018\n",
      "Logistic Regression with L1 Regularization: End\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:898: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "if enable_logistic_regression_l1:\n",
    "    # with L1 regularization\n",
    "    print(\"Logistic Regression with L1 Regularization: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    lr = LogisticRegression(penalty='l1', C=1, random_state=0, verbose=verbose_level)\n",
    "    print(\"Logistic Regression with L1 Regularization: Fit\")\n",
    "    lr.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"Logistic Regression with L1 Regularization: Predict\")\n",
    "    y_pred = lr.predict(X_test)\n",
    "    \n",
    "    print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(lr.score(X_train, Y_train)))\n",
    "    print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(lr.score(X_test, Y_test)))\n",
    "\n",
    "    print(\"Logistic Regression with L1 Regularization: Confusion Matrix\")\n",
    "    cnf_matrix_lg_l1 = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_lg_l1)\n",
    "    \n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    print(\"Logistic Regression with L1 Regularization: Classification Report\")\n",
    "\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "    print(\"Logistic Regression with L1 Regularization: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: Start\n",
      "Sun Nov 11 14:49:13 2018\n",
      "Decision Tree: Fit\n",
      "Decision Tree: Predict\n",
      "Accuracy of Decision Tree classifier on train set: 1.00\n",
      "Accuracy of Decision Tree classifier on test set: 0.42\n",
      "Decision Tree: Confusion Matrix\n",
      "[[ 71  95  30]\n",
      " [ 77  68  58]\n",
      " [ 35  51 115]]\n",
      "Decision Tree: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.39      0.36      0.37       196\n",
      "          1       0.32      0.33      0.33       203\n",
      "          2       0.57      0.57      0.57       201\n",
      "\n",
      "avg / total       0.42      0.42      0.42       600\n",
      "\n",
      "Sun Nov 11 14:49:13 2018\n",
      "Decision Tree: End\n"
     ]
    }
   ],
   "source": [
    "if enable_decision_tree:\n",
    "    print(\"Decision Tree: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    tree = DecisionTreeClassifier(criterion='entropy',max_depth=50, random_state=0)\n",
    "    print(\"Decision Tree: Fit\")\n",
    "    tree.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"Decision Tree: Predict\")\n",
    "    y_pred = tree.predict(X_test)\n",
    "    print('Accuracy of Decision Tree classifier on train set: {:.2f}'.format(tree.score(X_train, Y_train)))\n",
    "    print('Accuracy of Decision Tree classifier on test set: {:.2f}'.format(tree.score(X_test, Y_test)))\n",
    "    \n",
    "    cnf_matrix_dt = confusion_matrix(Y_test, y_pred)\n",
    "    print(\"Decision Tree: Confusion Matrix\")\n",
    "    print(cnf_matrix_dt)\n",
    "    print(\"Decision Tree: Classification Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    print(\"Decision Tree: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-N-N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: Start\n",
      "Sun Nov 11 14:49:13 2018\n",
      "KNN: Fit\n",
      "KNN: Predict\n",
      "Accuracy of KNN classifier on train set: 0.64\n",
      "Accuracy of KNN classifier on test set: 0.43\n",
      "KNN: Confusion Matrix\n",
      "[[103  72  21]\n",
      " [ 87  68  48]\n",
      " [ 61  52  88]]\n",
      "KNN: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.41      0.53      0.46       196\n",
      "          1       0.35      0.33      0.34       203\n",
      "          2       0.56      0.44      0.49       201\n",
      "\n",
      "avg / total       0.44      0.43      0.43       600\n",
      "\n",
      "Sun Nov 11 14:49:13 2018\n",
      "KNN: End\n"
     ]
    }
   ],
   "source": [
    "if enable_knn:\n",
    "    print(\"KNN: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    knn = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "    print(\"KNN: Fit\")\n",
    "    knn.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"KNN: Predict\")\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print('Accuracy of KNN classifier on train set: {:.2f}'.format(knn.score(X_train, Y_train)))\n",
    "    print('Accuracy of KNN classifier on test set: {:.2f}'.format(knn.score(X_test, Y_test)))\n",
    "    \n",
    "    print(\"KNN: Confusion Matrix\")\n",
    "    cnf_matrix_knn = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_knn)\n",
    "\n",
    "    print(\"KNN: Classification Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "\n",
    "    print(\"KNN: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: Start\n",
      "Sun Nov 11 14:49:13 2018\n",
      "SVM: Fit\n",
      "[LibSVM]SVM: Predict\n",
      "Accuracy of SVM classifier on train set: 1.00\n",
      "Accuracy of SVM classifier on test set: 0.36\n",
      "SVM: Confusion Matrix\n",
      "[[ 39 139  18]\n",
      " [ 32 149  22]\n",
      " [ 14 158  29]]\n",
      "SVM: Classfication Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.46      0.20      0.28       196\n",
      "          1       0.33      0.73      0.46       203\n",
      "          2       0.42      0.14      0.21       201\n",
      "\n",
      "avg / total       0.40      0.36      0.32       600\n",
      "\n",
      "Sun Nov 11 14:49:14 2018\n",
      "SVM: End\n"
     ]
    }
   ],
   "source": [
    "if enable_svm:\n",
    "    print(\"SVM: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    #svm = SVC(C=1, random_state=0, kernel='sigmoid', verbose=True)\n",
    "    #svm = SVC(C=1, random_state=0, kernel='linear', verbose=True, cache_size=200)\n",
    "    #svm = SVC(C=svm_c, gamma=svm_gamma, verbose = verbose_level)\n",
    "    svm = SVC(C=1, verbose = verbose_level)\n",
    "    print(\"SVM: Fit\")\n",
    "    svm.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"SVM: Predict\")\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    print('Accuracy of SVM classifier on train set: {:.2f}'.format(svm.score(X_train, Y_train)))\n",
    "    print('Accuracy of SVM classifier on test set: {:.2f}'.format(svm.score(X_test, Y_test)))\n",
    "    \n",
    "    print(\"SVM: Confusion Matrix\")\n",
    "    cnf_matrix_svm = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_svm)\n",
    "    \n",
    "    print(\"SVM: Classfication Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "    print(\"SVM: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN - Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Preceptron: Start\n",
      "Sun Nov 11 14:49:14 2018\n",
      "Multilayer Preceptron: fit\n",
      "Iteration 1, loss = 15.42553865\n",
      "Iteration 2, loss = 13.71725614\n",
      "Iteration 3, loss = 12.22575614\n",
      "Iteration 4, loss = 10.08290247\n",
      "Iteration 5, loss = 9.59670727\n",
      "Iteration 6, loss = 8.98710167\n",
      "Iteration 7, loss = 8.51382777\n",
      "Iteration 8, loss = 11.46911419\n",
      "Iteration 9, loss = 10.35655079\n",
      "Iteration 10, loss = 8.65055746\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Multilayer Preceptron: Predict\n",
      "Accuracy of Multilayer Perceptron classifier on train set: 0.33\n",
      "Accuracy of Multilayer Perceptron classifier on test set: 0.33\n",
      "Multilayer Preceptron: Confusion Matrix\n",
      "[[196   0   0]\n",
      " [203   0   0]\n",
      " [201   0   0]]\n",
      "Multilayer Preceptron: Classificiation Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      1.00      0.49       196\n",
      "          1       0.00      0.00      0.00       203\n",
      "          2       0.00      0.00      0.00       201\n",
      "\n",
      "avg / total       0.11      0.33      0.16       600\n",
      "\n",
      "Sun Nov 11 14:49:14 2018\n",
      "Multilayer Preceptron: End\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "if enable_mlp:\n",
    "    print(\"Multilayer Preceptron: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    \n",
    "    #mlpc = MLPClassifier(alpha=1)\n",
    "    mlpc = MLPClassifier(hidden_layer_sizes=(12, 12, 12), max_iter=100, verbose=verbose_level)\n",
    "    \n",
    "    #mlp = multilayer_perceptron(n_hidden =2, activation='logistic', algorithm='sgd', random_state=3)\n",
    "    print(\"Multilayer Preceptron: fit\")\n",
    "    mlpc.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"Multilayer Preceptron: Predict\")\n",
    "    y_pred = mlpc.predict(X_test)\n",
    "\n",
    "    print('Accuracy of Multilayer Perceptron classifier on train set: {:.2f}'.format(mlpc.score(X_train, Y_train)))\n",
    "    print('Accuracy of Multilayer Perceptron classifier on test set: {:.2f}'.format(mlpc.score(X_test, Y_test)))\n",
    "    \n",
    "    print(\"Multilayer Preceptron: Confusion Matrix\")\n",
    "    cnf_matrix_mlp = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_mlp)\n",
    "    \n",
    "    print(\"Multilayer Preceptron: Classificiation Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "    print(\"Multilayer Preceptron: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble (Bagging): Random Forest: Start\n",
      "Sun Nov 11 14:49:14 2018\n",
      "Ensemble (Bagging): Random Forest: Fit\n",
      "building tree 1 of 50building tree 2 of 50\n",
      "\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50building tree 8 of 50\n",
      "\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n",
      "Ensemble (Bagging): Random Forest: Predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForest classifier on train set: 1.00\n",
      "Accuracy of RandomForest classifier on test set: 0.49\n",
      "Ensemble (Bagging): Random Forest: Confusion Matrix\n",
      "[[107  66  23]\n",
      " [ 84  54  65]\n",
      " [ 33  35 133]]\n",
      "Ensemble (Bagging): Random Forest: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.55      0.51       196\n",
      "          1       0.35      0.27      0.30       203\n",
      "          2       0.60      0.66      0.63       201\n",
      "\n",
      "avg / total       0.48      0.49      0.48       600\n",
      "\n",
      "Sun Nov 11 14:49:14 2018\n",
      "Ensemble (Bagging): Random Forest: End\n"
     ]
    }
   ],
   "source": [
    "if enable_rf:\n",
    "    print(\"Ensemble (Bagging): Random Forest: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    forest = RandomForestClassifier(criterion='entropy', n_estimators=50, random_state=0, n_jobs=2, verbose=verbose_level)\n",
    "    print(\"Ensemble (Bagging): Random Forest: Fit\")\n",
    "    forest.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"Ensemble (Bagging): Random Forest: Predict\")\n",
    "    y_pred = forest.predict(X_test)\n",
    "    \n",
    "    print('Accuracy of RandomForest classifier on train set: {:.2f}'.format(forest.score(X_train, Y_train)))\n",
    "    print('Accuracy of RandomForest classifier on test set: {:.2f}'.format(forest.score(X_test, Y_test)))\n",
    "    \n",
    "    print(\"Ensemble (Bagging): Random Forest: Confusion Matrix\")\n",
    "    cnf_matrix_rf = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_rf)\n",
    "    \n",
    "    print(\"Ensemble (Bagging): Random Forest: Classification Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    \n",
    "    print(\"Ensemble (Bagging): Random Forest: End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#check sigmoid and rbf\n",
    "#from sklearn.ensemble import BaggingClassifier\n",
    "#from sklearn.svm import SVC\n",
    "#clf = BaggingClassifier(SVC(C=1.0,\n",
    "#        cache_size=200,\n",
    "#        class_weight=None,\n",
    "#        coef0=0.0,\n",
    "#        decision_function_shape=None,\n",
    "#        degree=3,\n",
    "#        gamma='auto',\n",
    "#        kernel='linear',\n",
    "#        max_iter=-1,\n",
    "#        probability=False,\n",
    "#        random_state=None,\n",
    "#        shrinking=True,\n",
    "#        tol=0.001,\n",
    "#        verbose=False,\n",
    "#        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 11 14:49:14 2018\n"
     ]
    }
   ],
   "source": [
    "t_end =  time.time()\n",
    "print(time.asctime( time.localtime(t_end) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.stdout.close()\n",
    "%logstop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
