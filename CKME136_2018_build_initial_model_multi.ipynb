{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activating auto-logging. Current session state plus future input saved.\n",
      "Filename       : ipython_log.py\n",
      "Mode           : rotate\n",
      "Output logging : True\n",
      "Raw input log  : False\n",
      "Timestamping   : True\n",
      "State          : active\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%logstart -o -t\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "#in case we need to repeat experiment\n",
    "np.random.seed(255)\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 22\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('classic')\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "#sklearn imports\n",
    "from sklearn.cluster import KMeans\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "#Use print instead of display when run as python script\n",
    "pyscript = True\n",
    "\n",
    "#Classifier verborsity where supported\n",
    "verbose_level=4\n",
    "\n",
    "#Sample Size\n",
    "sampleN = 2000\n",
    "\n",
    "import time\n",
    "\n",
    "#Enable Optimization Algorithms\n",
    "enable_grid_search = False\n",
    "svm_c = 1\n",
    "svm_gamma = 1\n",
    "enable_rf_features = True\n",
    "feature_all = False\n",
    "defaultFeatures = ['P_AGE', 'V_YEAR', 'C_HOUR', 'C_YEAR', 'C_MNTH', 'C_CONF', 'C_WDAY', 'C_VEHS', 'P_USER', 'P_SEX']\n",
    "enable_kmeans = True\n",
    "enable_logistic_regression_l1 = True\n",
    "\n",
    "# Enable Algorithms\n",
    "enable_logistic_regression = True\n",
    "enable_decision_tree = True\n",
    "enable_svm = True\n",
    "enable_knn = True\n",
    "enable_mlp = True\n",
    "enable_rf = True\n",
    "\n",
    "#Multiclass classification, binary if falase\n",
    "multiclass = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 2000\n",
      "Multi-Class Classification: Enabled\n",
      "Grid Search: Disabled\n",
      "Feature Selection by RandomForest: Enabled\n",
      "All Features: Disabled\n",
      "K-means: Enabled\n",
      "Logistic Regression: Enabled\n",
      "Decision Tree: Enabled\n",
      "Support Vector Machines: Enabled\n",
      "KNN: Enabled\n",
      "MLP: Enabled\n",
      "Random Forest: Enabeld\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample size: {}\".format(sampleN))\n",
    "\n",
    "if multiclass:\n",
    "    print(\"Multi-Class Classification: Enabled\")\n",
    "else:\n",
    "    print(\"Multi-Class Classification: Disabled\")\n",
    "\n",
    "if enable_grid_search:\n",
    "    print(\"Grid Search: Enabled\")\n",
    "else:\n",
    "    print(\"Grid Search: Disabled\")\n",
    "\n",
    "if enable_rf_features:\n",
    "    print(\"Feature Selection by RandomForest: Enabled\")\n",
    "else:\n",
    "    print(\"Feature Selection by RandomForest: Disabled\")\n",
    "    print(\"Default Feature: {}\".format(defaultFeatures))\n",
    "\n",
    "if feature_all:\n",
    "    print(\"All Features: Enabled\")\n",
    "else:\n",
    "    print(\"All Features: Disabled\")\n",
    "    \n",
    "if enable_kmeans:\n",
    "    print(\"K-means: Enabled\")\n",
    "else:\n",
    "    print(\"K-means: Disabled\")\n",
    "\n",
    "if enable_logistic_regression:\n",
    "    print(\"Logistic Regression: Enabled\")\n",
    "else:\n",
    "    print(\"Logistic Regression: Disabled\")\n",
    "    \n",
    "if enable_decision_tree:\n",
    "    print(\"Decision Tree: Enabled\")\n",
    "else:\n",
    "    print(\"Decision Tree: Disabled\")\n",
    "    \n",
    "if enable_svm:\n",
    "    print(\"Support Vector Machines: Enabled\")\n",
    "else:\n",
    "    print(\"Support Vector Machines: Disabled\")\n",
    "\n",
    "if  enable_knn:\n",
    "    print(\"KNN: Enabled\")\n",
    "else:\n",
    "    print(\"KNN: Disabled\")\n",
    "    \n",
    "if enable_mlp:\n",
    "    print(\"MLP: Enabled\")\n",
    "else:\n",
    "    print(\"MLP: Disabled\")\n",
    "    \n",
    "if enable_rf:\n",
    "    print(\"Random Forest: Enabeld\")\n",
    "else:\n",
    "    print(\"Random Forest: Disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.stdout=open(\"Initial_Binary_Model2.out\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 11 13:05:45 2018\n"
     ]
    }
   ],
   "source": [
    "t_start =  time.time()\n",
    "print(time.asctime( time.localtime(t_start) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C_YEAR  C_MNTH  C_WDAY  C_HOUR  C_VEHS  C_CONF  C_RCFG  C_WTHR  C_RSUR  \\\n",
      "0    1999       1       1      20       2      34       8       1       5   \n",
      "1    1999       1       1      20       2      34       2       1       5   \n",
      "\n",
      "   C_RALN   ...    V_ID  V_TYPE  V_YEAR  P_ID  P_SEX  P_AGE  P_PSN  P_SAFE  \\\n",
      "0       3   ...       1       6    1990     1      1     41     11       2   \n",
      "1       3   ...       2       1    1987     1      1     19     11       2   \n",
      "\n",
      "   P_USER  P_ISEV  \n",
      "0       1       1  \n",
      "1       1       1  \n",
      "\n",
      "[2 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv('data01_simple.csv', engine = 'python')\n",
    "df = pd.read_csv('data01_clean.csv', engine = 'python')\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df[df.columns].apply(lambda x: x.astype(str).str.contains('[^0-9]')).sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = df.astype('category').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_int = df.astype('int').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['C_YEAR', 'C_MNTH', 'C_WDAY', 'C_HOUR', 'C_VEHS', 'C_CONF', 'C_RCFG',\n",
      "       'C_WTHR', 'C_RSUR', 'C_RALN', 'C_TRAF', 'V_ID', 'V_TYPE', 'V_YEAR',\n",
      "       'P_ID', 'P_SEX', 'P_AGE', 'P_PSN', 'P_SAFE', 'P_USER', 'P_ISEV'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Class Variable to Binary if multi class disabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Fatal: 43559\n",
      "    C_YEAR C_MNTH C_WDAY C_HOUR C_VEHS C_CONF C_RCFG C_WTHR C_RSUR C_RALN  \\\n",
      "47    1999      1      1     23      1      4      2      1      1      4   \n",
      "151   1999      1      1     12      1      1      2      1      1      1   \n",
      "\n",
      "     ...   V_ID V_TYPE V_YEAR P_ID P_SEX P_AGE P_PSN P_SAFE P_USER P_ISEV  \n",
      "47   ...      1      6   1997    1     1    44    11      2      1      3  \n",
      "151  ...     99      1   2017    1     1    15    99      2      3      3  \n",
      "\n",
      "[2 rows x 21 columns]\n",
      "Number of Injury: 3351616\n",
      "  C_YEAR C_MNTH C_WDAY C_HOUR C_VEHS C_CONF C_RCFG C_WTHR C_RSUR C_RALN  \\\n",
      "2   1999      1      1     20      2     34      2      1      5      3   \n",
      "4   1999      1      1      8      1      1      2      5      3      6   \n",
      "\n",
      "   ...   V_ID V_TYPE V_YEAR P_ID P_SEX P_AGE P_PSN P_SAFE P_USER P_ISEV  \n",
      "2  ...      2      1   1987    2     0    20    13      2      2      2  \n",
      "4  ...     99      1   2017    1     1     5    99      2      3      2  \n",
      "\n",
      "[2 rows x 21 columns]\n",
      "Number of Non-Injury: 2568097\n",
      "  C_YEAR C_MNTH C_WDAY C_HOUR C_VEHS C_CONF C_RCFG C_WTHR C_RSUR C_RALN  \\\n",
      "0   1999      1      1     20      2     34      8      1      5      3   \n",
      "1   1999      1      1     20      2     34      2      1      5      3   \n",
      "\n",
      "   ...   V_ID V_TYPE V_YEAR P_ID P_SEX P_AGE P_PSN P_SAFE P_USER P_ISEV  \n",
      "0  ...      1      6   1990    1     1    41    11      2      1      1  \n",
      "1  ...      2      1   1987    1     1    19    11      2      1      1  \n",
      "\n",
      "[2 rows x 21 columns]\n",
      "Size of Fatal Subset: 43559\n",
      "Size of injury Subset: 3351616\n",
      "Size of non-fatal Subset: 2568097\n",
      "Shape of injury sampled dataframe: (43559, 21)\n",
      "Shape of nom-injury sampled dataframe: (43559, 21)\n",
      "(130677, 21)\n",
      "43559\n",
      "43559\n",
      "43559\n",
      "['2' '1' '0']\n"
     ]
    }
   ],
   "source": [
    "## Convert Class Variable to Binary\n",
    "### Merge Injury and Fatality as a single class\n",
    "### we will compare the results.\n",
    "if multiclass:\n",
    "    #Undersample the majority for the 3 class evaluation\n",
    "    \n",
    "    df_class = df_cat.copy()\n",
    "    \n",
    "    # subset fatal class\n",
    "    is_fatal =  df_class['P_ISEV']==3\n",
    "    is_fatal_count = is_fatal.sum()\n",
    "    print(\"Number of Fatal: {}\".format(is_fatal_count))\n",
    "    df_class_fatal = df_class[is_fatal]\n",
    "    print(df_class_fatal.head(2))\n",
    "    \n",
    "    # subset injury class\n",
    "    is_injury =  df_class['P_ISEV']==2\n",
    "    is_injury_count = is_injury.sum()\n",
    "    print(\"Number of Injury: {}\".format(is_injury_count))\n",
    "    df_class_injury = df_class[is_injury]\n",
    "    print(df_class_injury.head(2))\n",
    "    \n",
    "    # subset non_injury class\n",
    "    is_safe =  df_class['P_ISEV']==1\n",
    "    is_safe_count = is_safe.sum()\n",
    "    print(\"Number of Non-Injury: {}\".format(is_safe_count))\n",
    "    df_class_safe = df_class[is_safe]\n",
    "    print(df_class_safe.head(2))\n",
    "    \n",
    "    # get the size of fatal datafram\n",
    "    min_size = df_class_fatal.index.size\n",
    "    print(\"Size of Fatal Subset: {}\".format(min_size))\n",
    "    \n",
    "    # get size of injury\n",
    "    print(\"Size of injury Subset: {}\".format(df_class_injury.index.size))\n",
    "    \n",
    "    # size of non-fatal\n",
    "    print(\"Size of non-fatal Subset: {}\".format(df_class_safe.index.size))\n",
    "    \n",
    "    # randomly sample n number of injury and no injury and append to fatal\n",
    "    df_class_injury_select = df_class_injury.sample(n=min_size)\n",
    "    print(\"Shape of injury sampled dataframe: {}\".format(df_class_injury_select.shape))\n",
    "    df_class_safe_select = df_class_safe.sample(n=min_size)\n",
    "    print(\"Shape of nom-injury sampled dataframe: {}\".format(df_class_safe_select.shape))\n",
    "    \n",
    "    #concat the three dataframes\n",
    "    df_sample = pd.concat([df_class_fatal, df_class_injury_select, df_class_safe_select])\n",
    "    print(df_sample.shape)\n",
    "    \n",
    "    #perform the conversion in two steps to avoid any unwanted side effects\n",
    "    df_sample['P_ISEV'] = df_sample['P_ISEV'].map({1: 'safe', 2: 'injury', 3:'fatal'})\n",
    "    df_sample['P_ISEV'] = df_sample['P_ISEV'].map({'safe': '0', 'injury': '1', 'fatal':'2'})\n",
    "    print((df_sample['P_ISEV']=='0').sum())\n",
    "    print((df_sample['P_ISEV']=='1').sum())\n",
    "    print((df_sample['P_ISEV']=='2').sum())\n",
    "    print(df_sample['P_ISEV'].unique())\n",
    "else:\n",
    "    df_class = df_cat.copy()\n",
    "\n",
    "    #perform the conversion in two steps to avoid any unwanted side effects\n",
    "    df_class['P_ISEV'] = df_class['P_ISEV'].map({1: 'safe', 2: 'injury', 3:'fatal'})\n",
    "    df_class['P_ISEV'] = df_class['P_ISEV'].map({'safe': '0', 'injury': '1', 'fatal':'1'})\n",
    "    print((df_class['P_ISEV']=='0').sum())\n",
    "    print((df_class['P_ISEV']=='1').sum())\n",
    "    print(df_class['P_ISEV'].unique())\n",
    "    \n",
    "    df_sample = df_class.sample(n=sampleN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training and Testing for Binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split between data and class\n",
    "Y = df_sample[df_sample.columns[-1]]\n",
    "X = df_sample[df_sample.columns[0:df_sample.columns.size -1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Test(70%) and Train (30%) for Bianry class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sprint into train and test 70/30\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Xbinary_train, Xbinary_test, Ybinary_train, Ybinary_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write cleaned data to file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets write the datafile for future use\n",
    "df_sample.to_csv('cleansimple_binary.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering based on K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 11 13:09:20 2018\n",
      "K-Means Clustering: Start\n",
      "K-Means Clustering: Build\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 211280608.70485866\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 151581533.6000452\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 86971887.87358797\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 85350756.78652638\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 83135763.23882091\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 82887806.17937374\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 82853800.11943491\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 82842080.79316713\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 82838456.41562855\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 82837204.56623851\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 82836808.73143478\n",
      "center shift 7.014949e-02 within tolerance 9.624589e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 196788651.11647058\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 139619107.5266829\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 85831117.21057053\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 84854917.16539808\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 82934830.5847819\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 82836897.03114304\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 82836725.8740039\n",
      "center shift 4.112998e-02 within tolerance 9.624589e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 178294858.32405317\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 88632479.86262926\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 85914542.3141156\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 83365518.76121265\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 82943012.8048654\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 82871594.39465915\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 82848075.6282195\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 82840233.17075285\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 82837849.73661757\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 82837021.66731516\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 82836766.9111913\n",
      "center shift 5.388016e-02 within tolerance 9.624589e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 213638953.924335\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 208344793.32956466\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 203800970.11946413\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 173348729.51515928\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 86054379.9275626\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 84914956.80330577\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 82986516.33195783\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 82838976.52781023\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 82837410.00591189\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 82836876.70162651\n",
      "center shift 8.084966e-02 within tolerance 9.624589e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 85074414.1231138\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 83356614.59660053\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 82985006.1389722\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 82881834.55330178\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 82850393.11197764\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 82840254.82122791\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 82837621.74340965\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 82836920.16888706\n",
      "center shift 8.878472e-02 within tolerance 9.624589e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 84339938.4386998\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 83143254.61078359\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 82923326.3186353\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 82864816.4960279\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 82845887.71644102\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 82839607.05926047\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 82837617.63918738\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 82836945.42940916\n",
      "center shift 9.174550e-02 within tolerance 9.624589e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 201410327.0266712\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 148420853.8703528\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 86554751.69288714\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 84879953.36775298\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 82931358.92038362\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 82856617.53853403\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 82842092.92461945\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 82838109.71925287\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 82837054.6681433\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 82836796.72273801\n",
      "center shift 5.441452e-02 within tolerance 9.624589e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 86710994.97096223\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 83082597.5120665\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 82858105.5070456\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 82839167.47433548\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 82836995.52236857\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 82836742.42508146\n",
      "center shift 4.847668e-02 within tolerance 9.624589e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 223617979.72345608\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 185220342.60297087\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 89849734.87091582\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 85322238.73988469\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 83652400.83510375\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 82840385.99119832\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 82837627.42175806\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 82836936.12587376\n",
      "center shift 8.482112e-02 within tolerance 9.624589e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 199838863.31298003\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 101419398.2842237\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 85300768.26690929\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 83203616.41001028\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 82861714.60643086\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 82843607.96151373\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 82838530.12150104\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 82837140.42559563\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 82836824.09013885\n",
      "center shift 5.795492e-02 within tolerance 9.624589e-03\n",
      "[[2.00651365e+03 6.74756847e+00 4.18824762e+00 1.33068893e+01\n",
      "  1.95226383e+00 2.13434600e+01 1.62442705e+00 1.63237842e+00\n",
      "  1.59937116e+00 1.58563443e+00 1.22706680e+01 1.43521520e+00\n",
      "  2.52585243e+00 1.99975981e+03 1.60389883e+00 6.11710453e-01\n",
      "  2.42456400e+01 1.48631079e+01 2.44569592e+00 1.58651481e+00]\n",
      " [2.00710014e+03 6.96448864e+00 3.94045928e+00 1.37228930e+01\n",
      "  1.15021307e+00 9.09753788e+00 1.62215909e+00 1.59031723e+00\n",
      "  1.46827652e+00 1.33013731e+00 1.20866477e+01 9.90000000e+01\n",
      "  2.23283617e+00 2.01700000e+03 1.04876894e+00 5.73508523e-01\n",
      "  4.59308712e+01 9.89895833e+01 5.13494318e+00 3.00000000e+00]\n",
      " [2.00724899e+03 6.76857645e+00 3.96469242e+00 1.35788747e+01\n",
      "  2.03820877e+00 2.34894117e+01 1.65852888e+00 1.61899781e+00\n",
      "  1.57747341e+00 1.53892913e+00 1.16676271e+01 1.50152953e+00\n",
      "  2.70544120e+00 2.00061527e+03 1.28449348e+00 6.04708994e-01\n",
      "  5.69910399e+01 1.26296552e+01 2.50020723e+00 1.45370937e+00]]\n",
      "[2 1 1 ... 0 0 0]\n",
      "K-Means Clustering: End\n",
      "Sun Nov 11 13:09:24 2018\n"
     ]
    }
   ],
   "source": [
    "if enable_kmeans:\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print(\"K-Means Clustering: Start\")\n",
    "    kmeans = KMeans(n_clusters=3, init='random', n_init=10, max_iter=100, tol=1e-04, verbose= verbose_level)\n",
    "    print(\"K-Means Clustering: Build\")\n",
    "    ykm = kmeans.fit(X)\n",
    "    \n",
    "    if pyscript:\n",
    "        print(ykm.cluster_centers_)\n",
    "        print(ykm.labels_)\n",
    "    else:\n",
    "        display(ykm.cluster_centers_)\n",
    "        display(ykm.labels_)\n",
    "    \n",
    "    print(\"K-Means Clustering: End\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection using Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the inportant features from random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Selection: Start\n",
      "Sun Nov 11 13:09:24 2018\n",
      "Random Forest Feature Selection: Fit Start\n",
      "building tree 1 of 250building tree 2 of 250\n",
      "\n",
      "building tree 3 of 250\n",
      "building tree 4 of 250\n",
      "building tree 5 of 250\n",
      "building tree 6 of 250\n",
      "building tree 7 of 250building tree 8 of 250\n",
      "\n",
      "building tree 9 of 250\n",
      "building tree 10 of 250\n",
      "building tree 11 of 250\n",
      "building tree 12 of 250\n",
      "building tree 13 of 250\n",
      "building tree 14 of 250\n",
      "building tree 15 of 250\n",
      "building tree 16 of 250\n",
      "building tree 17 of 250\n",
      "building tree 18 of 250\n",
      "building tree 19 of 250\n",
      "building tree 20 of 250\n",
      "building tree 21 of 250\n",
      "building tree 22 of 250building tree 23 of 250\n",
      "\n",
      "building tree 24 of 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 25 of 250building tree 26 of 250\n",
      "\n",
      "building tree 27 of 250\n",
      "building tree 28 of 250\n",
      "building tree 29 of 250\n",
      "building tree 30 of 250\n",
      "building tree 31 of 250\n",
      "building tree 32 of 250\n",
      "building tree 33 of 250\n",
      "building tree 34 of 250\n",
      "building tree 35 of 250\n",
      "building tree 36 of 250\n",
      "building tree 37 of 250\n",
      "building tree 38 of 250\n",
      "building tree 39 of 250\n",
      "building tree 40 of 250\n",
      "building tree 41 of 250\n",
      "building tree 42 of 250\n",
      "building tree 43 of 250\n",
      "building tree 44 of 250\n",
      "building tree 45 of 250\n",
      "building tree 46 of 250\n",
      "building tree 47 of 250\n",
      "building tree 48 of 250\n",
      "building tree 49 of 250\n",
      "building tree 50 of 250\n",
      "building tree 51 of 250\n",
      "building tree 52 of 250\n",
      "building tree 53 of 250\n",
      "building tree 54 of 250\n",
      "building tree 55 of 250\n",
      "building tree 56 of 250\n",
      "building tree 57 of 250\n",
      "building tree 58 of 250\n",
      "building tree 59 of 250building tree 60 of 250\n",
      "\n",
      "building tree 61 of 250\n",
      "building tree 62 of 250\n",
      "building tree 63 of 250\n",
      "building tree 64 of 250\n",
      "building tree 65 of 250\n",
      "building tree 66 of 250\n",
      "building tree 67 of 250\n",
      "building tree 68 of 250\n",
      "building tree 69 of 250\n",
      "building tree 70 of 250\n",
      "building tree 71 of 250\n",
      "building tree 72 of 250\n",
      "building tree 73 of 250\n",
      "building tree 74 of 250\n",
      "building tree 75 of 250\n",
      "building tree 76 of 250\n",
      "building tree 77 of 250\n",
      "building tree 78 of 250\n",
      "building tree 79 of 250\n",
      "building tree 80 of 250\n",
      "building tree 81 of 250\n",
      "building tree 82 of 250\n",
      "building tree 83 of 250\n",
      "building tree 84 of 250\n",
      "building tree 85 of 250\n",
      "building tree 86 of 250\n",
      "building tree 87 of 250\n",
      "building tree 88 of 250\n",
      "building tree 89 of 250\n",
      "building tree 90 of 250\n",
      "building tree 91 of 250\n",
      "building tree 92 of 250\n",
      "building tree 93 of 250\n",
      "building tree 94 of 250\n",
      "building tree 95 of 250\n",
      "building tree 96 of 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:    3.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 97 of 250\n",
      "building tree 98 of 250\n",
      "building tree 99 of 250\n",
      "building tree 100 of 250\n",
      "building tree 101 of 250\n",
      "building tree 102 of 250\n",
      "building tree 103 of 250\n",
      "building tree 104 of 250\n",
      "building tree 105 of 250\n",
      "building tree 106 of 250\n",
      "building tree 107 of 250\n",
      "building tree 108 of 250\n",
      "building tree 109 of 250\n",
      "building tree 110 of 250building tree 111 of 250\n",
      "\n",
      "building tree 112 of 250\n",
      "building tree 113 of 250\n",
      "building tree 114 of 250\n",
      "building tree 115 of 250\n",
      "building tree 116 of 250\n",
      "building tree 117 of 250\n",
      "building tree 118 of 250\n",
      "building tree 119 of 250\n",
      "building tree 120 of 250\n",
      "building tree 121 of 250\n",
      "building tree 122 of 250\n",
      "building tree 123 of 250\n",
      "building tree 124 of 250\n",
      "building tree 125 of 250\n",
      "building tree 126 of 250\n",
      "building tree 127 of 250\n",
      "building tree 128 of 250\n",
      "building tree 129 of 250\n",
      "building tree 130 of 250\n",
      "building tree 131 of 250\n",
      "building tree 132 of 250\n",
      "building tree 133 of 250\n",
      "building tree 134 of 250\n",
      "building tree 135 of 250\n",
      "building tree 136 of 250\n",
      "building tree 137 of 250\n",
      "building tree 138 of 250\n",
      "building tree 139 of 250\n",
      "building tree 140 of 250\n",
      "building tree 141 of 250\n",
      "building tree 142 of 250\n",
      "building tree 143 of 250\n",
      "building tree 144 of 250\n",
      "building tree 145 of 250\n",
      "building tree 146 of 250\n",
      "building tree 147 of 250\n",
      "building tree 148 of 250\n",
      "building tree 149 of 250\n",
      "building tree 150 of 250\n",
      "building tree 151 of 250\n",
      "building tree 152 of 250\n",
      "building tree 153 of 250\n",
      "building tree 154 of 250\n",
      "building tree 155 of 250\n",
      "building tree 156 of 250\n",
      "building tree 157 of 250\n",
      "building tree 158 of 250\n",
      "building tree 159 of 250\n",
      "building tree 160 of 250\n",
      "building tree 161 of 250\n",
      "building tree 162 of 250\n",
      "building tree 163 of 250\n",
      "building tree 164 of 250\n",
      "building tree 165 of 250\n",
      "building tree 166 of 250\n",
      "building tree 167 of 250building tree 168 of 250\n",
      "\n",
      "building tree 169 of 250\n",
      "building tree 170 of 250\n",
      "building tree 171 of 250\n",
      "building tree 172 of 250\n",
      "building tree 173 of 250\n",
      "building tree 174 of 250\n",
      "building tree 175 of 250\n",
      "building tree 176 of 250\n",
      "building tree 177 of 250\n",
      "building tree 178 of 250\n",
      "building tree 179 of 250\n",
      "building tree 180 of 250\n",
      "building tree 181 of 250\n",
      "building tree 182 of 250\n",
      "building tree 183 of 250\n",
      "building tree 184 of 250\n",
      "building tree 185 of 250\n",
      "building tree 186 of 250\n",
      "building tree 187 of 250\n",
      "building tree 188 of 250\n",
      "building tree 189 of 250\n",
      "building tree 190 of 250\n",
      "building tree 191 of 250\n",
      "building tree 192 of 250\n",
      "building tree 193 of 250\n",
      "building tree 194 of 250\n",
      "building tree 195 of 250\n",
      "building tree 196 of 250\n",
      "building tree 197 of 250\n",
      "building tree 198 of 250\n",
      "building tree 199 of 250\n",
      "building tree 200 of 250\n",
      "building tree 201 of 250\n",
      "building tree 202 of 250\n",
      "building tree 203 of 250\n",
      "building tree 204 of 250\n",
      "building tree 205 of 250\n",
      "building tree 206 of 250\n",
      "building tree 207 of 250\n",
      "building tree 208 of 250\n",
      "building tree 209 of 250\n",
      "building tree 210 of 250\n",
      "building tree 211 of 250\n",
      "building tree 212 of 250\n",
      "building tree 213 of 250\n",
      "building tree 214 of 250\n",
      "building tree 215 of 250\n",
      "building tree 216 of 250\n",
      "building tree 217 of 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed:    8.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 218 of 250\n",
      "building tree 219 of 250\n",
      "building tree 220 of 250\n",
      "building tree 221 of 250\n",
      "building tree 222 of 250\n",
      "building tree 223 of 250\n",
      "building tree 224 of 250\n",
      "building tree 225 of 250\n",
      "building tree 226 of 250\n",
      "building tree 227 of 250\n",
      "building tree 228 of 250\n",
      "building tree 229 of 250\n",
      "building tree 230 of 250\n",
      "building tree 231 of 250\n",
      "building tree 232 of 250\n",
      "building tree 233 of 250\n",
      "building tree 234 of 250\n",
      "building tree 235 of 250\n",
      "building tree 236 of 250\n",
      "building tree 237 of 250\n",
      "building tree 238 of 250\n",
      "building tree 239 of 250\n",
      "building tree 240 of 250\n",
      "building tree 241 of 250\n",
      "building tree 242 of 250\n",
      "building tree 243 of 250\n",
      "building tree 244 of 250\n",
      "building tree 245 of 250\n",
      "building tree 246 of 250\n",
      "building tree 247 of 250\n",
      "building tree 248 of 250\n",
      "building tree 249 of 250\n",
      "building tree 250 of 250\n",
      "Random Forest Feature Selection: Fit\n",
      "Random Forest Feature Selection: Feature Importance\n",
      "[0.0834577  0.07503953 0.06160617 0.09303    0.03450744 0.09665788\n",
      " 0.03058348 0.02836922 0.02735289 0.03022306 0.0331378  0.02498694\n",
      " 0.0242914  0.09184883 0.01686839 0.01840339 0.12254422 0.02550727\n",
      " 0.05444795 0.02713646]\n",
      "[16  5  3 13  0  1  2 18  4 10  6  9  7  8 19 17 11 12 15 14]\n",
      "Index(['C_YEAR', 'C_MNTH', 'C_WDAY', 'C_HOUR', 'C_VEHS', 'C_CONF', 'C_RCFG',\n",
      "       'C_WTHR', 'C_RSUR', 'C_RALN', 'C_TRAF', 'V_ID', 'V_TYPE', 'V_YEAR',\n",
      "       'P_ID', 'P_SEX', 'P_AGE', 'P_PSN', 'P_SAFE', 'P_USER'],\n",
      "      dtype='object')\n",
      " 1) P_AGE                          0.122544\n",
      " 2) C_CONF                         0.096658\n",
      " 3) C_HOUR                         0.093030\n",
      " 4) V_YEAR                         0.091849\n",
      " 5) C_YEAR                         0.083458\n",
      " 6) C_MNTH                         0.075040\n",
      " 7) C_WDAY                         0.061606\n",
      " 8) P_SAFE                         0.054448\n",
      " 9) C_VEHS                         0.034507\n",
      "10) C_TRAF                         0.033138\n",
      "11) C_RCFG                         0.030583\n",
      "12) C_RALN                         0.030223\n",
      "13) C_WTHR                         0.028369\n",
      "14) C_RSUR                         0.027353\n",
      "15) P_USER                         0.027136\n",
      "16) P_PSN                          0.025507\n",
      "17) V_ID                           0.024987\n",
      "18) V_TYPE                         0.024291\n",
      "19) P_SEX                          0.018403\n",
      "20) P_ID                           0.016868\n",
      "['P_AGE', 'C_CONF', 'C_HOUR', 'V_YEAR', 'C_YEAR', 'C_MNTH', 'C_WDAY', 'P_SAFE', 'C_VEHS', 'C_TRAF', 'C_RCFG', 'C_RALN', 'C_WTHR', 'C_RSUR', 'P_USER', 'P_PSN', 'V_ID', 'V_TYPE', 'P_SEX', 'P_ID']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   10.4s finished\n"
     ]
    }
   ],
   "source": [
    "if enable_rf_features:\n",
    "    print(\"Random Forest Feature Selection: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    forest = RandomForestClassifier(n_estimators=250, random_state=0, n_jobs=-1, verbose=verbose_level)\n",
    "    print(\"Random Forest Feature Selection: Fit Start\")\n",
    "    forest.fit(X, Y)\n",
    "    print(\"Random Forest Feature Selection: Fit\")\n",
    "\n",
    "    importFeatures = forest.feature_importances_\n",
    "    print(\"Random Forest Feature Selection: Feature Importance\")\n",
    "    print(importFeatures)\n",
    "    \n",
    "    indices = np.argsort(importFeatures)[::-1]\n",
    "    print(indices)\n",
    "    featureLabel = X.columns[0:]\n",
    "    print(featureLabel)\n",
    "    rankedFeature = []\n",
    "    for f in range(X.shape[1]):\n",
    "        rankedFeature.append(featureLabel[indices[f]])\n",
    "        print(\"%2d) %-*s %f\" % (f+1, 30,  featureLabel[indices[f]], importFeatures[indices[f]]))\n",
    "    print(rankedFeature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce the number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        P_AGE C_CONF C_HOUR V_YEAR C_YEAR C_MNTH C_WDAY P_SAFE C_VEHS C_TRAF\n",
      "47         44      4     23   1997   1999      1      1      2      1     18\n",
      "151        15      1     12   2017   1999      1      1      2      1      6\n",
      "258        26      1     15   2017   1999      1      1      2      1      1\n",
      "307        74      2     22   1991   1999      1      1      2      1     18\n",
      "503        59     31     13   1989   1999      1      1      2      2     18\n",
      "513         5      1      7   2017   1999      1      1      2      1     18\n",
      "524        60     35     20   1990   1999      1      1     13      2      1\n",
      "527        52     21     20   1986   1999      1      1      2      2     18\n",
      "640        30     31     11   1988   1999      1      1      2      2     18\n",
      "641        27     31     11   1988   1999      1      1      2      2     18\n",
      "642         7     31     11   1988   1999      1      1      2      2     18\n",
      "...       ...    ...    ...    ...    ...    ...    ...    ...    ...    ...\n",
      "4009826    33     32     12   2001   2010      4      6      2      2      4\n",
      "3055213     8     35     22   2002   2007      3      5      2      3      1\n",
      "5904223    40      6     19   2002   2016     10      5      9      2     18\n",
      "1607405    59     31     11   1998   2003      2      7      2      2     18\n",
      "4139307     5     24     15   2001   2010      9      4      2      2     18\n",
      "1868572    38     24     12   1999   2003     11      3      2      2     18\n",
      "5502622    34     21     18   2014   2015      5      7      2      2     18\n",
      "2338802    45     35     13   1997   2005      3      2      2      2      3\n",
      "1836636    26     33     20   1997   2003     10      3      2      2     18\n",
      "2110263    33     21     11   1987   2004      7      5      2      2      1\n",
      "3316308    34     22     11   2007   2007     12      7      2      2     18\n",
      "\n",
      "[130677 rows x 10 columns]\n",
      "Sun Nov 11 13:09:35 2018\n",
      "Random Forest Feature Selection: End\n"
     ]
    }
   ],
   "source": [
    "#select features that contribute more than 0.05\n",
    "if enable_rf_features:\n",
    "    X_Selected = X[rankedFeature[0:10]]\n",
    "else:\n",
    "    if feature_all:\n",
    "        X_Selected = X\n",
    "    else:\n",
    "        X_Selected = X[defaultFeatures]\n",
    "\n",
    "if pyscript:\n",
    "    print(X_Selected)\n",
    "else:\n",
    "    display(X_Selected)\n",
    "\n",
    "t_end =  time.time()\n",
    "print(time.asctime( time.localtime(t_end) ))\n",
    "\n",
    "print(\"Random Forest Feature Selection: End\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Test and Train based on Selected Features\n"
     ]
    }
   ],
   "source": [
    "print(\"Split Test and Train based on Selected Features\")\n",
    "#sprint into train and test 70/30\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_Selected, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM GridSearch for Optimal Parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This operation is computationaly expensive.\n",
    "if enable_grid_search:\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    param_grid = {'C':[0.1, 1, 10, 100, 1000], 'gamma':[1, 0.1, 0.01, 0.001, 0.0001]}\n",
    "    grid = GridSearchCV(SVC(), param_grid, verbose=verbose_level)\n",
    "    grid.fit(X_train, Y_train)\n",
    "    print(grid.best_params_)\n",
    "    svm_c = grid.best_params_.get('C')\n",
    "    svm_gamma = grid.best_params_.get('gamma')\n",
    "    print(grid.best_estimator_)\n",
    "    grid_predictions = grid.predict(X_test)\n",
    "    cfn_matrix_grid = confusion_matrix(Y_test, grid_predictions)\n",
    "    print(cfn_matrix_grid)\n",
    "    print(classification_report(Y_test,grid_predictions))\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Start\n",
      "Sun Nov 11 13:09:35 2018\n",
      "Logistic Regression: Fit\n",
      "[LibLinear]Logistic Regression: Predict\n",
      "Accuracy of logistic regression classifier on train set: 0.47\n",
      "Accuracy of logistic regression classifier on test set: 0.46\n",
      "Logistic Regression: Intercept\n",
      "[-5.09996102e-04 -5.63764791e-05  8.50339240e-04]\n",
      "Logistic Regression: Coefficients\n",
      "[[-0.01087864  0.00964506  0.01994049 -0.01267847  0.01231995 -0.0047745\n",
      "  -0.02485683 -0.09374094  0.37538169 -0.04319582]\n",
      " [-0.00656579 -0.00109746  0.00515405  0.00315407 -0.00314781 -0.00959903\n",
      "  -0.03530438  0.00750739 -0.02344563 -0.02145296]\n",
      " [ 0.01849188 -0.00304781 -0.02552123  0.00788566 -0.00871877  0.01604748\n",
      "   0.06007965  0.0612583  -0.44122949  0.07717584]]\n",
      "Logistic Regression: Confusion Matrix\n",
      "[[8032 1150 3981]\n",
      " [6126 1329 5663]\n",
      " [3044 1059 8820]]\n",
      "Logistic Regression: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.61      0.53     13163\n",
      "          1       0.38      0.10      0.16     13118\n",
      "          2       0.48      0.68      0.56     12923\n",
      "\n",
      "avg / total       0.44      0.46      0.42     39204\n",
      "\n",
      "Sun Nov 11 13:09:38 2018\n",
      "Logistic Regression: End\n"
     ]
    }
   ],
   "source": [
    "if enable_logistic_regression:\n",
    "    print(\"Logistic Regression: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    lr = LogisticRegression(C=1, random_state=0, verbose=verbose_level)\n",
    "    print(\"Logistic Regression: Fit\")\n",
    "    lr.fit(X_train, Y_train)\n",
    "    print(\"Logistic Regression: Predict\")\n",
    "    y_pred = lr.predict(X_test)\n",
    "\n",
    "    print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(lr.score(X_train, Y_train)))\n",
    "    print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(lr.score(X_test, Y_test)))\n",
    "\n",
    "    # print the intercept (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "    print(\"Logistic Regression: Intercept\")\n",
    "    print(lr.intercept_)\n",
    "\n",
    "    # print the coeficients (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "    print(\"Logistic Regression: Coefficients\")\n",
    "    print(lr.coef_)\n",
    "\n",
    "    print(\"Logistic Regression: Confusion Matrix\")\n",
    "    cnf_matrix_lg = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_lg)\n",
    "    \n",
    "    print(\"Logistic Regression: Classification Report\")\n",
    "    print(classification_report(Y_test, y_pred))\n",
    "\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "    print(\"Logistic Regression: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with L1 Regularization: Start\n",
      "Sun Nov 11 13:09:38 2018\n",
      "Logistic Regression with L1 Regularization: Fit\n",
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:898: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with L1 Regularization: Predict\n",
      "Accuracy of logistic regression classifier on train set: 0.47\n",
      "Accuracy of logistic regression classifier on test set: 0.46\n",
      "Logistic Regression with L1 Regularization: Confusion Matrix\n",
      "[[8116 1062 3985]\n",
      " [6231 1229 5658]\n",
      " [3047 1031 8845]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.62      0.53     13163\n",
      "          1       0.37      0.09      0.15     13118\n",
      "          2       0.48      0.68      0.56     12923\n",
      "\n",
      "avg / total       0.44      0.46      0.41     39204\n",
      "\n",
      "Logistic Regression with L1 Regularization: Classification Report\n",
      "Sun Nov 11 13:13:27 2018\n",
      "Logistic Regression with L1 Regularization: End\n"
     ]
    }
   ],
   "source": [
    "if enable_logistic_regression_l1:\n",
    "    # with L1 regularization\n",
    "    print(\"Logistic Regression with L1 Regularization: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    lr = LogisticRegression(penalty='l1', C=1, random_state=0, verbose=verbose_level)\n",
    "    print(\"Logistic Regression with L1 Regularization: Fit\")\n",
    "    lr.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"Logistic Regression with L1 Regularization: Predict\")\n",
    "    y_pred = lr.predict(X_test)\n",
    "    \n",
    "    print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(lr.score(X_train, Y_train)))\n",
    "    print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(lr.score(X_test, Y_test)))\n",
    "\n",
    "    print(\"Logistic Regression with L1 Regularization: Confusion Matrix\")\n",
    "    cnf_matrix_lg_l1 = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_lg_l1)\n",
    "    \n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    print(\"Logistic Regression with L1 Regularization: Classification Report\")\n",
    "\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "    print(\"Logistic Regression with L1 Regularization: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: Start\n",
      "Sun Nov 11 13:13:27 2018\n",
      "Decision Tree: Fit\n",
      "Decision Tree: Predict\n",
      "Accuracy of Decision Tree classifier on train set: 1.00\n",
      "Accuracy of Decision Tree classifier on test set: 0.50\n",
      "Decision Tree: Confusion Matrix\n",
      "[[6421 4849 1893]\n",
      " [4805 5168 3145]\n",
      " [1844 3110 7969]]\n",
      "Decision Tree: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.49      0.49     13163\n",
      "          1       0.39      0.39      0.39     13118\n",
      "          2       0.61      0.62      0.61     12923\n",
      "\n",
      "avg / total       0.50      0.50      0.50     39204\n",
      "\n",
      "Sun Nov 11 13:13:28 2018\n",
      "Decision Tree: End\n"
     ]
    }
   ],
   "source": [
    "if enable_decision_tree:\n",
    "    print(\"Decision Tree: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    tree = DecisionTreeClassifier(criterion='entropy',max_depth=50, random_state=0)\n",
    "    print(\"Decision Tree: Fit\")\n",
    "    tree.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"Decision Tree: Predict\")\n",
    "    y_pred = tree.predict(X_test)\n",
    "    print('Accuracy of Decision Tree classifier on train set: {:.2f}'.format(tree.score(X_train, Y_train)))\n",
    "    print('Accuracy of Decision Tree classifier on test set: {:.2f}'.format(tree.score(X_test, Y_test)))\n",
    "    \n",
    "    cnf_matrix_dt = confusion_matrix(Y_test, y_pred)\n",
    "    print(\"Decision Tree: Confusion Matrix\")\n",
    "    print(cnf_matrix_dt)\n",
    "    print(\"Decision Tree: Classification Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    print(\"Decision Tree: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-N-N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: Start\n",
      "Sun Nov 11 13:13:28 2018\n",
      "KNN: Fit\n",
      "KNN: Predict\n",
      "Accuracy of KNN classifier on train set: 0.66\n",
      "Accuracy of KNN classifier on test set: 0.50\n",
      "KNN: Confusion Matrix\n",
      "[[7536 4110 1517]\n",
      " [5709 4565 2844]\n",
      " [2445 2871 7607]]\n",
      "KNN: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.57      0.52     13163\n",
      "          1       0.40      0.35      0.37     13118\n",
      "          2       0.64      0.59      0.61     12923\n",
      "\n",
      "avg / total       0.50      0.50      0.50     39204\n",
      "\n",
      "Sun Nov 11 13:13:48 2018\n",
      "KNN: End\n"
     ]
    }
   ],
   "source": [
    "if enable_knn:\n",
    "    print(\"KNN: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    knn = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "    print(\"KNN: Fit\")\n",
    "    knn.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"KNN: Predict\")\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print('Accuracy of KNN classifier on train set: {:.2f}'.format(knn.score(X_train, Y_train)))\n",
    "    print('Accuracy of KNN classifier on test set: {:.2f}'.format(knn.score(X_test, Y_test)))\n",
    "    \n",
    "    print(\"KNN: Confusion Matrix\")\n",
    "    cnf_matrix_knn = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_knn)\n",
    "\n",
    "    print(\"KNN: Classification Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "\n",
    "    print(\"KNN: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: Start\n",
      "Sun Nov 11 13:13:48 2018\n",
      "SVM: Fit\n",
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "if enable_svm:\n",
    "    print(\"SVM: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    #svm = SVC(C=1, random_state=0, kernel='sigmoid', verbose=True)\n",
    "    #svm = SVC(C=1, random_state=0, kernel='linear', verbose=True, cache_size=200)\n",
    "    svm = SVC(C=svm_c, gamma=svm_gamma, verbose = verbose_level)\n",
    "    print(\"SVM: Fit\")\n",
    "    svm.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"SVM: Predict\")\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    print('Accuracy of SVM classifier on train set: {:.2f}'.format(svm.score(X_train, Y_train)))\n",
    "    print('Accuracy of SVM classifier on test set: {:.2f}'.format(svm.score(X_test, Y_test)))\n",
    "    \n",
    "    print(\"SVM: Confusion Matrix\")\n",
    "    cnf_matrix_svm = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_svm)\n",
    "    \n",
    "    print(\"SVM: Classfication Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "    print(\"SVM: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN - Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_mlp:\n",
    "    print(\"Multilayer Preceptron: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    \n",
    "    #mlpc = MLPClassifier(alpha=1)\n",
    "    mlpc = MLPClassifier(hidden_layer_sizes=(12, 12, 12), max_iter=100, verbose=verbose_level)\n",
    "    \n",
    "    #mlp = multilayer_perceptron(n_hidden =2, activation='logistic', algorithm='sgd', random_state=3)\n",
    "    print(\"Multilayer Preceptron: fit\")\n",
    "    mlpc.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"Multilayer Preceptron: Predict\")\n",
    "    y_pred = mlpc.predict(X_test)\n",
    "\n",
    "    print('Accuracy of Multilayer Perceptron classifier on train set: {:.2f}'.format(mlpc.score(X_train, Y_train)))\n",
    "    print('Accuracy of Multilayer Perceptron classifier on test set: {:.2f}'.format(mlpc.score(X_test, Y_test)))\n",
    "    \n",
    "    print(\"Multilayer Preceptron: Confusion Matrix\")\n",
    "    cnf_matrix_mlp = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_mlp)\n",
    "    \n",
    "    print(\"Multilayer Preceptron: Classificiation Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "    print(\"Multilayer Preceptron: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_rf:\n",
    "    print(\"Ensemble (Bagging): Random Forest: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    forest = RandomForestClassifier(criterion='entropy', n_estimators=50, random_state=0, n_jobs=2, verbose=verbose_level)\n",
    "    print(\"Ensemble (Bagging): Random Forest: Fit\")\n",
    "    forest.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"Ensemble (Bagging): Random Forest: Predict\")\n",
    "    y_pred = forest.predict(X_test)\n",
    "    \n",
    "    print('Accuracy of RandomForest classifier on train set: {:.2f}'.format(forest.score(X_train, Y_train)))\n",
    "    print('Accuracy of RandomForest classifier on test set: {:.2f}'.format(forest.score(X_test, Y_test)))\n",
    "    \n",
    "    print(\"Ensemble (Bagging): Random Forest: Confusion Matrix\")\n",
    "    cnf_matrix_rf = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_rf)\n",
    "    \n",
    "    print(\"Ensemble (Bagging): Random Forest: Classification Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    \n",
    "    print(\"Ensemble (Bagging): Random Forest: End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#check sigmoid and rbf\n",
    "#from sklearn.ensemble import BaggingClassifier\n",
    "#from sklearn.svm import SVC\n",
    "#clf = BaggingClassifier(SVC(C=1.0,\n",
    "#        cache_size=200,\n",
    "#        class_weight=None,\n",
    "#        coef0=0.0,\n",
    "#        decision_function_shape=None,\n",
    "#        degree=3,\n",
    "#        gamma='auto',\n",
    "#        kernel='linear',\n",
    "#        max_iter=-1,\n",
    "#        probability=False,\n",
    "#        random_state=None,\n",
    "#        shrinking=True,\n",
    "#        tol=0.001,\n",
    "#        verbose=False,\n",
    "#        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_end =  time.time()\n",
    "print(time.asctime( time.localtime(t_end) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.stdout.close()\n",
    "%logstop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
