{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#in case we need to repeat experiment\n",
    "#np.random.seed(255)\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 22\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('classic')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "#sklearn imports\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import model_selection\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pickle # allows for model to be saved/load to file\n",
    "\n",
    "\n",
    "#Use print instead of display when run as python script\n",
    "pyscript = True\n",
    "\n",
    "#Classifier verborsity where supported\n",
    "verbose_level=3\n",
    "\n",
    "#Sample Size (5963272)\n",
    "#sampleN = 3000000\n",
    "#SampleN = 5963000\n",
    "sampleN = 3500000\n",
    "\n",
    "import time\n",
    "\n",
    "#datafile\n",
    "#datafile = 'NCDB_FULL_Removed_All_Missing_Values_Multi_Class.csv'\n",
    "datafile = 'NCDB_FULL_Removed_All_Missing_Values_Binary_Class_Transformed.csv'\n",
    "\n",
    "#Model Store\n",
    "file_lr = 'lr_dec_02.model'\n",
    "file_lr_l1 = 'lr_l2_dec_01.model'\n",
    "file_dt = 'dt_dec_02.model'\n",
    "file_svm = 'svm_dec_02.model'\n",
    "file_knn = 'knn_dec_02.model'\n",
    "file_mlp = 'mlp_dec_02.model'\n",
    "file_kmean = 'kmean_dec_02.model'\n",
    "file_nbayes = 'nbayes_dec_02.model'\n",
    "\n",
    "file_final_train = 'final_train_dec_02.data'\n",
    "file_final_test = 'final_test_dec_02.data'\n",
    "\n",
    "#Enable Optimization Algorithms\n",
    "enable_grid_search = False\n",
    "svm_c = 1\n",
    "svm_gamma = 1\n",
    "feature_all = True\n",
    "defaultFeatures = ['P_AGE', 'V_YEAR', 'C_HOUR', 'C_YEAR', 'C_MNTH', 'C_CONF', 'C_WDAY', 'C_VEHS', 'P_USER', 'P_SEX']\n",
    "\n",
    "enable_lr_l1 = True\n",
    "predict_lr_l1 = True\n",
    "\n",
    "# Enable Algorithms\n",
    "enable_lr = True\n",
    "enable_dt = True\n",
    "enable_svm = True\n",
    "enable_knn = True\n",
    "enable_mlp = True\n",
    "enable_kmean = True\n",
    "enable_nbayes = True\n",
    "\n",
    "predict_lr = True\n",
    "predict_dt = True\n",
    "predict_svm = True\n",
    "predict_knn = True\n",
    "predict_mlp = True\n",
    "predict_nbayes = True\n",
    "\n",
    "\n",
    "#Multiclass classification, binary if falase\n",
    "multiclass = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 3500000\n",
      "Multi-Class Classification: Disabled\n",
      "Grid Search: Disabled\n",
      "All Features: Enabled\n",
      "K-means: Enabled\n",
      "Logistic Regression: Enabled\n",
      "Decision Tree: Enabled\n",
      "Support Vector Machines: Enabled\n",
      "KNN: Enabled\n",
      "MLP: Enabled\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample size: {}\".format(sampleN))\n",
    "\n",
    "if multiclass:\n",
    "    print(\"Multi-Class Classification: Enabled\")\n",
    "else:\n",
    "    print(\"Multi-Class Classification: Disabled\")\n",
    "\n",
    "if enable_grid_search:\n",
    "    print(\"Grid Search: Enabled\")\n",
    "else:\n",
    "    print(\"Grid Search: Disabled\")\n",
    "\n",
    "if feature_all:\n",
    "    print(\"All Features: Enabled\")\n",
    "else:\n",
    "    print(\"All Features: Disabled\")\n",
    "    \n",
    "if enable_kmean:\n",
    "    print(\"K-means: Enabled\")\n",
    "else:\n",
    "    print(\"K-means: Disabled\")\n",
    "\n",
    "if enable_lr_l1:\n",
    "    print(\"Logistic Regression: Enabled\")\n",
    "else:\n",
    "    print(\"Logistic Regression: Disabled\")\n",
    "    \n",
    "if enable_dt:\n",
    "    print(\"Decision Tree: Enabled\")\n",
    "else:\n",
    "    print(\"Decision Tree: Disabled\")\n",
    "    \n",
    "if enable_svm:\n",
    "    print(\"Support Vector Machines: Enabled\")\n",
    "else:\n",
    "    print(\"Support Vector Machines: Disabled\")\n",
    "\n",
    "if  enable_knn:\n",
    "    print(\"KNN: Enabled\")\n",
    "else:\n",
    "    print(\"KNN: Disabled\")\n",
    "    \n",
    "if enable_mlp:\n",
    "    print(\"MLP: Enabled\")\n",
    "else:\n",
    "    print(\"MLP: Disabled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Dec  1 02:54:37 2018\n"
     ]
    }
   ],
   "source": [
    "t_start =  time.time()\n",
    "print(time.asctime( time.localtime(t_start) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C_YEAR  C_MNTH  C_WDAY  C_HOUR  C_VEHS  C_CONF  C_RCFG  C_WTHR  C_RSUR  \\\n",
      "0       1       1       1       1       2      34       2       1       1   \n",
      "1       1       1       1       1       2      34       2       1       1   \n",
      "\n",
      "   C_RALN  C_TRAF  V_YEAR  P_SEX  P_AGE  P_PSN  P_USER  P_ISEV  \n",
      "0       1       1       2      0     33      1       1       2  \n",
      "1       1       1       2      0     70      1       1       1  \n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "df = pd.read_csv(datafile, engine = 'python')\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df[df.columns].apply(lambda x: x.astype(str).str.contains('[^0-9]')).sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = df.astype('category').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows in the dataset: 3655334\n"
     ]
    }
   ],
   "source": [
    "totalRows = df_cat.index.size\n",
    "print(\"Number of Rows in the dataset: {}\".format(totalRows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['C_YEAR', 'C_MNTH', 'C_WDAY', 'C_HOUR', 'C_VEHS', 'C_CONF', 'C_RCFG',\n",
      "       'C_WTHR', 'C_RSUR', 'C_RALN', 'C_TRAF', 'V_YEAR', 'P_SEX', 'P_AGE',\n",
      "       'P_PSN', 'P_USER', 'P_ISEV'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_cat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-Hot-Encoding of categorical\n",
    "#TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Class Variable to Binary if multi class disabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570775\n",
      "2084559\n",
      "['1' '0']\n",
      "Size of dataframe for modeling: 3500000\n"
     ]
    }
   ],
   "source": [
    "## Convert Class Variable to Binary\n",
    "### Merge Injury and Fatality as a single class\n",
    "### we will compare the results.\n",
    "if multiclass:\n",
    "    #Undersample the majority for the 3 class evaluation\n",
    "    \n",
    "    df_class = df_cat.copy()\n",
    "    \n",
    "    # subset fatal class\n",
    "    is_fatal =  df_class['P_ISEV']==3\n",
    "    is_fatal_count = is_fatal.sum()\n",
    "    print(\"Number of Fatal: {}\".format(is_fatal_count))\n",
    "    df_class_fatal = df_class[is_fatal]\n",
    "    print(df_class_fatal.head(2))\n",
    "    \n",
    "    # subset injury class\n",
    "    is_injury =  df_class['P_ISEV']==2\n",
    "    is_injury_count = is_injury.sum()\n",
    "    print(\"Number of Injury: {}\".format(is_injury_count))\n",
    "    df_class_injury = df_class[is_injury]\n",
    "    print(df_class_injury.head(2))\n",
    "    \n",
    "    # subset non_injury class\n",
    "    is_safe =  df_class['P_ISEV']==1\n",
    "    is_safe_count = is_safe.sum()\n",
    "    print(\"Number of Non-Injury: {}\".format(is_safe_count))\n",
    "    df_class_safe = df_class[is_safe]\n",
    "    print(df_class_safe.head(2))\n",
    "    \n",
    "    # get the size of fatal datafram\n",
    "    min_size = df_class_fatal.index.size\n",
    "    print(\"Size of Fatal Subset: {}\".format(min_size))\n",
    "    \n",
    "    # get size of injury\n",
    "    print(\"Size of injury Subset: {}\".format(df_class_injury.index.size))\n",
    "    \n",
    "    # size of non-fatal\n",
    "    print(\"Size of non-fatal Subset: {}\".format(df_class_safe.index.size))\n",
    "    \n",
    "    # randomly sample n number of injury and no injury and append to fatal\n",
    "    df_class_injury_select = df_class_injury.sample(n=min_size)\n",
    "    print(\"Shape of injury sampled dataframe: {}\".format(df_class_injury_select.shape))\n",
    "    df_class_safe_select = df_class_safe.sample(n=min_size)\n",
    "    print(\"Shape of nom-injury sampled dataframe: {}\".format(df_class_safe_select.shape))\n",
    "    \n",
    "    #concat the three dataframes\n",
    "    df_underSample = pd.concat([df_class_fatal, df_class_injury_select, df_class_safe_select])\n",
    "    print(df_underSample.shape)\n",
    "    \n",
    "    #TBD\n",
    "    if sampleN < df_underSample.index.size:\n",
    "        df_sample = df_underSample.sample(n=sampleN)\n",
    "    else:\n",
    "        df_sample = df_underSample.sample(n=df_underSample.index.size)\n",
    "    \n",
    "    #perform the conversion in two steps to avoid any unwanted side effects\n",
    "    df_sample['P_ISEV'] = df_sample['P_ISEV'].map({1: 'safe', 2: 'injury', 3:'fatal'})\n",
    "    df_sample['P_ISEV'] = df_sample['P_ISEV'].map({'safe': '0', 'injury': '1', 'fatal':'2'})\n",
    "    print((df_sample['P_ISEV']=='0').sum())\n",
    "    print((df_sample['P_ISEV']=='1').sum())\n",
    "    print((df_sample['P_ISEV']=='2').sum())\n",
    "    print(df_sample['P_ISEV'].unique())\n",
    "else:\n",
    "    df_class = df_cat.copy()\n",
    "\n",
    "    #perform the conversion in two steps to avoid any unwanted side effects\n",
    "    df_class['P_ISEV'] = df_class['P_ISEV'].map({1: 'safe', 2: 'injury', 3:'fatal'})\n",
    "    df_class['P_ISEV'] = df_class['P_ISEV'].map({'safe': '0', 'injury': '1', 'fatal':'1'})\n",
    "    print((df_class['P_ISEV']=='0').sum())\n",
    "    print((df_class['P_ISEV']=='1').sum())\n",
    "    print(df_class['P_ISEV'].unique())\n",
    "    \n",
    "    df_sample = df_class.sample(n=sampleN)\n",
    "\n",
    "print(\"Size of dataframe for modeling: {}\".format(df_sample.index.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df_sample[df_sample.columns].apply(lambda x: x.astype(str).str.contains('[^0-9]')).sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3500000 entries, 2687805 to 2542334\n",
      "Data columns (total 17 columns):\n",
      "C_YEAR    category\n",
      "C_MNTH    category\n",
      "C_WDAY    category\n",
      "C_HOUR    category\n",
      "C_VEHS    category\n",
      "C_CONF    category\n",
      "C_RCFG    category\n",
      "C_WTHR    category\n",
      "C_RSUR    category\n",
      "C_RALN    category\n",
      "C_TRAF    category\n",
      "V_YEAR    category\n",
      "P_SEX     category\n",
      "P_AGE     int32\n",
      "P_PSN     category\n",
      "P_USER    category\n",
      "P_ISEV    int32\n",
      "dtypes: category(15), int32(2)\n",
      "memory usage: 103.5 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# convert to the correct type\n",
    "df_sample = df_sample.astype('category')\n",
    "df_sample['C_YEAR'] = df_sample['C_YEAR'].astype(CategoricalDtype(ordered=True))\n",
    "df_sample['C_MNTH'] = df_sample['C_MNTH'].astype(CategoricalDtype(ordered=True))\n",
    "df_sample['C_WDAY'] = df_sample['C_WDAY'].astype(CategoricalDtype(ordered=True))\n",
    "df_sample['C_HOUR'] = df_sample['C_HOUR'].astype(CategoricalDtype(ordered=True))\n",
    "df_sample['V_YEAR'] = df_sample['V_YEAR'].astype(CategoricalDtype(ordered=True))\n",
    "df_sample['P_AGE'] = df_sample['P_AGE'].astype('int')\n",
    "df_sample['P_ISEV'] = df_sample['P_ISEV'].astype('int')\n",
    "print(df_sample.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training and Testing for Binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split between data and class\n",
    "Y = df_sample[df_sample.columns[-1]]\n",
    "X = df_sample[df_sample.columns[0:df_sample.columns.size -1]]\n",
    "\n",
    "# split data into X and y\n",
    "#X = df_sample.iloc[:,0:16]\n",
    "#Y = df_sample.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "print(Y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C_YEAR C_MNTH C_WDAY C_HOUR C_VEHS C_CONF C_RCFG C_WTHR C_RSUR C_RALN  \\\n",
      "2687805     13      8      1      3      2     36      2      1      1      1   \n",
      "2739281     13     11      2      4      1      6      2      3      2      1   \n",
      "2624349     13      3      6      1      2     36      2      1      1      1   \n",
      "\n",
      "        C_TRAF V_YEAR P_SEX  P_AGE P_PSN P_USER  \n",
      "2687805      1      2     1     42     1      2  \n",
      "2739281      1      2     0     38     1      1  \n",
      "2624349      1      3     0     25     1      1  \n"
     ]
    }
   ],
   "source": [
    "print(X.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Test(70%) and Train (30%) for Bianry class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sprint into train and test 70/30\n",
    "#X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the final train and test data for future model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C_YEAR C_MNTH C_WDAY C_HOUR C_VEHS C_CONF C_RCFG C_WTHR C_RSUR C_RALN  \\\n",
      "617039       3      9      2      4      2     21      2      1      1      1   \n",
      "3277496     16     11      5      0      1      6      2      3      2      1   \n",
      "1429986      7      3      7      2      4     21      1      1      1      2   \n",
      "14031        1      1      6      4      2     22      1      4      3      1   \n",
      "1788391      8     11      5      1      2     35      2      1      1      2   \n",
      "3151005     16      2      4      1      2     33      1      4      3      3   \n",
      "1146192      5     12      2      2      2     36      2      1      1      2   \n",
      "1159432      5     12      7      2      2     31      1      4      3      1   \n",
      "3042484     15      7      5      3      2     21      1      1      1      2   \n",
      "779849       4      5      7      0      2     21      1      1      1      1   \n",
      "\n",
      "        C_TRAF V_YEAR P_SEX  P_AGE P_PSN P_USER  P_ISEV  \n",
      "617039       1      3     1     27     1      1       1  \n",
      "3277496      2      3     1     27     1      1       0  \n",
      "1429986      7      3     0     27     2      2       1  \n",
      "14031        7      2     1     28     1      1       0  \n",
      "1788391      2      2     0     27     1      1       1  \n",
      "3151005      7      3     0     49     1      1       1  \n",
      "1146192      1      2     0     29     1      1       1  \n",
      "1159432      7      3     0     21     1      1       1  \n",
      "3042484      7      3     0      4     2      2       1  \n",
      "779849       7      2     1     37     1      1       1  \n",
      "        C_YEAR C_MNTH C_WDAY C_HOUR C_VEHS C_CONF C_RCFG C_WTHR C_RSUR C_RALN  \\\n",
      "679817       3     12      3      1      2     21      2      1      1      1   \n",
      "2964341     15      2      1      3      1      2      1      3      3      2   \n",
      "2184210     10     11      5      1      2     21      1      1      2      1   \n",
      "3090580     15     10      4      2      2     36      2      1      1      1   \n",
      "1398330      7      1      7      1      1      3      1      1      4      1   \n",
      "497581       3      2      7      3      2     35      2      1      1      1   \n",
      "3068367     15      9      1      3      2     24      2      2      2      1   \n",
      "555546       3      6      3      4      1      6      2      1      1      1   \n",
      "485855       3      2      3      2      2     36      2      4      2      1   \n",
      "1760023      8     10      1      2      2     21      1      1      1      1   \n",
      "\n",
      "        C_TRAF V_YEAR P_SEX  P_AGE P_PSN P_USER  P_ISEV  \n",
      "679817       1      3     1     39     1      1       1  \n",
      "2964341      7      3     0     37     1      1       1  \n",
      "2184210      7      3     1     30     1      1       1  \n",
      "3090580      1      3     0     66     1      1       1  \n",
      "1398330      7      2     0     42     1      2       1  \n",
      "497581       1      2     0     34     1      1       1  \n",
      "3068367      1      3     1     55     1      1       1  \n",
      "555546       7      1     1     29     1      1       0  \n",
      "485855       1      3     0     38     1      1       1  \n",
      "1760023      7      3     1     32     1      1       0  \n"
     ]
    }
   ],
   "source": [
    "FullTrain = X_train.copy()\n",
    "FullTrain['P_ISEV'] = Y_train.copy()\n",
    "FullTrain.to_csv(file_final_train, encoding='utf-8', index=False)\n",
    "print(FullTrain.head(10))\n",
    "\n",
    "FullTest = X_test.copy()\n",
    "FullTest['P_ISEV'] = Y_test.copy()\n",
    "FullTest.to_csv(file_final_test, encoding='utf-8', index=False)\n",
    "print(FullTest.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering based on K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Dec  1 02:57:17 2018\n",
      "K-Means Clustering: Start\n",
      "KMeans(algorithm='auto', copy_x=True, init='random', max_iter=1000,\n",
      "    n_clusters=3, n_init=10, n_jobs=None, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=3)\n",
      "K-Means Clustering: Build\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 660871183.6981761\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 576012641.6652817\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 570340124.3896588\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 564987630.1290531\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 559653648.2239835\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 557995855.3770834\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 557395407.562223\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 557223723.7739966\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 557153338.3928941\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 557126635.1973974\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 557116764.7680193\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 557111917.3444437\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 557110162.46112\n",
      "center shift 3.966737e-02 within tolerance 3.278924e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 653872282.6083698\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 574306247.280209\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 563745552.4638364\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 562597261.1291237\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 562462920.3955464\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 562423906.9807756\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 562404834.0104344\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 562390948.848603\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 562379971.4020367\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 562372783.7697493\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 562370115.010475\n",
      "center shift 5.213001e-02 within tolerance 3.278924e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 684823021.1692654\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 590117705.1671572\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 577112047.3620795\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 573128641.297277\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 570608424.1805153\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 568805124.1806862\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 567350292.6891685\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 566344279.2443012\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 565436797.2554501\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 564860875.0635058\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 564557148.9618655\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 564386186.8442883\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 564313454.3516977\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 564252922.590307\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 564150241.3153917\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 564008939.9565076\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 563924634.8927361\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 563905499.1021085\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 563900090.5253328\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 19, inertia 563897117.3980583\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 20, inertia 563895290.3699236\n",
      "center shift 5.026025e-02 within tolerance 3.278924e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 719430871.4133325\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 606446947.5966098\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 574580047.9743748\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 570497768.7271018\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 568502324.6456722\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 567237529.7977759\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 566223948.9845135\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 565316679.2400018\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 564809771.340794\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 564519425.6226046\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 564371853.4491727\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 564305270.7483296\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 564242741.3417894\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 564134135.3735728\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 563987375.8285786\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 563919614.8790243\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 563904386.5815283\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 563899427.0311807\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 563896716.0529897\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 19, inertia 563894998.4644349\n",
      "center shift 4.921415e-02 within tolerance 3.278924e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 650907981.6099458\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 625491015.9064085\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 608977311.603178\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 593032803.5431478\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 582224604.3241677\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 575078438.6811029\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 568024728.9603792\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 560235528.5038892\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 557835553.3380833\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 557371043.8466206\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 557181871.6441263\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 557148355.0223464\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 557146949.4956298\n",
      "center shift 2.744417e-02 within tolerance 3.278924e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 673711243.912807\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 603753797.5083432\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 568141861.1978847\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 564072023.5505575\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 563001908.300324\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 562329309.0308313\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 561096149.0532225\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 559720683.7254623\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 558486860.9361042\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 557802907.7616082\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 557389383.7136992\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 557188745.0126746\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, inertia 557148805.0122266\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 557147223.1871184\n",
      "center shift 3.729982e-02 within tolerance 3.278924e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 627885115.6519587\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 568959453.3149986\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 564098481.6821291\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 562840439.5990058\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 562513840.642583\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 562461211.2686478\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 562429651.2111588\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 562409176.2886137\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 562394362.8847816\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 562382481.8987883\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 562374175.2768724\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 562370475.4891812\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 562369559.9396939\n",
      "center shift 3.191933e-02 within tolerance 3.278924e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 625002855.1418363\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 602988107.9319763\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 591327305.827091\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 582062323.735072\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 575576795.8735051\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 571327735.0586888\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 568621232.2843783\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 566660543.9093734\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 565823786.9917909\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 565140289.82207\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 564620136.77581\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 564426397.1451434\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 564349924.7673603\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 564288114.2290856\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 564224100.1215096\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 564102636.0540769\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 563951678.4977654\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 563913236.6782212\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 563902448.7177001\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 19, inertia 563898449.4879624\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 20, inertia 563896060.3584985\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 21, inertia 563894611.7328367\n",
      "center shift 4.479813e-02 within tolerance 3.278924e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 614507653.2500759\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 603516040.6364442\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 596371841.5710696\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 587022015.6823026\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 580678341.700447\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 575262547.0341618\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 566255224.759864\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 561121627.3590724\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 558992749.316933\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 557951561.2684058\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 557490617.8140972\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 557322112.5123999\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 557172073.6039515\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 557131768.1267586\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 557118851.3306977\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 557113007.0813564\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 557110416.3185006\n",
      "center shift 5.065515e-02 within tolerance 3.278924e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 706513126.8928431\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 650742754.9241134\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 605598530.4237353\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 589210309.8372134\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 580673417.3026284\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 573872648.2552413\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 569011270.0642382\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 566385508.0576533\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 564923884.5213246\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 564444103.6623482\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 564196200.6357962\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 564063274.2545266\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 563994587.8724649\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 563954354.6928295\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 563926499.1484972\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 563904210.3176484\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 563894183.5645549\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 563892053.3811917\n",
      "center shift 4.363306e-02 within tolerance 3.278924e-03\n",
      "[[ 8.7115983   6.72886511  4.11176535  2.2012936   1.68940555 11.66714396\n",
      "   1.44285448  1.6822767   1.64606185  1.51337806  5.60142852  2.4935871\n",
      "   0.55944328 30.80875104  1.11649089  1.32747116]\n",
      " [ 8.66553409  6.68617268  4.07680739  2.44486602  2.23490768 29.500077\n",
      "   1.81015274  1.55081666  1.44879453  1.26912185  3.89990553  2.46212655\n",
      "   0.52496846 21.21695254  1.24489332  1.47664575]\n",
      " [ 9.40446212  6.72147023  3.90995602  2.30268433  2.16438686 26.20980739\n",
      "   1.75391363  1.53870374  1.4515336   1.29272638  4.09858602  2.58425599\n",
      "   0.53581854 56.72848622  1.05221738  1.25032616]]\n",
      "[1 0 0 ... 0 0 2]\n",
      "K-Means Clustering: End\n",
      "Sat Dec  1 02:59:35 2018\n"
     ]
    }
   ],
   "source": [
    "if enable_kmean:\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print(\"K-Means Clustering: Start\")\n",
    "    kmeans = KMeans(n_clusters=3, init='random', n_init=10, tol=1e-04, verbose= verbose_level, max_iter=1000)\n",
    "    print(kmeans)\n",
    "    \n",
    "    print(\"K-Means Clustering: Build\")\n",
    "    ykm = kmeans.fit(X_train)\n",
    "    \n",
    "    if pyscript:\n",
    "        print(ykm.cluster_centers_)\n",
    "        print(ykm.labels_)\n",
    "    else:\n",
    "        display(ykm.cluster_centers_)\n",
    "        display(ykm.labels_)\n",
    "    \n",
    "    # save model to file\n",
    "    pickle.dump(ykm, open(file_kmean, \"wb\"))\n",
    "    \n",
    "    print(\"K-Means Clustering: End\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM GridSearch for Optimal Parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This operation is computationaly expensive.\n",
    "if enable_grid_search:\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    param_grid = {'C':[0.1, 1, 10, 100, 1000], 'gamma':[1, 0.1, 0.01, 0.001, 0.0001]}\n",
    "    grid = GridSearchCV(SVC(), param_grid, verbose=verbose_level)\n",
    "    print(grid)\n",
    "    grid.fit(X_train, Y_train)\n",
    "    print(grid.best_params_)\n",
    "    svm_c = grid.best_params_.get('C')\n",
    "    svm_gamma = grid.best_params_.get('gamma')\n",
    "    print(grid.best_estimator_)\n",
    "    grid_predictions = grid.predict(X_test)\n",
    "    cfn_matrix_grid = confusion_matrix(Y_test, grid_predictions)\n",
    "    print(cfn_matrix_grid)\n",
    "    print(classification_report(Y_test,grid_predictions))\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Start\n",
      "Sat Dec  1 02:59:35 2018\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='auto',\n",
      "          n_jobs=10, penalty='l2', random_state=0, solver='saga',\n",
      "          tol=0.0001, verbose=3, warm_start=False)\n",
      "Logistic Regression: Fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 13 epochs took 20 seconds\n",
      "Logistic Regression: Predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   20.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on train set: 0.62\n",
      "Accuracy of logistic regression classifier on test set: 0.62\n",
      "Logistic Regression: Intercept\n",
      "[1.68091606]\n",
      "Logistic Regression: Coefficients\n",
      "[[ 0.00436564  0.00073385 -0.00414846 -0.071603   -0.43396847  0.00112751\n",
      "  -0.12727912 -0.01778397  0.1304307   0.15589815  0.04017879 -0.1227636\n",
      "  -0.6848408   0.0059682  -0.51629328  0.25351272]]\n",
      "Logistic Regression: Confusion Matrix\n",
      "[[195411 256055]\n",
      " [140429 458105]]\n",
      "Logistic Regression: Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.43      0.50    451466\n",
      "           1       0.64      0.77      0.70    598534\n",
      "\n",
      "   micro avg       0.62      0.62      0.62   1050000\n",
      "   macro avg       0.61      0.60      0.60   1050000\n",
      "weighted avg       0.62      0.62      0.61   1050000\n",
      "\n",
      "Sat Dec  1 03:00:02 2018\n",
      "Logistic Regression: End\n"
     ]
    }
   ],
   "source": [
    "if enable_lr:\n",
    "    print(\"Logistic Regression: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    lr = LogisticRegression(C=1, random_state=0, solver='saga', multi_class='auto', \n",
    "                            verbose=verbose_level, n_jobs=10, max_iter=1000)\n",
    "    print(lr)\n",
    "    print(\"Logistic Regression: Fit\")\n",
    "    lr.fit(X_train, Y_train)\n",
    "    \n",
    "    # save model to file\n",
    "    pickle.dump(lr, open(file_lr, \"wb\"))\n",
    "    \n",
    "    \n",
    "if predict_lr:\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_lr, \"rb\"))\n",
    "    print(\"Logistic Regression: Predict\")\n",
    "    y_pred = lr.predict(X_test)\n",
    "\n",
    "    print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(lr.score(X_train, Y_train)))\n",
    "    print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(lr.score(X_test, Y_test)))\n",
    "\n",
    "    # print the intercept (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "    print(\"Logistic Regression: Intercept\")\n",
    "    print(lr.intercept_)\n",
    "\n",
    "    # print the coeficients (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "    print(\"Logistic Regression: Coefficients\")\n",
    "    print(lr.coef_)\n",
    "\n",
    "    print(\"Logistic Regression: Confusion Matrix\")\n",
    "    cnf_matrix_lg = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_lg)\n",
    "    \n",
    "    print(\"Logistic Regression: Classification Report\")\n",
    "    print(classification_report(Y_test, y_pred))\n",
    "\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"Logistic Regression: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with L1 Regularization: Start\n",
      "Sat Dec  1 03:00:02 2018\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='auto',\n",
      "          n_jobs=10, penalty='l1', random_state=None, solver='saga',\n",
      "          tol=0.0001, verbose=3, warm_start=False)\n",
      "Logistic Regression with L1 Regularization: Fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 15 epochs took 26 seconds\n",
      "Logistic Regression with L1 Regularization: Predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   26.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on train set: 0.62\n",
      "Accuracy of logistic regression classifier on test set: 0.62\n",
      "Logistic Regression with L1 Regularization: Confusion Matrix\n",
      "[[195176 256290]\n",
      " [140236 458298]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.43      0.50    451466\n",
      "           1       0.64      0.77      0.70    598534\n",
      "\n",
      "   micro avg       0.62      0.62      0.62   1050000\n",
      "   macro avg       0.61      0.60      0.60   1050000\n",
      "weighted avg       0.62      0.62      0.61   1050000\n",
      "\n",
      "Logistic Regression with L1 Regularization: Classification Report\n",
      "Sat Dec  1 03:00:34 2018\n",
      "Logistic Regression with L1 Regularization: End\n"
     ]
    }
   ],
   "source": [
    "if (enable_lr_l1):\n",
    "    # with L1 regularization\n",
    "    print(\"Logistic Regression with L1 Regularization: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    lr = LogisticRegression(penalty='l1', C=1, solver='saga', multi_class='auto', \n",
    "                            verbose=verbose_level, n_jobs = 10, max_iter=1000)\n",
    "    print(lr)\n",
    "    print(\"Logistic Regression with L1 Regularization: Fit\")\n",
    "    lr.fit(X_train, Y_train)\n",
    "    \n",
    "    # save model to file\n",
    "    pickle.dump(lr, open(file_lr_l1, \"wb\"))\n",
    "\n",
    "if (predict_lr_l1):\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_lr_l1, \"rb\"))\n",
    "    print(\"Logistic Regression with L1 Regularization: Predict\")\n",
    "    y_pred = lr.predict(X_test)\n",
    "    \n",
    "    print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(lr.score(X_train, Y_train)))\n",
    "    print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(lr.score(X_test, Y_test)))\n",
    "\n",
    "    print(\"Logistic Regression with L1 Regularization: Confusion Matrix\")\n",
    "    cnf_matrix_lg_l1 = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_lg_l1)\n",
    "    \n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    print(\"Logistic Regression with L1 Regularization: Classification Report\")\n",
    "\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"Logistic Regression with L1 Regularization: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes: Start\n",
      "Sat Dec  1 03:00:35 2018\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "Naive Bayes: Fit\n",
      "Naive Bayes: Predict\n",
      "Accuracy of Naive Bayes classifier on train set: 0.59\n",
      "Accuracy of Naove Nayes classifier on test set: 0.59\n",
      "Naive Bayes: Confusion Matrix\n",
      "[[280528 170938]\n",
      " [257559 340975]]\n",
      "Naive Bayes: Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.62      0.57    451466\n",
      "           1       0.67      0.57      0.61    598534\n",
      "\n",
      "   micro avg       0.59      0.59      0.59   1050000\n",
      "   macro avg       0.59      0.60      0.59   1050000\n",
      "weighted avg       0.60      0.59      0.59   1050000\n",
      "\n",
      "Sat Dec  1 03:00:43 2018\n",
      "Naive Bayes: End\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes Classification\n",
    "if enable_nbayes:\n",
    "    print(\"Naive Bayes: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    nbayes = GaussianNB()\n",
    "    print(nbayes)\n",
    "    print(\"Naive Bayes: Fit\")\n",
    "    nbayes.fit(X_train, Y_train)\n",
    "    # save model to file\n",
    "    pickle.dump(nbayes, open(file_nbayes, \"wb\"))\n",
    "\n",
    "if predict_nbayes:\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_nbayes, \"rb\"))\n",
    "    print(\"Naive Bayes: Predict\")\n",
    "    y_pred = nbayes.predict(X_test)\n",
    "    print('Accuracy of Naive Bayes classifier on train set: {:.2f}'.format(nbayes.score(X_train, Y_train)))\n",
    "    print('Accuracy of Naove Nayes classifier on test set: {:.2f}'.format(nbayes.score(X_test, Y_test)))\n",
    "    \n",
    "    cnf_matrix_dt = confusion_matrix(Y_test, y_pred)\n",
    "    print(\"Naive Bayes: Confusion Matrix\")\n",
    "    print(cnf_matrix_dt)\n",
    "    print(\"Naive Bayes: Classification Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    print(\"Naive Bayes: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: Start\n",
      "Sat Dec  1 03:00:43 2018\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=50,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "Decision Tree: Fit\n",
      "Decision Tree: Predict\n",
      "Accuracy of Decision Tree classifier on train set: 1.00\n",
      "Accuracy of Decision Tree classifier on test set: 0.59\n",
      "Decision Tree: Confusion Matrix\n",
      "[[237492 213974]\n",
      " [221283 377251]]\n",
      "Decision Tree: Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.53      0.52    451466\n",
      "           1       0.64      0.63      0.63    598534\n",
      "\n",
      "   micro avg       0.59      0.59      0.59   1050000\n",
      "   macro avg       0.58      0.58      0.58   1050000\n",
      "weighted avg       0.59      0.59      0.59   1050000\n",
      "\n",
      "Sat Dec  1 03:01:25 2018\n",
      "Decision Tree: End\n"
     ]
    }
   ],
   "source": [
    "if enable_dt:\n",
    "    print(\"Decision Tree: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    tree = DecisionTreeClassifier(criterion='entropy',max_depth=50)\n",
    "    print(tree)\n",
    "    print(\"Decision Tree: Fit\")\n",
    "    tree.fit(X_train, Y_train)\n",
    "    # save model to file\n",
    "    pickle.dump(tree, open(file_dt, \"wb\"))\n",
    "\n",
    "if predict_dt:\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_dt, \"rb\"))\n",
    "    print(\"Decision Tree: Predict\")\n",
    "    y_pred = tree.predict(X_test)\n",
    "    print('Accuracy of Decision Tree classifier on train set: {:.2f}'.format(tree.score(X_train, Y_train)))\n",
    "    print('Accuracy of Decision Tree classifier on test set: {:.2f}'.format(tree.score(X_test, Y_test)))\n",
    "    \n",
    "    cnf_matrix_dt = confusion_matrix(Y_test, y_pred)\n",
    "    print(\"Decision Tree: Confusion Matrix\")\n",
    "    print(cnf_matrix_dt)\n",
    "    print(\"Decision Tree: Classification Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    print(\"Decision Tree: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-N-N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: Start\n",
      "Sat Dec  1 03:01:25 2018\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=10, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNN: Fit\n",
      "KNN: Predict\n",
      "Accuracy of KNN classifier on train set: 0.74\n",
      "Accuracy of KNN classifier on test set: 0.60\n",
      "KNN: Confusion Matrix\n",
      "[[228725 222741]\n",
      " [197477 401057]]\n",
      "KNN: Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.51      0.52    451466\n",
      "           1       0.64      0.67      0.66    598534\n",
      "\n",
      "   micro avg       0.60      0.60      0.60   1050000\n",
      "   macro avg       0.59      0.59      0.59   1050000\n",
      "weighted avg       0.60      0.60      0.60   1050000\n",
      "\n",
      "Sat Dec  1 03:34:37 2018\n",
      "KNN: End\n"
     ]
    }
   ],
   "source": [
    "if enable_knn:\n",
    "    print(\"KNN: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    knn = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski', n_jobs = 10)\n",
    "    print(knn)\n",
    "    print(\"KNN: Fit\")\n",
    "    knn.fit(X_train, Y_train)\n",
    "\n",
    "    # save model to file\n",
    "    pickle.dump(knn, open(file_knn, \"wb\"))\n",
    "\n",
    "if predict_knn:\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_knn, \"rb\"))\n",
    "    \n",
    "    print(\"KNN: Predict\")\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print('Accuracy of KNN classifier on train set: {:.2f}'.format(knn.score(X_train, Y_train)))\n",
    "    print('Accuracy of KNN classifier on test set: {:.2f}'.format(knn.score(X_test, Y_test)))\n",
    "    \n",
    "    print(\"KNN: Confusion Matrix\")\n",
    "    cnf_matrix_knn = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_knn)\n",
    "\n",
    "    print(\"KNN: Classification Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "\n",
    "    print(\"KNN: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN - Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Preceptron: Start\n",
      "Sat Dec  1 03:34:37 2018\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(25, 25, 25), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=3, warm_start=False)\n",
      "Multilayer Preceptron: fit\n",
      "Iteration 1, loss = 0.63178562\n",
      "Iteration 2, loss = 0.62142621\n",
      "Iteration 3, loss = 0.61737828\n",
      "Iteration 4, loss = 0.61530847\n",
      "Iteration 5, loss = 0.61405752\n",
      "Iteration 6, loss = 0.61340958\n",
      "Iteration 7, loss = 0.61283719\n",
      "Iteration 8, loss = 0.61227489\n",
      "Iteration 9, loss = 0.61186819\n",
      "Iteration 10, loss = 0.61149607\n",
      "Iteration 11, loss = 0.61119114\n",
      "Iteration 12, loss = 0.61093501\n",
      "Iteration 13, loss = 0.61067899\n",
      "Iteration 14, loss = 0.61051348\n",
      "Iteration 15, loss = 0.61046796\n",
      "Iteration 16, loss = 0.61029392\n",
      "Iteration 17, loss = 0.61018146\n",
      "Iteration 18, loss = 0.61011412\n",
      "Iteration 19, loss = 0.61000592\n",
      "Iteration 20, loss = 0.60987566\n",
      "Iteration 21, loss = 0.60982884\n",
      "Iteration 22, loss = 0.60972880\n",
      "Iteration 23, loss = 0.60962103\n",
      "Iteration 24, loss = 0.60952009\n",
      "Iteration 25, loss = 0.60944458\n",
      "Iteration 26, loss = 0.60940630\n",
      "Iteration 27, loss = 0.60929518\n",
      "Iteration 28, loss = 0.60925230\n",
      "Iteration 29, loss = 0.60914847\n",
      "Iteration 30, loss = 0.60906115\n",
      "Iteration 31, loss = 0.60890642\n",
      "Iteration 32, loss = 0.60889175\n",
      "Iteration 33, loss = 0.60880279\n",
      "Iteration 34, loss = 0.60870076\n",
      "Iteration 35, loss = 0.60874772\n",
      "Iteration 36, loss = 0.60864913\n",
      "Iteration 37, loss = 0.60861713\n",
      "Iteration 38, loss = 0.60854728\n",
      "Iteration 39, loss = 0.60849023\n",
      "Iteration 40, loss = 0.60843538\n",
      "Iteration 41, loss = 0.60839858\n",
      "Iteration 42, loss = 0.60840033\n",
      "Iteration 43, loss = 0.60839356\n",
      "Iteration 44, loss = 0.60836913\n",
      "Iteration 45, loss = 0.60827963\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Multilayer Preceptron: Predict\n",
      "Accuracy of Multilayer Perceptron classifier on train set: 0.66\n",
      "Accuracy of Multilayer Perceptron classifier on test set: 0.66\n",
      "Multilayer Preceptron: Confusion Matrix\n",
      "[[267057 184409]\n",
      " [177723 420811]]\n",
      "Multilayer Preceptron: Classificiation Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.59      0.60    451466\n",
      "           1       0.70      0.70      0.70    598534\n",
      "\n",
      "   micro avg       0.66      0.66      0.66   1050000\n",
      "   macro avg       0.65      0.65      0.65   1050000\n",
      "weighted avg       0.65      0.66      0.65   1050000\n",
      "\n",
      "Sat Dec  1 03:43:15 2018\n",
      "Multilayer Preceptron: End\n"
     ]
    }
   ],
   "source": [
    "if enable_mlp:\n",
    "    print(\"Multilayer Preceptron: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    \n",
    "    #mlpc = MLPClassifier(alpha=1)\n",
    "    #mlpc = MLPClassifier(hidden_layer_sizes=(12, 12, 12), max_iter=100, verbose=verbose_level)\n",
    "    mlpc = MLPClassifier(hidden_layer_sizes=(25, 25, 25), verbose=verbose_level, max_iter=1000)\n",
    "    print(mlpc)\n",
    "    #mlp = multilayer_perceptron(n_hidden =2, activation='logistic', algorithm='sgd', random_state=3)\n",
    "    print(\"Multilayer Preceptron: fit\")\n",
    "    mlpc.fit(X_train, Y_train)\n",
    "    \n",
    "    # save model to file\n",
    "    pickle.dump(mlpc, open(file_mlp, \"wb\"))\n",
    "    \n",
    "if predict_mlp:\n",
    "    \n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_mlp, \"rb\"))\n",
    "    print(\"Multilayer Preceptron: Predict\")\n",
    "    y_pred = mlpc.predict(X_test)\n",
    "\n",
    "    print('Accuracy of Multilayer Perceptron classifier on train set: {:.2f}'.format(mlpc.score(X_train, Y_train)))\n",
    "    print('Accuracy of Multilayer Perceptron classifier on test set: {:.2f}'.format(mlpc.score(X_test, Y_test)))\n",
    "    \n",
    "    print(\"Multilayer Preceptron: Confusion Matrix\")\n",
    "    cnf_matrix_mlp = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_mlp)\n",
    "    \n",
    "    print(\"Multilayer Preceptron: Classificiation Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "    print(\"Multilayer Preceptron: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: Start\n",
      "Sat Dec  1 03:43:15 2018\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=1000, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=3)\n",
      "SVM: Fit\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:244: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: Predict\n",
      "Accuracy of SVM classifier on train set: 0.43\n",
      "Accuracy of SVM classifier on test set: 0.43\n",
      "SVM: Confusion Matrix\n",
      "[[442180   9286]\n",
      " [585958  12576]]\n",
      "SVM: Classfication Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.98      0.60    451466\n",
      "           1       0.58      0.02      0.04    598534\n",
      "\n",
      "   micro avg       0.43      0.43      0.43   1050000\n",
      "   macro avg       0.50      0.50      0.32   1050000\n",
      "weighted avg       0.51      0.43      0.28   1050000\n",
      "\n",
      "Sat Dec  1 03:49:29 2018\n",
      "SVM: End\n"
     ]
    }
   ],
   "source": [
    "if enable_svm:\n",
    "    print(\"SVM: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    #svm = SVC(C=1, random_state=0, kernel='sigmoid', verbose=True)\n",
    "    #svm = SVC(C=1, random_state=0, kernel='linear', verbose=True, cache_size=200)\n",
    "    #svm = SVC(C=svm_c, gamma=svm_gamma, verbose = verbose_level)\n",
    "    #SVN prediction is taking for ever, limiting the max_iter to 100 instead of -1 (no limit)\n",
    "    svm = SVC(C=1, gamma = 'auto', verbose = verbose_level, max_iter=1000)\n",
    "    print(svm)\n",
    "    print(\"SVM: Fit\")\n",
    "    svm.fit(X_train, Y_train)\n",
    "\n",
    "    # save model to file\n",
    "    pickle.dump(svm, open(file_svm, \"wb\"))\n",
    "    \n",
    "if predict_svm:\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_svm, \"rb\"))\n",
    "    print(\"SVM: Predict\")\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    print('Accuracy of SVM classifier on train set: {:.2f}'.format(svm.score(X_train, Y_train)))\n",
    "    print('Accuracy of SVM classifier on test set: {:.2f}'.format(svm.score(X_test, Y_test)))\n",
    "    \n",
    "    print(\"SVM: Confusion Matrix\")\n",
    "    cnf_matrix_svm = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_svm)\n",
    "    \n",
    "    print(\"SVM: Classfication Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "    print(\"SVM: End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Dec  1 03:49:29 2018\n"
     ]
    }
   ],
   "source": [
    "t_end =  time.time()\n",
    "print(time.asctime( time.localtime(t_end) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
