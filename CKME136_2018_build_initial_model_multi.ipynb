{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#in case we need to repeat experiment\n",
    "#np.random.seed(255)\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 22\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('classic')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "#sklearn imports\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import model_selection\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import pickle # allows for model to be saved/load to file\n",
    "\n",
    "\n",
    "#Use print instead of display when run as python script\n",
    "pyscript = True\n",
    "\n",
    "#Classifier verborsity where supported\n",
    "verbose_level=3\n",
    "\n",
    "#Sample Size (5963272)\n",
    "#sampleN = 3000000\n",
    "#SampleN = 5963000\n",
    "sampleN = 3500000\n",
    "\n",
    "import time\n",
    "\n",
    "#datafile\n",
    "#datafile = 'NCDB_FULL_Removed_All_Missing_Values_Multi_Class.csv'\n",
    "datafile = 'NCDB_FULL_Removed_All_Missing_Values_Binary_Class_Transformed.csv'\n",
    "\n",
    "#Model Store\n",
    "file_lr = 'lr_nov_30.model'\n",
    "file_lr_l1 = 'lr_l1_nov_30.model'\n",
    "file_dt = 'dt_nov_30.model'\n",
    "file_svm = 'svm_nov_30.model'\n",
    "file_knn = 'knn_nov_30.model'\n",
    "file_mlp = 'mlp_nov_30.model'\n",
    "file_kmean = 'kmean_nov_30.model'\n",
    "\n",
    "#Enable Optimization Algorithms\n",
    "enable_grid_search = False\n",
    "svm_c = 1\n",
    "svm_gamma = 1\n",
    "feature_all = True\n",
    "defaultFeatures = ['P_AGE', 'V_YEAR', 'C_HOUR', 'C_YEAR', 'C_MNTH', 'C_CONF', 'C_WDAY', 'C_VEHS', 'P_USER', 'P_SEX']\n",
    "\n",
    "enable_lr_l1 = True\n",
    "predict_lr_l1 = True\n",
    "\n",
    "# Enable Algorithms\n",
    "enable_lr = True\n",
    "enable_dt = True\n",
    "enable_svm = True\n",
    "enable_knn = True\n",
    "enable_mlp = True\n",
    "enable_kmean = True\n",
    "\n",
    "predict_lr = True\n",
    "predict_dt = True\n",
    "predict_svm = True\n",
    "predict_knn = True\n",
    "predict_mlp = True\n",
    "\n",
    "\n",
    "#Multiclass classification, binary if falase\n",
    "multiclass = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 3500000\n",
      "Multi-Class Classification: Disabled\n",
      "Grid Search: Disabled\n",
      "All Features: Enabled\n",
      "K-means: Disabled\n",
      "Logistic Regression: Enabled\n",
      "Decision Tree: Enabled\n",
      "Support Vector Machines: Enabled\n",
      "KNN: Enabled\n",
      "MLP: Enabled\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample size: {}\".format(sampleN))\n",
    "\n",
    "if multiclass:\n",
    "    print(\"Multi-Class Classification: Enabled\")\n",
    "else:\n",
    "    print(\"Multi-Class Classification: Disabled\")\n",
    "\n",
    "if enable_grid_search:\n",
    "    print(\"Grid Search: Enabled\")\n",
    "else:\n",
    "    print(\"Grid Search: Disabled\")\n",
    "\n",
    "if feature_all:\n",
    "    print(\"All Features: Enabled\")\n",
    "else:\n",
    "    print(\"All Features: Disabled\")\n",
    "    \n",
    "if enable_kmeans:\n",
    "    print(\"K-means: Enabled\")\n",
    "else:\n",
    "    print(\"K-means: Disabled\")\n",
    "\n",
    "if enable_lr_l1:\n",
    "    print(\"Logistic Regression: Enabled\")\n",
    "else:\n",
    "    print(\"Logistic Regression: Disabled\")\n",
    "    \n",
    "if enable_dt:\n",
    "    print(\"Decision Tree: Enabled\")\n",
    "else:\n",
    "    print(\"Decision Tree: Disabled\")\n",
    "    \n",
    "if enable_svm:\n",
    "    print(\"Support Vector Machines: Enabled\")\n",
    "else:\n",
    "    print(\"Support Vector Machines: Disabled\")\n",
    "\n",
    "if  enable_knn:\n",
    "    print(\"KNN: Enabled\")\n",
    "else:\n",
    "    print(\"KNN: Disabled\")\n",
    "    \n",
    "if enable_mlp:\n",
    "    print(\"MLP: Enabled\")\n",
    "else:\n",
    "    print(\"MLP: Disabled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 30 21:35:17 2018\n"
     ]
    }
   ],
   "source": [
    "t_start =  time.time()\n",
    "print(time.asctime( time.localtime(t_start) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C_YEAR  C_MNTH  C_WDAY  C_HOUR  C_VEHS  C_CONF  C_RCFG  C_WTHR  C_RSUR  \\\n",
      "0       1       1       1       1       2      34       2       1       1   \n",
      "1       1       1       1       1       2      34       2       1       1   \n",
      "\n",
      "   C_RALN  C_TRAF  V_YEAR  P_SEX  P_AGE  P_PSN  P_USER  P_ISEV  \n",
      "0       1       1       2      0     33      1       1       2  \n",
      "1       1       1       2      0     70      1       1       1  \n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "df = pd.read_csv(datafile, engine = 'python')\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df[df.columns].apply(lambda x: x.astype(str).str.contains('[^0-9]')).sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = df.astype('category').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows in the dataset: 3655334\n"
     ]
    }
   ],
   "source": [
    "totalRows = df_cat.index.size\n",
    "print(\"Number of Rows in the dataset: {}\".format(totalRows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['C_YEAR', 'C_MNTH', 'C_WDAY', 'C_HOUR', 'C_VEHS', 'C_CONF', 'C_RCFG',\n",
      "       'C_WTHR', 'C_RSUR', 'C_RALN', 'C_TRAF', 'V_YEAR', 'P_SEX', 'P_AGE',\n",
      "       'P_PSN', 'P_USER', 'P_ISEV'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_cat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-Hot-Encoding of categorical\n",
    "#TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Class Variable to Binary if multi class disabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570775\n",
      "2084559\n",
      "['1' '0']\n",
      "Size of dataframe for modeling: 3500000\n"
     ]
    }
   ],
   "source": [
    "## Convert Class Variable to Binary\n",
    "### Merge Injury and Fatality as a single class\n",
    "### we will compare the results.\n",
    "if multiclass:\n",
    "    #Undersample the majority for the 3 class evaluation\n",
    "    \n",
    "    df_class = df_cat.copy()\n",
    "    \n",
    "    # subset fatal class\n",
    "    is_fatal =  df_class['P_ISEV']==3\n",
    "    is_fatal_count = is_fatal.sum()\n",
    "    print(\"Number of Fatal: {}\".format(is_fatal_count))\n",
    "    df_class_fatal = df_class[is_fatal]\n",
    "    print(df_class_fatal.head(2))\n",
    "    \n",
    "    # subset injury class\n",
    "    is_injury =  df_class['P_ISEV']==2\n",
    "    is_injury_count = is_injury.sum()\n",
    "    print(\"Number of Injury: {}\".format(is_injury_count))\n",
    "    df_class_injury = df_class[is_injury]\n",
    "    print(df_class_injury.head(2))\n",
    "    \n",
    "    # subset non_injury class\n",
    "    is_safe =  df_class['P_ISEV']==1\n",
    "    is_safe_count = is_safe.sum()\n",
    "    print(\"Number of Non-Injury: {}\".format(is_safe_count))\n",
    "    df_class_safe = df_class[is_safe]\n",
    "    print(df_class_safe.head(2))\n",
    "    \n",
    "    # get the size of fatal datafram\n",
    "    min_size = df_class_fatal.index.size\n",
    "    print(\"Size of Fatal Subset: {}\".format(min_size))\n",
    "    \n",
    "    # get size of injury\n",
    "    print(\"Size of injury Subset: {}\".format(df_class_injury.index.size))\n",
    "    \n",
    "    # size of non-fatal\n",
    "    print(\"Size of non-fatal Subset: {}\".format(df_class_safe.index.size))\n",
    "    \n",
    "    # randomly sample n number of injury and no injury and append to fatal\n",
    "    df_class_injury_select = df_class_injury.sample(n=min_size)\n",
    "    print(\"Shape of injury sampled dataframe: {}\".format(df_class_injury_select.shape))\n",
    "    df_class_safe_select = df_class_safe.sample(n=min_size)\n",
    "    print(\"Shape of nom-injury sampled dataframe: {}\".format(df_class_safe_select.shape))\n",
    "    \n",
    "    #concat the three dataframes\n",
    "    df_underSample = pd.concat([df_class_fatal, df_class_injury_select, df_class_safe_select])\n",
    "    print(df_underSample.shape)\n",
    "    \n",
    "    #TBD\n",
    "    if sampleN < df_underSample.index.size:\n",
    "        df_sample = df_underSample.sample(n=sampleN)\n",
    "    else:\n",
    "        df_sample = df_underSample.sample(n=df_underSample.index.size)\n",
    "    \n",
    "    #perform the conversion in two steps to avoid any unwanted side effects\n",
    "    df_sample['P_ISEV'] = df_sample['P_ISEV'].map({1: 'safe', 2: 'injury', 3:'fatal'})\n",
    "    df_sample['P_ISEV'] = df_sample['P_ISEV'].map({'safe': '0', 'injury': '1', 'fatal':'2'})\n",
    "    print((df_sample['P_ISEV']=='0').sum())\n",
    "    print((df_sample['P_ISEV']=='1').sum())\n",
    "    print((df_sample['P_ISEV']=='2').sum())\n",
    "    print(df_sample['P_ISEV'].unique())\n",
    "else:\n",
    "    df_class = df_cat.copy()\n",
    "\n",
    "    #perform the conversion in two steps to avoid any unwanted side effects\n",
    "    df_class['P_ISEV'] = df_class['P_ISEV'].map({1: 'safe', 2: 'injury', 3:'fatal'})\n",
    "    df_class['P_ISEV'] = df_class['P_ISEV'].map({'safe': '0', 'injury': '1', 'fatal':'1'})\n",
    "    print((df_class['P_ISEV']=='0').sum())\n",
    "    print((df_class['P_ISEV']=='1').sum())\n",
    "    print(df_class['P_ISEV'].unique())\n",
    "    \n",
    "    df_sample = df_class.sample(n=sampleN)\n",
    "\n",
    "print(\"Size of dataframe for modeling: {}\".format(df_sample.index.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df_sample[df_sample.columns].apply(lambda x: x.astype(str).str.contains('[^0-9]')).sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3500000 entries, 1384892 to 3358225\n",
      "Data columns (total 17 columns):\n",
      "C_YEAR    category\n",
      "C_MNTH    category\n",
      "C_WDAY    category\n",
      "C_HOUR    category\n",
      "C_VEHS    category\n",
      "C_CONF    category\n",
      "C_RCFG    category\n",
      "C_WTHR    category\n",
      "C_RSUR    category\n",
      "C_RALN    category\n",
      "C_TRAF    category\n",
      "V_YEAR    category\n",
      "P_SEX     category\n",
      "P_AGE     int32\n",
      "P_PSN     category\n",
      "P_USER    category\n",
      "P_ISEV    int32\n",
      "dtypes: category(15), int32(2)\n",
      "memory usage: 103.5 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# convert to the correct type\n",
    "df_sample = df_sample.astype('category')\n",
    "df_sample['C_YEAR'] = df_sample['C_YEAR'].astype(CategoricalDtype(ordered=True))\n",
    "df_sample['C_MNTH'] = df_sample['C_MNTH'].astype(CategoricalDtype(ordered=True))\n",
    "df_sample['C_WDAY'] = df_sample['C_WDAY'].astype(CategoricalDtype(ordered=True))\n",
    "df_sample['C_HOUR'] = df_sample['C_HOUR'].astype(CategoricalDtype(ordered=True))\n",
    "df_sample['V_YEAR'] = df_sample['V_YEAR'].astype(CategoricalDtype(ordered=True))\n",
    "df_sample['P_AGE'] = df_sample['P_AGE'].astype('int')\n",
    "df_sample['P_ISEV'] = df_sample['P_ISEV'].astype('int')\n",
    "print(df_sample.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training and Testing for Binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split between data and class\n",
    "#Y = df_sample[df_sample.columns[-1]]\n",
    "#X = df_sample[df_sample.columns[0:df_sample.columns.size -1]]\n",
    "\n",
    "# split data into X and y\n",
    "X = df_sample.iloc[0:1000,0:16]\n",
    "Y = df_sample.iloc[0:1000,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "print(Y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C_YEAR C_MNTH C_WDAY C_HOUR C_VEHS C_CONF C_RCFG C_WTHR C_RSUR C_RALN  \\\n",
      "1384892      7      1      2      1      4     21      1      1      4      3   \n",
      "1171035      6      1      4      1      2     21      1      4      3      1   \n",
      "3257595     16     10      3      3      2     36      2      1      1      1   \n",
      "\n",
      "        C_TRAF V_YEAR P_SEX  P_AGE P_PSN P_USER  \n",
      "1384892      7      2     1     52     1      1  \n",
      "1171035      7      3     0     26     1      1  \n",
      "3257595      1      3     0     27     1      1  \n"
     ]
    }
   ],
   "source": [
    "print(X.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Test(70%) and Train (30%) for Bianry class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sprint into train and test 70/30\n",
    "#X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering based on K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 30 21:37:50 2018\n",
      "K-Means Clustering: Start\n",
      "KMeans(algorithm='auto', copy_x=True, init='random', max_iter=100,\n",
      "    n_clusters=3, n_init=10, n_jobs=None, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=3)\n",
      "K-Means Clustering: Build\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 272196.1085016302\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 241472.24011975277\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 233387.44287938677\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 229839.87104405923\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 228176.45754562446\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 227492.86220597313\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 227187.17864805082\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 227040.74769395945\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 227004.239188437\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 226990.93443046988\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 226977.3491129981\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 226971.55059484934\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 226969.91872674198\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 226967.34309285134\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 226960.5396483306\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 226957.51296579384\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 226957.51296579384\n",
      "center shift 0.000000e+00 within tolerance 3.279565e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 354365.6224035267\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 279781.7092794187\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 254967.48469075834\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 244789.52782745054\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 236320.72587742558\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 230433.8844689818\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 228762.92881515663\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 227908.37885392466\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 227423.10879966992\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 227167.34048431102\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 226961.93434043412\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 226924.99871599363\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 226914.93788994433\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 226907.34829280825\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 226904.78909077152\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 226891.41037375908\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 226885.80971100208\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 226885.80971100208\n",
      "center shift 0.000000e+00 within tolerance 3.279565e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 399000.4309566959\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 263451.5793860064\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 232999.85687479874\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 231246.63753436593\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 231017.0956716583\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 230948.8806724883\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 230948.8806724883\n",
      "center shift 0.000000e+00 within tolerance 3.279565e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 254634.35800124658\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 237616.4773506884\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 234307.96991473006\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 229099.72830926592\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 227295.70337013406\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 227014.70039372222\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 227005.78124326392\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 226997.940473443\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 226985.4058632531\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 226971.88099563954\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 226967.22273017903\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 226967.22273017903\n",
      "center shift 0.000000e+00 within tolerance 3.279565e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 281055.8602760332\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 266541.19134364027\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 242255.78487929647\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 236543.55758644373\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 235193.75782953226\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 234236.83964650292\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 233055.9737234534\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 232169.6808930204\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 231728.24655432595\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 231327.33270905234\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 230976.0068140298\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 230893.51293267016\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 230821.05488156053\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 230701.74885914795\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 230623.14579418272\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 230609.42184210502\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 230604.5844105018\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 230600.3427782324\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 230600.3427782324\n",
      "center shift 0.000000e+00 within tolerance 3.279565e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 253474.12843243193\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 234440.50417169268\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 231695.37481800443\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 230736.0025263842\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 229541.73882891267\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 228400.90902100914\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 227714.2872028557\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 227356.95532870054\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 227072.17121322622\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 226931.37423364678\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 226914.93788994433\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 226907.34829280825\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 226904.78909077152\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 226891.41037375908\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 226885.80971100208\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 226885.80971100208\n",
      "center shift 0.000000e+00 within tolerance 3.279565e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 279029.9458989985\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 240334.29802115462\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 233215.84721643967\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 231506.82886547456\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 230916.8139595379\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 230668.36067196832\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 230642.77753141292\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 230638.29997537754\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 230636.42703376035\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 230636.42703376035\n",
      "center shift 0.000000e+00 within tolerance 3.279565e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 229058.60952968345\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 227503.95542332722\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 227221.4927108895\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 226974.6978186734\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 226914.6992176387\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 226905.25439035133\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 226899.00854516862\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 226897.5604372461\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 226885.14955799282\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, inertia 226878.58580358443\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 226878.58580358443\n",
      "center shift 0.000000e+00 within tolerance 3.279565e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 385332.66765523405\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 267993.61693192564\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 243611.45663889428\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 239599.33117124793\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 238379.07763076195\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 238100.06630247316\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 237742.7017920321\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 236983.5591265679\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 235955.75323689723\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 233293.2536582427\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 227959.8612232576\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 227022.3304358013\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 226990.8051920221\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 226971.93454921132\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 226968.60042056188\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 226957.92374848184\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 226953.2584777521\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 226946.30666572085\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 226946.30666572085\n",
      "center shift 0.000000e+00 within tolerance 3.279565e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 257158.97416344535\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 234035.10634097946\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 231268.75015703743\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 230793.5168406146\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 230677.54590284222\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 230642.26168437186\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 230633.79064690025\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 230631.40171856218\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 230626.4075887575\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 230617.45555444434\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 230617.45555444434\n",
      "center shift 0.000000e+00 within tolerance 3.279565e-03\n",
      "[[ 9.37196765  6.67385445  3.90566038  2.30458221  2.1671159  27.19407008\n",
      "   1.77897574  1.46091644  1.3638814   1.23989218  4.03504043  2.5902965\n",
      "   0.54177898 56.61994609  1.04851752  1.23450135]\n",
      " [ 9.44215938  6.84318766  3.8714653   2.42416452  2.2159383  28.85604113\n",
      "   1.80205656  1.6066838   1.50899743  1.2622108   3.66580977  2.55526992\n",
      "   0.54498715 21.93830334  1.24421594  1.43701799]\n",
      " [ 8.65833333  7.33333333  4.21666667  2.29166667  1.5625     10.0375\n",
      "   1.39166667  1.76666667  1.67083333  1.58333333  5.89166667  2.475\n",
      "   0.5875     31.99166667  1.07916667  1.31666667]]\n",
      "[0 1 1 2 1 0 1 0 1 1 0 2 0 0 0 0 2 1 1 1 1 0 0 1 1 0 1 1 0 1 0 1 0 0 1 0 0\n",
      " 1 1 2 1 1 1 2 0 1 2 1 1 0 2 0 2 1 0 1 1 1 1 2 2 1 1 1 0 1 1 0 1 1 1 2 1 2\n",
      " 2 0 1 2 0 0 1 0 0 1 1 0 2 0 1 2 1 0 0 2 1 2 2 0 0 2 0 2 1 2 1 2 1 0 1 1 0\n",
      " 0 1 0 2 2 0 1 0 1 2 0 2 1 0 0 1 1 0 1 0 1 1 2 2 0 0 2 1 1 0 0 0 0 1 0 0 0\n",
      " 2 0 2 1 1 0 2 2 1 1 0 0 0 1 2 0 1 0 1 1 1 0 1 1 0 2 2 2 2 0 0 2 0 2 1 1 0\n",
      " 1 1 2 1 2 2 1 0 0 1 2 0 0 1 0 0 0 1 1 1 1 1 0 0 2 0 1 0 1 1 0 2 2 0 0 0 1\n",
      " 0 0 2 2 0 1 1 1 2 0 1 1 2 1 1 1 1 2 2 0 2 0 0 0 2 0 1 1 0 0 1 2 1 1 2 0 1\n",
      " 1 2 1 0 2 0 0 1 1 1 1 0 1 2 1 1 1 2 2 0 2 0 1 0 1 1 0 1 0 0 0 2 0 0 0 2 0\n",
      " 1 1 2 1 0 0 0 0 2 1 1 0 1 2 0 2 0 0 0 1 0 1 0 1 0 2 2 2 1 1 1 2 1 1 0 0 2\n",
      " 2 2 2 2 1 2 0 2 0 0 0 2 2 1 1 0 2 2 1 1 0 2 0 0 0 2 2 0 0 0 0 1 2 1 1 0 0\n",
      " 1 0 1 1 1 1 1 0 1 2 0 0 1 2 1 2 1 1 0 2 1 0 0 0 1 2 0 0 1 1 0 0 0 0 1 0 2\n",
      " 0 0 0 2 1 1 1 1 2 0 1 1 0 1 0 0 2 1 2 2 2 0 2 1 0 1 0 1 1 2 0 0 0 0 2 0 2\n",
      " 0 1 1 2 2 1 1 1 0 0 1 1 0 0 1 1 2 0 1 2 0 1 1 2 0 0 0 2 1 2 1 2 2 1 0 1 1\n",
      " 0 0 1 0 0 0 1 2 2 1 0 1 1 2 1 0 1 1 1 0 0 1 2 1 2 1 2 1 2 0 2 0 0 0 0 2 1\n",
      " 0 1 2 1 1 0 2 2 1 1 2 2 2 1 1 2 1 0 0 2 1 0 0 2 1 0 2 2 1 1 0 2 0 0 1 1 0\n",
      " 2 1 2 2 2 0 0 0 1 2 1 1 2 0 1 2 2 0 1 0 0 1 2 1 2 1 0 2 1 2 0 0 1 0 2 0 1\n",
      " 2 1 0 0 2 0 0 0 1 0 1 0 0 0 0 1 2 0 1 1 1 1 2 2 1 1 2 0 1 0 1 2 2 0 1 0 0\n",
      " 2 2 2 0 1 0 1 0 0 2 0 0 0 0 1 0 2 2 2 1 0 0 0 1 0 1 0 1 1 1 2 0 1 2 0 0 2\n",
      " 1 2 0 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 0 1 2 1 2 1 2 0 1 1 0 0 0 1 0 0 1 0 1\n",
      " 2 0 0 1 0 0 0 2 1 0 1 1 1 2 1 2 1 1 0 1 1 2 0 0 1 0 1 1 0 0 2 1 2 1 0 1 2\n",
      " 0 1 0 0 0 1 1 2 0 2 1 0 1 0 1 1 1 0 2 2 0 2 0 1 0 1 1 2 2 1 0 0 0 1 1 2 0\n",
      " 0 0 0 2 0 0 1 1 2 2 2 1 2 0 1 0 1 0 0 1 0 2 1 1 1 1 0 1 1 2 1 1 1 0 1 1 0\n",
      " 0 2 1 2 2 0 0 0 0 2 1 0 0 1 1 0 1 1 2 0 0 0 2 2 0 0 0 0 1 1 1 0 0 0 0 1 1\n",
      " 0 0 2 2 1 1 0 2 0 0 0 1 1 0 1 1 1 0 0 2 0 0 2 1 2 1 1 1 2 1 0 2 1 2 2 1 1\n",
      " 2 0 0 0 1 1 2 1 1 1 2 0 2 2 2 1 1 2 1 0 2 1 2 2 0 1 0 2 1 1 2 1 1 0 0 2 0\n",
      " 2 0 0 1 0 1 0 1 2 0 1 2 0 2 1 1 0 2 1 1 1 0 2 0 1 2 1 1 2 1 0 1 1 1 2 2 1\n",
      " 0 1 1 2 0 1 1 0 1 2 1 0 1 0 1 0 2 2 1 0 0 0 1 1 2 1 0 1 1 0 2 1 2 1 0 0 1\n",
      " 0]\n",
      "K-Means Clustering: End\n",
      "Fri Nov 30 21:37:50 2018\n"
     ]
    }
   ],
   "source": [
    "if enable_kmean:\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print(\"K-Means Clustering: Start\")\n",
    "    kmeans = KMeans(n_clusters=3, init='random', n_init=10, max_iter=100, tol=1e-04, verbose= verbose_level)\n",
    "    print(kmeans)\n",
    "    \n",
    "    print(\"K-Means Clustering: Build\")\n",
    "    ykm = kmeans.fit(X)\n",
    "    \n",
    "    if pyscript:\n",
    "        print(ykm.cluster_centers_)\n",
    "        print(ykm.labels_)\n",
    "    else:\n",
    "        display(ykm.cluster_centers_)\n",
    "        display(ykm.labels_)\n",
    "    \n",
    "    # save model to file\n",
    "    pickle.dump(ykm, open(file_kmean, \"wb\"))\n",
    "    \n",
    "    print(\"K-Means Clustering: End\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM GridSearch for Optimal Parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This operation is computationaly expensive.\n",
    "if enable_grid_search:\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    param_grid = {'C':[0.1, 1, 10, 100, 1000], 'gamma':[1, 0.1, 0.01, 0.001, 0.0001]}\n",
    "    grid = GridSearchCV(SVC(), param_grid, verbose=verbose_level)\n",
    "    print(grid)\n",
    "    grid.fit(X_train, Y_train)\n",
    "    print(grid.best_params_)\n",
    "    svm_c = grid.best_params_.get('C')\n",
    "    svm_gamma = grid.best_params_.get('gamma')\n",
    "    print(grid.best_estimator_)\n",
    "    grid_predictions = grid.predict(X_test)\n",
    "    cfn_matrix_grid = confusion_matrix(Y_test, grid_predictions)\n",
    "    print(cfn_matrix_grid)\n",
    "    print(classification_report(Y_test,grid_predictions))\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Start\n",
      "Fri Nov 30 21:37:50 2018\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='auto', n_jobs=10,\n",
      "          penalty='l2', random_state=0, solver='saga', tol=0.0001,\n",
      "          verbose=3, warm_start=False)\n",
      "Logistic Regression: Fit\n",
      "max_iter reached after 0 seconds\n",
      "Logistic Regression: Predict\n",
      "Accuracy of logistic regression classifier on train set: 0.60\n",
      "Accuracy of logistic regression classifier on test set: 0.61\n",
      "Logistic Regression: Intercept\n",
      "[0.08195873]\n",
      "Logistic Regression: Coefficients\n",
      "[[ 0.04046685  0.00833698  0.02357705 -0.02748427 -0.20673744 -0.01473736\n",
      "   0.06470615 -0.00215138  0.0864911   0.20766686  0.04873346 -0.17703569\n",
      "  -0.399519    0.00602553 -0.07988818  0.18707998]]\n",
      "Logistic Regression: Confusion Matrix\n",
      "[[ 55  61]\n",
      " [ 56 128]]\n",
      "Logistic Regression: Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.47      0.48       116\n",
      "           1       0.68      0.70      0.69       184\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       300\n",
      "   macro avg       0.59      0.58      0.59       300\n",
      "weighted avg       0.61      0.61      0.61       300\n",
      "\n",
      "Fri Nov 30 21:37:50 2018\n",
      "Logistic Regression: End\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "if enable_lr:\n",
    "    print(\"Logistic Regression: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    lr = LogisticRegression(C=1, random_state=0, solver='saga', multi_class='auto', verbose=verbose_level, n_jobs=10)\n",
    "    print(lr)\n",
    "    print(\"Logistic Regression: Fit\")\n",
    "    lr.fit(X_train, Y_train)\n",
    "    \n",
    "    # save model to file\n",
    "    pickle.dump(lr, open(file_lr, \"wb\"))\n",
    "    \n",
    "    \n",
    "if predict_lr:\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_lr, \"rb\"))\n",
    "    print(\"Logistic Regression: Predict\")\n",
    "    y_pred = lr.predict(X_test)\n",
    "\n",
    "    print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(lr.score(X_train, Y_train)))\n",
    "    print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(lr.score(X_test, Y_test)))\n",
    "\n",
    "    # print the intercept (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "    print(\"Logistic Regression: Intercept\")\n",
    "    print(lr.intercept_)\n",
    "\n",
    "    # print the coeficients (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "    print(\"Logistic Regression: Coefficients\")\n",
    "    print(lr.coef_)\n",
    "\n",
    "    print(\"Logistic Regression: Confusion Matrix\")\n",
    "    cnf_matrix_lg = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_lg)\n",
    "    \n",
    "    print(\"Logistic Regression: Classification Report\")\n",
    "    print(classification_report(Y_test, y_pred))\n",
    "\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"Logistic Regression: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with L1 Regularization: Start\n",
      "Fri Nov 30 21:37:50 2018\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='auto', n_jobs=10,\n",
      "          penalty='l1', random_state=None, solver='saga', tol=0.0001,\n",
      "          verbose=3, warm_start=False)\n",
      "Logistic Regression with L1 Regularization: Fit\n",
      "max_iter reached after 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with L1 Regularization: Predict\n",
      "Accuracy of logistic regression classifier on train set: 0.60\n",
      "Accuracy of logistic regression classifier on test set: 0.64\n",
      "Logistic Regression with L1 Regularization: Confusion Matrix\n",
      "[[ 61  55]\n",
      " [ 53 131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.53      0.53       116\n",
      "           1       0.70      0.71      0.71       184\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       300\n",
      "   macro avg       0.62      0.62      0.62       300\n",
      "weighted avg       0.64      0.64      0.64       300\n",
      "\n",
      "Logistic Regression with L1 Regularization: Classification Report\n",
      "Fri Nov 30 21:37:50 2018\n",
      "Logistic Regression with L1 Regularization: End\n"
     ]
    }
   ],
   "source": [
    "if (enable_lr_l1):\n",
    "    # with L1 regularization\n",
    "    print(\"Logistic Regression with L1 Regularization: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    lr = LogisticRegression(penalty='l1', C=1, solver='saga', multi_class='auto', verbose=verbose_level, n_jobs = 10)\n",
    "    print(lr)\n",
    "    print(\"Logistic Regression with L1 Regularization: Fit\")\n",
    "    lr.fit(X_train, Y_train)\n",
    "    \n",
    "    # save model to file\n",
    "    pickle.dump(lr, open(file_lr_l1, \"wb\"))\n",
    "\n",
    "if (predict_lr_l1):\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_lr_l1, \"rb\"))\n",
    "    print(\"Logistic Regression with L1 Regularization: Predict\")\n",
    "    y_pred = lr.predict(X_test)\n",
    "    \n",
    "    print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(lr.score(X_train, Y_train)))\n",
    "    print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(lr.score(X_test, Y_test)))\n",
    "\n",
    "    print(\"Logistic Regression with L1 Regularization: Confusion Matrix\")\n",
    "    cnf_matrix_lg_l1 = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_lg_l1)\n",
    "    \n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    print(\"Logistic Regression with L1 Regularization: Classification Report\")\n",
    "\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "print(\"Logistic Regression with L1 Regularization: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: Start\n",
      "Fri Nov 30 21:37:50 2018\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=50,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "Decision Tree: Fit\n",
      "Decision Tree: Predict\n",
      "Accuracy of Decision Tree classifier on train set: 1.00\n",
      "Accuracy of Decision Tree classifier on test set: 0.59\n",
      "Decision Tree: Confusion Matrix\n",
      "[[ 61  55]\n",
      " [ 68 116]]\n",
      "Decision Tree: Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.53      0.50       116\n",
      "           1       0.68      0.63      0.65       184\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       300\n",
      "   macro avg       0.58      0.58      0.58       300\n",
      "weighted avg       0.60      0.59      0.59       300\n",
      "\n",
      "Fri Nov 30 21:37:50 2018\n",
      "Decision Tree: End\n"
     ]
    }
   ],
   "source": [
    "if enable_dt:\n",
    "    print(\"Decision Tree: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    tree = DecisionTreeClassifier(criterion='entropy',max_depth=50)\n",
    "    print(tree)\n",
    "    print(\"Decision Tree: Fit\")\n",
    "    tree.fit(X_train, Y_train)\n",
    "    # save model to file\n",
    "    pickle.dump(tree, open(file_dt, \"wb\"))\n",
    "\n",
    "if predict_dt:\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_dt, \"rb\"))\n",
    "    print(\"Decision Tree: Predict\")\n",
    "    y_pred = tree.predict(X_test)\n",
    "    print('Accuracy of Decision Tree classifier on train set: {:.2f}'.format(tree.score(X_train, Y_train)))\n",
    "    print('Accuracy of Decision Tree classifier on test set: {:.2f}'.format(tree.score(X_test, Y_test)))\n",
    "    \n",
    "    cnf_matrix_dt = confusion_matrix(Y_test, y_pred)\n",
    "    print(\"Decision Tree: Confusion Matrix\")\n",
    "    print(cnf_matrix_dt)\n",
    "    print(\"Decision Tree: Classification Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    print(\"Decision Tree: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-N-N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: Start\n",
      "Fri Nov 30 21:37:50 2018\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=10, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNN: Fit\n",
      "KNN: Predict\n",
      "Accuracy of KNN classifier on train set: 0.71\n",
      "Accuracy of KNN classifier on test set: 0.53\n",
      "KNN: Confusion Matrix\n",
      "[[ 48  68]\n",
      " [ 73 111]]\n",
      "KNN: Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.41      0.41       116\n",
      "           1       0.62      0.60      0.61       184\n",
      "\n",
      "   micro avg       0.53      0.53      0.53       300\n",
      "   macro avg       0.51      0.51      0.51       300\n",
      "weighted avg       0.53      0.53      0.53       300\n",
      "\n",
      "Fri Nov 30 21:37:50 2018\n",
      "KNN: End\n"
     ]
    }
   ],
   "source": [
    "if enable_knn:\n",
    "    print(\"KNN: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    knn = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski', n_jobs = 10)\n",
    "    print(knn)\n",
    "    print(\"KNN: Fit\")\n",
    "    knn.fit(X_train, Y_train)\n",
    "\n",
    "    # save model to file\n",
    "    pickle.dump(knn, open(file_knn, \"wb\"))\n",
    "\n",
    "if predict_knn:\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_knn, \"rb\"))\n",
    "    \n",
    "    print(\"KNN: Predict\")\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print('Accuracy of KNN classifier on train set: {:.2f}'.format(knn.score(X_train, Y_train)))\n",
    "    print('Accuracy of KNN classifier on test set: {:.2f}'.format(knn.score(X_test, Y_test)))\n",
    "    \n",
    "    print(\"KNN: Confusion Matrix\")\n",
    "    cnf_matrix_knn = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_knn)\n",
    "\n",
    "    print(\"KNN: Classification Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "\n",
    "    print(\"KNN: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN - Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Preceptron: Start\n",
      "Fri Nov 30 21:37:50 2018\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(25, 25, 25), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=3, warm_start=False)\n",
      "Multilayer Preceptron: fit\n",
      "Iteration 1, loss = 1.36585763\n",
      "Iteration 2, loss = 0.92206233\n",
      "Iteration 3, loss = 0.85918506\n",
      "Iteration 4, loss = 0.79060167\n",
      "Iteration 5, loss = 0.71862777\n",
      "Iteration 6, loss = 0.72741696\n",
      "Iteration 7, loss = 0.70384951\n",
      "Iteration 8, loss = 0.68834516\n",
      "Iteration 9, loss = 0.68873291\n",
      "Iteration 10, loss = 0.67848949\n",
      "Iteration 11, loss = 0.67199238\n",
      "Iteration 12, loss = 0.67040980\n",
      "Iteration 13, loss = 0.66651320\n",
      "Iteration 14, loss = 0.66520833\n",
      "Iteration 15, loss = 0.66365721\n",
      "Iteration 16, loss = 0.66208645\n",
      "Iteration 17, loss = 0.66147079\n",
      "Iteration 18, loss = 0.65958524\n",
      "Iteration 19, loss = 0.65861162\n",
      "Iteration 20, loss = 0.65781411\n",
      "Iteration 21, loss = 0.65604081\n",
      "Iteration 22, loss = 0.65512379\n",
      "Iteration 23, loss = 0.65437387\n",
      "Iteration 24, loss = 0.65506968\n",
      "Iteration 25, loss = 0.65392517\n",
      "Iteration 26, loss = 0.65545620\n",
      "Iteration 27, loss = 0.65183170\n",
      "Iteration 28, loss = 0.65155571\n",
      "Iteration 29, loss = 0.65203353\n",
      "Iteration 30, loss = 0.65074937\n",
      "Iteration 31, loss = 0.64874105\n",
      "Iteration 32, loss = 0.64834537\n",
      "Iteration 33, loss = 0.64735914\n",
      "Iteration 34, loss = 0.64661214\n",
      "Iteration 35, loss = 0.64590832\n",
      "Iteration 36, loss = 0.64582420\n",
      "Iteration 37, loss = 0.64650732\n",
      "Iteration 38, loss = 0.64681453\n",
      "Iteration 39, loss = 0.64469747\n",
      "Iteration 40, loss = 0.64405029\n",
      "Iteration 41, loss = 0.64478347\n",
      "Iteration 42, loss = 0.64222621\n",
      "Iteration 43, loss = 0.64141328\n",
      "Iteration 44, loss = 0.64136969\n",
      "Iteration 45, loss = 0.64041500\n",
      "Iteration 46, loss = 0.64143643\n",
      "Iteration 47, loss = 0.64249936\n",
      "Iteration 48, loss = 0.64155124\n",
      "Iteration 49, loss = 0.63854241\n",
      "Iteration 50, loss = 0.63782136\n",
      "Iteration 51, loss = 0.63725876\n",
      "Iteration 52, loss = 0.63732707\n",
      "Iteration 53, loss = 0.63654295\n",
      "Iteration 54, loss = 0.63556333\n",
      "Iteration 55, loss = 0.63753760\n",
      "Iteration 56, loss = 0.63575862\n",
      "Iteration 57, loss = 0.63700744\n",
      "Iteration 58, loss = 0.63500356\n",
      "Iteration 59, loss = 0.63442659\n",
      "Iteration 60, loss = 0.63459084\n",
      "Iteration 61, loss = 0.63330620\n",
      "Iteration 62, loss = 0.63297450\n",
      "Iteration 63, loss = 0.63286842\n",
      "Iteration 64, loss = 0.63108144\n",
      "Iteration 65, loss = 0.63213819\n",
      "Iteration 66, loss = 0.63013492\n",
      "Iteration 67, loss = 0.62995929\n",
      "Iteration 68, loss = 0.62924143\n",
      "Iteration 69, loss = 0.63094202\n",
      "Iteration 70, loss = 0.62717961\n",
      "Iteration 71, loss = 0.62899580\n",
      "Iteration 72, loss = 0.62528006\n",
      "Iteration 73, loss = 0.62855587\n",
      "Iteration 74, loss = 0.62570255\n",
      "Iteration 75, loss = 0.62719470\n",
      "Iteration 76, loss = 0.62577765\n",
      "Iteration 77, loss = 0.62491166\n",
      "Iteration 78, loss = 0.62313904\n",
      "Iteration 79, loss = 0.62362155\n",
      "Iteration 80, loss = 0.62290916\n",
      "Iteration 81, loss = 0.62190059\n",
      "Iteration 82, loss = 0.62118192\n",
      "Iteration 83, loss = 0.62082213\n",
      "Iteration 84, loss = 0.62039210\n",
      "Iteration 85, loss = 0.61896257\n",
      "Iteration 86, loss = 0.61953073\n",
      "Iteration 87, loss = 0.61969713\n",
      "Iteration 88, loss = 0.61750744\n",
      "Iteration 89, loss = 0.61893402\n",
      "Iteration 90, loss = 0.61642490\n",
      "Iteration 91, loss = 0.61527224\n",
      "Iteration 92, loss = 0.61461895\n",
      "Iteration 93, loss = 0.61605482\n",
      "Iteration 94, loss = 0.61374310\n",
      "Iteration 95, loss = 0.61444650\n",
      "Iteration 96, loss = 0.61302837\n",
      "Iteration 97, loss = 0.61128499\n",
      "Iteration 98, loss = 0.61136916\n",
      "Iteration 99, loss = 0.61337550\n",
      "Iteration 100, loss = 0.60945290\n",
      "Multilayer Preceptron: Predict\n",
      "Accuracy of Multilayer Perceptron classifier on train set: 0.67\n",
      "Accuracy of Multilayer Perceptron classifier on test set: 0.60\n",
      "Multilayer Preceptron: Confusion Matrix\n",
      "[[ 69  47]\n",
      " [ 74 110]]\n",
      "Multilayer Preceptron: Classificiation Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.59      0.53       116\n",
      "           1       0.70      0.60      0.65       184\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       300\n",
      "   macro avg       0.59      0.60      0.59       300\n",
      "weighted avg       0.62      0.60      0.60       300\n",
      "\n",
      "Fri Nov 30 21:37:51 2018\n",
      "Multilayer Preceptron: End\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "if enable_mlp:\n",
    "    print(\"Multilayer Preceptron: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    \n",
    "    #mlpc = MLPClassifier(alpha=1)\n",
    "    #mlpc = MLPClassifier(hidden_layer_sizes=(12, 12, 12), max_iter=100, verbose=verbose_level)\n",
    "    mlpc = MLPClassifier(hidden_layer_sizes=(25, 25, 25), max_iter=100, verbose=verbose_level)\n",
    "    print(mlpc)\n",
    "    #mlp = multilayer_perceptron(n_hidden =2, activation='logistic', algorithm='sgd', random_state=3)\n",
    "    print(\"Multilayer Preceptron: fit\")\n",
    "    mlpc.fit(X_train, Y_train)\n",
    "    \n",
    "    # save model to file\n",
    "    pickle.dump(mlpc, open(file_mlp, \"wb\"))\n",
    "    \n",
    "if predict_mlp:\n",
    "    \n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_mlp, \"rb\"))\n",
    "    print(\"Multilayer Preceptron: Predict\")\n",
    "    y_pred = mlpc.predict(X_test)\n",
    "\n",
    "    print('Accuracy of Multilayer Perceptron classifier on train set: {:.2f}'.format(mlpc.score(X_train, Y_train)))\n",
    "    print('Accuracy of Multilayer Perceptron classifier on test set: {:.2f}'.format(mlpc.score(X_test, Y_test)))\n",
    "    \n",
    "    print(\"Multilayer Preceptron: Confusion Matrix\")\n",
    "    cnf_matrix_mlp = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_mlp)\n",
    "    \n",
    "    print(\"Multilayer Preceptron: Classificiation Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "    print(\"Multilayer Preceptron: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: Start\n",
      "Fri Nov 30 21:37:51 2018\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=3)\n",
      "SVM: Fit\n",
      "[LibSVM]SVM: Predict\n",
      "Accuracy of SVM classifier on train set: 0.98\n",
      "Accuracy of SVM classifier on test set: 0.56\n",
      "SVM: Confusion Matrix\n",
      "[[ 32  84]\n",
      " [ 48 136]]\n",
      "SVM: Classfication Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.28      0.33       116\n",
      "           1       0.62      0.74      0.67       184\n",
      "\n",
      "   micro avg       0.56      0.56      0.56       300\n",
      "   macro avg       0.51      0.51      0.50       300\n",
      "weighted avg       0.53      0.56      0.54       300\n",
      "\n",
      "Fri Nov 30 21:37:51 2018\n",
      "SVM: End\n"
     ]
    }
   ],
   "source": [
    "if enable_svm:\n",
    "    print(\"SVM: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    #svm = SVC(C=1, random_state=0, kernel='sigmoid', verbose=True)\n",
    "    #svm = SVC(C=1, random_state=0, kernel='linear', verbose=True, cache_size=200)\n",
    "    #svm = SVC(C=svm_c, gamma=svm_gamma, verbose = verbose_level)\n",
    "    svm = SVC(C=1, gamma = 'auto', verbose = verbose_level)\n",
    "    print(svm)\n",
    "    print(\"SVM: Fit\")\n",
    "    svm.fit(X_train, Y_train)\n",
    "\n",
    "    # save model to file\n",
    "    pickle.dump(svm, open(file_svm, \"wb\"))\n",
    "    \n",
    "if predict_svm:\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_svm, \"rb\"))\n",
    "    print(\"SVM: Predict\")\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    print('Accuracy of SVM classifier on train set: {:.2f}'.format(svm.score(X_train, Y_train)))\n",
    "    print('Accuracy of SVM classifier on test set: {:.2f}'.format(svm.score(X_test, Y_test)))\n",
    "    \n",
    "    print(\"SVM: Confusion Matrix\")\n",
    "    cnf_matrix_svm = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_svm)\n",
    "    \n",
    "    print(\"SVM: Classfication Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "    print(\"SVM: End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 30 21:37:51 2018\n"
     ]
    }
   ],
   "source": [
    "t_end =  time.time()\n",
    "print(time.asctime( time.localtime(t_end) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
