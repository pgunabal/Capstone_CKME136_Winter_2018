{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 25\n",
    "pd.options.display.max_columns  = 25\n",
    "import time\n",
    "import pickle # allows for model to be saved/load to file\n",
    "import xgboost\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function converts the data frame to the appropriate data type\n",
    "def convert_type(data):\n",
    "    data = data.astype('category')\n",
    "    data['C_MNTH'] = data['C_MNTH'].astype(CategoricalDtype(ordered=True))\n",
    "    data['C_WDAY'] = data['C_WDAY'].astype(CategoricalDtype(ordered=True))\n",
    "    data['C_HOUR'] = data['C_HOUR'].astype(CategoricalDtype(ordered=True))\n",
    "    data['C_VEHS'] = data['C_VEHS'].astype(CategoricalDtype(ordered=True))\n",
    "    data['P_AGE'] = data['P_AGE'].astype(CategoricalDtype(ordered=True))\n",
    "    data['P_PSN'] = data['P_PSN'].astype(CategoricalDtype(ordered=True))\n",
    "    data['P_ISEV'] = data['P_ISEV'].astype('int')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable Algorithm Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable Algorithms\n",
    "enable_model_xgboost = True\n",
    "enable_model_randomForest = True\n",
    "enable_multiclass_model = True\n",
    "\n",
    "predict_xgboost = True\n",
    "predict_randomForest = True\n",
    "\n",
    "\n",
    "#Debug\n",
    "verbose_level=1\n",
    "#Multiclass classification, binary if falase\n",
    "multiclass = False\n",
    "over_sample = True\n",
    "\n",
    "# Datafile\n",
    "#inputfile = 'CKME136X10_2018_Data_CTF.csv'\n",
    "if multiclass:\n",
    "    inputfile_train_O = 'CKME136X10_2018_Data_CTFB_M_O_Train.csv'\n",
    "    inputfile_train_U = 'CKME136X10_2018_Data_CTFB_M_U_Train.csv'\n",
    "    inputfile_test = 'CKME136X10_2018_Data_CTFB_M_Test.csv'\n",
    "else:\n",
    "    inputfile_train_O = 'CKME136X10_2018_Data_CTFB_B_O_Train.csv'\n",
    "    inputfile_train_U = 'CKME136X10_2018_Data_CTFB_B_U_Train.csv'\n",
    "    inputfile_test = 'CKME136X10_2018_Data_CTFB_B_Test.csv'\n",
    "\n",
    "if over_sample:\n",
    "    datafile_train = inputfile_train_O\n",
    "else:\n",
    "    datafile_train = inputfile_train_U\n",
    "\n",
    "datafile_test = inputfile_test\n",
    "\n",
    "\n",
    "#file_input = 'NCDB_FULL_Removed_All_Missing_Values_Binary_Class_Transformed.csv'\n",
    "\n",
    "model_max_iter = 1000\n",
    "datestr = 'dec_07_binary_run_1000_BO'\n",
    "\n",
    "# Model File Names for storage\n",
    "file_random_forest = 'random_forest_'  + datestr + '.model'\n",
    "file_xgboost = 'xgboost_'  + datestr + '.model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C_MNTH  C_WDAY  C_HOUR  C_VEHS  C_CONF  C_RCFG  C_WTHR  C_RSUR  C_RALN  \\\n",
      "0       8       5       2       2      36       2       1       1       1   \n",
      "1       6       5       2       2      33       2       1       1       1   \n",
      "\n",
      "   C_TRAF  P_SEX  P_AGE  P_PSN  P_USER  P_ISEV  \n",
      "0       2      2      1      1       3       1  \n",
      "1       1      1      4      1       2       0  \n",
      "   C_MNTH  C_WDAY  C_HOUR  C_VEHS  C_CONF  C_RCFG  C_WTHR  C_RSUR  C_RALN  \\\n",
      "0       6       2       4       2      23       1       1       1       1   \n",
      "1       2       6       1       1       3       1       4       6       1   \n",
      "\n",
      "   C_TRAF  P_SEX  P_AGE  P_PSN  P_USER  P_ISEV  \n",
      "0       7      2      4      1       1       1  \n",
      "1       7      1      4      1       1       1  \n"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv(file_input, engine = 'python')\n",
    "\n",
    "#load data\n",
    "df_test = pd.read_csv(datafile_test, engine = 'python')\n",
    "df_train = pd.read_csv(datafile_train, engine = 'python')\n",
    "df = df_train.copy()\n",
    "\n",
    "print(df_test.head(2))\n",
    "print(df_train.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data set: (3878536, 15)\n",
      "Test data set: (1444846, 15)\n"
     ]
    }
   ],
   "source": [
    "print('Train data set: {}'.format(df_train.shape))\n",
    "print('Test data set: {}'.format(df_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into X and y\n",
    "#X = df.iloc[:,0:16]\n",
    "#Y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df_test.isnull().sum().sum())\n",
    "print(df_train.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df_test[df_test.columns].apply(lambda x: x.astype(str).str.contains('[^0-9]')).sum().sum())\n",
    "print(df_train[df_train.columns].apply(lambda x: x.astype(str).str.contains('[^0-9]')).sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1444846 entries, 0 to 1444845\n",
      "Data columns (total 15 columns):\n",
      "C_MNTH    1444846 non-null category\n",
      "C_WDAY    1444846 non-null category\n",
      "C_HOUR    1444846 non-null category\n",
      "C_VEHS    1444846 non-null category\n",
      "C_CONF    1444846 non-null category\n",
      "C_RCFG    1444846 non-null category\n",
      "C_WTHR    1444846 non-null category\n",
      "C_RSUR    1444846 non-null category\n",
      "C_RALN    1444846 non-null category\n",
      "C_TRAF    1444846 non-null category\n",
      "P_SEX     1444846 non-null category\n",
      "P_AGE     1444846 non-null category\n",
      "P_PSN     1444846 non-null category\n",
      "P_USER    1444846 non-null category\n",
      "P_ISEV    1444846 non-null int32\n",
      "dtypes: category(14), int32(1)\n",
      "memory usage: 24.8 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3878536 entries, 0 to 3878535\n",
      "Data columns (total 15 columns):\n",
      "C_MNTH    category\n",
      "C_WDAY    category\n",
      "C_HOUR    category\n",
      "C_VEHS    category\n",
      "C_CONF    category\n",
      "C_RCFG    category\n",
      "C_WTHR    category\n",
      "C_RSUR    category\n",
      "C_RALN    category\n",
      "C_TRAF    category\n",
      "P_SEX     category\n",
      "P_AGE     category\n",
      "P_PSN     category\n",
      "P_USER    category\n",
      "P_ISEV    int32\n",
      "dtypes: category(14), int32(1)\n",
      "memory usage: 66.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_test_cat = df_test.astype('int').copy()\n",
    "df_train_cat = df_train.astype('int').copy()\n",
    "\n",
    "# convert to the correct type\n",
    "df_test_cat = convert_type(df_test_cat)\n",
    "print(df_test_cat.info())\n",
    "\n",
    "df_train_cat = convert_type(df_train_cat)\n",
    "print(df_train_cat.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows in test data: 1444846\n",
      "Number of Rows in train data: 3878536\n",
      "Total Number of Rows : 5323382\n"
     ]
    }
   ],
   "source": [
    "total_test_Rows = df_test_cat.index.size\n",
    "print(\"Number of Rows in test data: {}\".format(total_test_Rows))\n",
    "\n",
    "total_train_Rows = df_train_cat.index.size\n",
    "print(\"Number of Rows in train data: {}\".format(total_train_Rows))\n",
    "\n",
    "print(\"Total Number of Rows : {}\".format(total_test_Rows + total_train_Rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_cat = df_test.astype('int').copy()\n",
    "df_train_cat = df_train.astype('int').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into X and y\n",
    "X_train = df_train_cat.iloc[:,0:14]\n",
    "Y_train = df_train_cat.iloc[:,-1]\n",
    "\n",
    "# split data into X and y\n",
    "X_test = df_test_cat.iloc[:,0:14]\n",
    "Y_test = df_test_cat.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split between data and class for training\n",
    "#Y_train = df_train_cat[df_train_cat.columns[-1]]\n",
    "#X_train = df_train_cat[df_train_cat.columns[0:df_train_cat.columns.size -1]]\n",
    "\n",
    "#Y_test = df_test_cat[df_test_cat.columns[-1]]\n",
    "#X_test = df_test_cat[df_test_cat.columns[0:df_test_cat.columns.size -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C_MNTH  C_WDAY  C_HOUR  C_VEHS  C_CONF  C_RCFG  C_WTHR  C_RSUR  C_RALN  \\\n",
      "0       6       2       4       2      23       1       1       1       1   \n",
      "1       2       6       1       1       3       1       4       6       1   \n",
      "2       4       4       2       2      36       2       4       4       1   \n",
      "3       2       4       3       2      35       2       1       1       1   \n",
      "4      10       7       3       2       6       2       3       2       1   \n",
      "5       6       5       3       2      21       2       2       2       1   \n",
      "6       5       7       3       4      21       1       1       1       1   \n",
      "7       4       1       2       2      35       3       1       1       1   \n",
      "8       9       5       3       2      24       1       1       1       2   \n",
      "9      11       2       3       3      51       1       2       1       1   \n",
      "\n",
      "   C_TRAF  P_SEX  P_AGE  P_PSN  P_USER  \n",
      "0       7      2      4      1       1  \n",
      "1       7      1      4      1       1  \n",
      "2       2      2      4      1       1  \n",
      "3       1      2      4      1       1  \n",
      "4       1      2      4      1       1  \n",
      "5       6      2      3      1       1  \n",
      "6       7      2      5      1       1  \n",
      "7       2      1      4      1       1  \n",
      "8       7      2      6      1       3  \n",
      "9       7      1      3      1       1  \n",
      "   C_MNTH  C_WDAY  C_HOUR  C_VEHS  C_CONF  C_RCFG  C_WTHR  C_RSUR  C_RALN  \\\n",
      "0       8       5       2       2      36       2       1       1       1   \n",
      "1       6       5       2       2      33       2       1       1       1   \n",
      "2       5       6       3       2      36       2       1       1       2   \n",
      "3      12       4       4       1       2       1       1       1       1   \n",
      "4       2       4       2       1       6       2       1       1       1   \n",
      "5       7       5       3       2      34       2       1       1       1   \n",
      "6       7       5       3       3      41       3       1       1       2   \n",
      "7       5       7       3       2      21       2       1       1       1   \n",
      "8       6       6       2       3      35       2       1       1       1   \n",
      "9       2       7       4       1       3       4       5       3       3   \n",
      "\n",
      "   C_TRAF  P_SEX  P_AGE  P_PSN  P_USER  \n",
      "0       2      2      1      1       3  \n",
      "1       1      1      4      1       2  \n",
      "2       1      2      4      1       1  \n",
      "3       7      2      5      3       3  \n",
      "4       1      1      1      3       3  \n",
      "5       1      2      1      1       2  \n",
      "6       7      1      4      1       1  \n",
      "7       1      1      4      1       1  \n",
      "8       2      1      4      1       1  \n",
      "9       7      2      1      2       2  \n"
     ]
    }
   ],
   "source": [
    "print(X_train.head(10))\n",
    "print(X_test.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec  7 16:45:49 2018\n",
      "[16:45:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:45:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:45:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:45:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:45:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:45:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:45:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:45:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:45:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:45:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:45:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:45:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:45:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:45:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:46:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[16:46:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "Fri Dec  7 16:46:50 2018\n"
     ]
    }
   ],
   "source": [
    "# fit model no training data\n",
    "if (enable_model_xgboost):\n",
    "    t_ =  time.time()\n",
    "    print(time.asctime( time.localtime(t_) ))\n",
    "    \n",
    "    nX_train = np.array(X_train)\n",
    "    nY_train = np.array(Y_train)\n",
    "    \n",
    "    model = xgboost.XGBClassifier(silent=False, n_jobs=10)\n",
    "    model.fit(nX_train, nY_train)\n",
    "    \n",
    "    # save model to file\n",
    "    pickle.dump(model, open(file_xgboost, \"wb\"))\n",
    "    \n",
    "    t_ =  time.time()\n",
    "    print(time.asctime( time.localtime(t_) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C_MNTH    0\n",
       "C_WDAY    0\n",
       "C_HOUR    0\n",
       "C_VEHS    0\n",
       "C_CONF    0\n",
       "C_RCFG    0\n",
       "C_WTHR    0\n",
       "C_RSUR    0\n",
       "C_RALN    0\n",
       "C_TRAF    0\n",
       "P_SEX     0\n",
       "P_AGE     0\n",
       "P_PSN     0\n",
       "P_USER    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  5  2 ...  1  1  3]\n",
      " [ 6  5  2 ...  4  1  2]\n",
      " [ 5  6  3 ...  4  1  1]\n",
      " ...\n",
      " [10  5  5 ...  1  1  2]\n",
      " [12  2  4 ...  5  1  1]\n",
      " [ 6  5  4 ...  3  1  1]]\n"
     ]
    }
   ],
   "source": [
    "nX_test = np.array(X_test)\n",
    "nY_test = np.array(Y_test)\n",
    "print(nX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 0 1 1]\n",
      "Accuracy: 65.94%\n"
     ]
    }
   ],
   "source": [
    "#predictions for test data\n",
    "if (predict_xgboost):\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_xgboost, \"rb\"))\n",
    "    \n",
    "    # make predictions for test data\n",
    "    y_pred = loaded_model.predict(nX_test)\n",
    "    print(y_pred)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(nY_test, predictions)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1444846 entries, 0 to 1444845\n",
      "Data columns (total 15 columns):\n",
      "C_MNTH    1444846 non-null category\n",
      "C_WDAY    1444846 non-null category\n",
      "C_HOUR    1444846 non-null category\n",
      "C_VEHS    1444846 non-null category\n",
      "C_CONF    1444846 non-null category\n",
      "C_RCFG    1444846 non-null category\n",
      "C_WTHR    1444846 non-null category\n",
      "C_RSUR    1444846 non-null category\n",
      "C_RALN    1444846 non-null category\n",
      "C_TRAF    1444846 non-null category\n",
      "P_SEX     1444846 non-null category\n",
      "P_AGE     1444846 non-null category\n",
      "P_PSN     1444846 non-null category\n",
      "P_USER    1444846 non-null category\n",
      "P_ISEV    1444846 non-null int32\n",
      "dtypes: category(14), int32(1)\n",
      "memory usage: 24.8 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3878536 entries, 0 to 3878535\n",
      "Data columns (total 15 columns):\n",
      "C_MNTH    category\n",
      "C_WDAY    category\n",
      "C_HOUR    category\n",
      "C_VEHS    category\n",
      "C_CONF    category\n",
      "C_RCFG    category\n",
      "C_WTHR    category\n",
      "C_RSUR    category\n",
      "C_RALN    category\n",
      "C_TRAF    category\n",
      "P_SEX     category\n",
      "P_AGE     category\n",
      "P_PSN     category\n",
      "P_USER    category\n",
      "P_ISEV    int32\n",
      "dtypes: category(14), int32(1)\n",
      "memory usage: 66.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# convert to the correct type\n",
    "df_test_cat = convert_type(df_test_cat)\n",
    "print(df_test_cat.info())\n",
    "\n",
    "df_train_cat = convert_type(df_train_cat)\n",
    "print(df_train_cat.info())\n",
    "# convert to the correct type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble (Bagging): Random Forest: Start\n",
      "Fri Dec  7 16:46:54 2018\n",
      "Ensemble (Bagging): Random Forest: Fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:  1.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec  7 16:51:26 2018\n",
      "Ensemble (Bagging): Random Forest: End\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:  4.5min finished\n"
     ]
    }
   ],
   "source": [
    "if (enable_model_randomForest):\n",
    "    print(\"Ensemble (Bagging): Random Forest: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    forest = RandomForestClassifier(criterion='entropy', n_estimators=100, random_state=0, n_jobs=10, verbose=verbose_level)\n",
    "    print(\"Ensemble (Bagging): Random Forest: Fit\")\n",
    "    forest.fit(X_train, Y_train)\n",
    "    \n",
    "    # save model to file\n",
    "    pickle.dump(model, open(file_random_forest, \"wb\"))\n",
    "    \n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    \n",
    "    print(\"Ensemble (Bagging): Random Forest: End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble (Bagging): Random Forest: Predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:   25.1s finished\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForest classifier on train set: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:   24.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForest classifier on test set: 0.63\n",
      "Ensemble (Bagging): Random Forest: Confusion Matrix\n",
      "[[387567 226164]\n",
      " [301451 529664]]\n",
      "Ensemble (Bagging): Random Forest: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.63      0.59    613731\n",
      "          1       0.70      0.64      0.67    831115\n",
      "\n",
      "avg / total       0.64      0.63      0.64   1444846\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predictions for test data\n",
    "if (predict_randomForest):\n",
    "    \n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(file_random_forest, \"rb\"))\n",
    "    \n",
    "    print(\"Ensemble (Bagging): Random Forest: Predict\")\n",
    "    y_pred = forest.predict(X_test)\n",
    "    \n",
    "    print('Accuracy of RandomForest classifier on train set: {:.2f}'.format(forest.score(X_train, Y_train)))\n",
    "    print('Accuracy of RandomForest classifier on test set: {:.2f}'.format(forest.score(X_test, Y_test)))\n",
    "    \n",
    "    print(\"Ensemble (Bagging): Random Forest: Confusion Matrix\")\n",
    "    cnf_matrix_rf = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_rf)\n",
    "    \n",
    "    print(\"Ensemble (Bagging): Random Forest: Classification Report\")\n",
    "    print(classification_report(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
