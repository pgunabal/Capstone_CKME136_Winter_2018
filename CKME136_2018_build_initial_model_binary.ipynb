{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\logging.py:130: UserWarning: Couldn't start log: Log file is already active: ipython_log.py\n",
      "  warn(\"Couldn't start log: %s\" % sys.exc_info()[1])\n"
     ]
    }
   ],
   "source": [
    "%logstart -o\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "#in case we need to repeat experiment\n",
    "np.random.seed(255)\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 22\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('classic')\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "#sklearn imports\n",
    "from sklearn.cluster import KMeans\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "#Use print instead of display when run as python script\n",
    "pyscript = True\n",
    "\n",
    "#Classifier verborsity where supported\n",
    "verbose_level=1\n",
    "\n",
    "#Sample Size\n",
    "sampleN = 100000\n",
    "\n",
    "import time\n",
    "\n",
    "#Enable Optimization Algorithms\n",
    "enable_grid_search = True\n",
    "svm_c = 1\n",
    "svm_gamma = 1\n",
    "enable_rf_features = True\n",
    "feature_all = False\n",
    "defaultFeatures = ['P_AGE', 'V_YEAR', 'C_HOUR', 'C_YEAR', 'C_MNTH', 'C_CONF', 'C_WDAY', 'C_VEHS', 'P_USER', 'P_SEX']\n",
    "enable_kmeans = True\n",
    "enable_logistic_regression_l1 = True\n",
    "\n",
    "# Enable Algorithms\n",
    "enable_logistic_regression = True\n",
    "enable_decision_tree = True\n",
    "enable_svm = True\n",
    "enable_knn = True\n",
    "enable_mlp = True\n",
    "enable_rf = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 20\n",
      "Grid Search: Enabled\n",
      "Feature Selection by RandomForest: Disabled\n",
      "Default Feature: ['P_AGE', 'V_YEAR', 'C_HOUR', 'C_YEAR', 'C_MNTH', 'C_CONF', 'C_WDAY', 'C_VEHS', 'P_USER', 'P_SEX']\n",
      "K-means: Enabled\n",
      "Logistic Regression: Enabled\n",
      "Decision Tree: Enabled\n",
      "Support Vector Machines: Enabled\n",
      "KNN: Enabled\n",
      "MLP: Enabled\n",
      "Random Forest: Enabeld\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample size: {}\".format(sampleN))\n",
    "\n",
    "if enable_grid_search:\n",
    "    print(\"Grid Search: Enabled\")\n",
    "else:\n",
    "    print(\"Grid Search: Disabled\")\n",
    "\n",
    "if enable_rf_features:\n",
    "    print(\"Feature Selection by RandomForest: Enabled\")\n",
    "else:\n",
    "    print(\"Feature Selection by RandomForest: Disabled\")\n",
    "    print(\"Default Feature: {}\".format(defaultFeatures))\n",
    "\n",
    "if feature_all:\n",
    "    print(\"All Features: Enabled\")\n",
    "else:\n",
    "    print(\"All Features: Disabled\")\n",
    "    \n",
    "if enable_kmeans:\n",
    "    print(\"K-means: Enabled\")\n",
    "else:\n",
    "    print(\"K-means: Disabled\")\n",
    "\n",
    "if enable_logistic_regression:\n",
    "    print(\"Logistic Regression: Enabled\")\n",
    "else:\n",
    "    print(\"Logistic Regression: Disabled\")\n",
    "    \n",
    "if enable_decision_tree:\n",
    "    print(\"Decision Tree: Enabled\")\n",
    "else:\n",
    "    print(\"Decision Tree: Disabled\")\n",
    "    \n",
    "if enable_svm:\n",
    "    print(\"Support Vector Machines: Enabled\")\n",
    "else:\n",
    "    print(\"Support Vector Machines: Disabled\")\n",
    "\n",
    "if  enable_knn:\n",
    "    print(\"KNN: Enabled\")\n",
    "else:\n",
    "    print(\"KNN: Disabled\")\n",
    "    \n",
    "if enable_mlp:\n",
    "    print(\"MLP: Enabled\")\n",
    "else:\n",
    "    print(\"MLP: Disabled\")\n",
    "    \n",
    "if enable_rf:\n",
    "    print(\"Random Forest: Enabeld\")\n",
    "else:\n",
    "    print(\"Random Forest: Disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.stdout=open(\"Initial_Binary_Model2.out\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 11 11:27:54 2018\n"
     ]
    }
   ],
   "source": [
    "t_start =  time.time()\n",
    "print(time.asctime( time.localtime(t_start) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C_YEAR  C_MNTH  C_WDAY  C_HOUR  C_VEHS  C_CONF  C_RCFG  C_WTHR  C_RSUR  \\\n",
      "0    1999       1       1       9       2      34       2       1       1   \n",
      "1    1999       1       1       9       2      34       2       1       1   \n",
      "\n",
      "   C_RALN   ...    V_ID  V_TYPE  V_YEAR  P_ID  P_SEX  P_AGE  P_PSN  P_SAFE  \\\n",
      "0       1   ...       1       1    1992     1      0     33     11       2   \n",
      "1       1   ...       2       1    1992     1      0     70     11       2   \n",
      "\n",
      "   P_USER  P_ISEV  \n",
      "0       1       2  \n",
      "1       1       1  \n",
      "\n",
      "[2 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv('data01_simple.csv', engine = 'python')\n",
    "df = pd.read_csv('data01_clean.csv', engine = 'python')\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df[df.columns].apply(lambda x: x.astype(str).str.contains('[^0-9]')).sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = df.astype('category').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_int = df.astype('int').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['C_YEAR', 'C_MNTH', 'C_WDAY', 'C_HOUR', 'C_VEHS', 'C_CONF', 'C_RCFG',\n",
      "       'C_WTHR', 'C_RSUR', 'C_RALN', 'C_TRAF', 'V_ID', 'V_TYPE', 'V_YEAR',\n",
      "       'P_ID', 'P_SEX', 'P_AGE', 'P_PSN', 'P_SAFE', 'P_USER', 'P_ISEV'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Class Variable to Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570775\n",
      "2084559\n",
      "['1' '0']\n"
     ]
    }
   ],
   "source": [
    "## Convert Class Variable to Binary\n",
    "### Merge Injury and Fatality as a single class\n",
    "### we will compare the results.\n",
    "df_binary_class = df_cat.copy()\n",
    "\n",
    "#perform the conversion in two steps to avoid any unwanted side effects\n",
    "df_binary_class['P_ISEV'] = df_binary_class['P_ISEV'].map({1: 'safe', 2: 'injury', 3:'fatal'})\n",
    "df_binary_class['P_ISEV'] = df_binary_class['P_ISEV'].map({'safe': '0', 'injury': '1', 'fatal':'1'})\n",
    "print((df_binary_class['P_ISEV']=='0').sum())\n",
    "print((df_binary_class['P_ISEV']=='1').sum())\n",
    "print(df_binary_class['P_ISEV'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_100k = df_binary_class.sample(n=sampleN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training and Testing for Binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split between data and class\n",
    "Y = df_100k[df_binary_class.columns[-1]]\n",
    "X = df_100k[df_binary_class.columns[0:df_binary_class.columns.size -1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Test(70%) and Train (30%) for Bianry class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sprint into train and test 70/30\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Xbinary_train, Xbinary_test, Ybinary_train, Ybinary_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write cleaned data to file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets write the datafile for future use\n",
    "df_binary_class.to_csv('cleansimple_binary.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering based on K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 11 11:30:33 2018\n",
      "K-Means Clustering: Start\n",
      "K-Means Clustering: Build\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 11181.05\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 10713.125\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 8859.333333333332\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 7721.647435897436\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 7721.647435897436\n",
      "center shift 0.000000e+00 within tolerance 4.622175e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 10975.125\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 10818.28968253968\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 10818.28968253968\n",
      "center shift 0.000000e+00 within tolerance 4.622175e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 11214.333333333334\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 10894.516666666665\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 10068.670634920636\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 8773.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 7721.647435897436\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 7721.647435897436\n",
      "center shift 0.000000e+00 within tolerance 4.622175e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 12013.066666666666\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 9686.783333333331\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 7721.647435897436\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 7721.647435897436\n",
      "center shift 0.000000e+00 within tolerance 4.622175e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 5809.216666666667\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 5809.216666666667\n",
      "center shift 0.000000e+00 within tolerance 4.622175e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 13818.444444444442\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 11640.18333333333\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 10818.349999999999\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 9427.35\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 7721.647435897436\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 7721.647435897436\n",
      "center shift 0.000000e+00 within tolerance 4.622175e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 11856.3\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 11856.3\n",
      "center shift 0.000000e+00 within tolerance 4.622175e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 11618.404545454545\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 11143.686507936505\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 11143.686507936505\n",
      "center shift 0.000000e+00 within tolerance 4.622175e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 11547.875\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 10975.125\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 10818.28968253968\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 10818.28968253968\n",
      "center shift 0.000000e+00 within tolerance 4.622175e-03\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 10855.833333333334\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 5809.216666666667\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 5809.216666666667\n",
      "center shift 0.000000e+00 within tolerance 4.622175e-03\n",
      "[[2.00800000e+03 1.00000000e+01 6.00000000e+00 2.10000000e+01\n",
      "  2.00000000e+00 2.10000000e+01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00 1.80000000e+01 1.00000000e+00\n",
      "  1.00000000e+00 2.00000000e+03 4.00000000e+00 1.00000000e+00\n",
      "  8.00000000e+00 9.60000000e+01 2.00000000e+00 2.00000000e+00]\n",
      " [2.00586667e+03 7.33333333e+00 4.33333333e+00 1.48000000e+01\n",
      "  2.13333333e+00 2.80000000e+01 1.80000000e+00 1.53333333e+00\n",
      "  1.33333333e+00 1.20000000e+00 9.46666667e+00 1.66666667e+00\n",
      "  2.46666667e+00 1.99933333e+03 1.73333333e+00 6.66666667e-01\n",
      "  2.16000000e+01 1.35333333e+01 2.00000000e+00 1.33333333e+00]\n",
      " [2.00900000e+03 4.25000000e+00 4.50000000e+00 1.30000000e+01\n",
      "  2.75000000e+00 2.45000000e+01 1.75000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 1.75000000e+00 5.50000000e+00 2.25000000e+00\n",
      "  1.00000000e+00 2.00050000e+03 1.00000000e+00 5.00000000e-01\n",
      "  6.25000000e+01 1.10000000e+01 2.00000000e+00 1.00000000e+00]]\n",
      "[1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 0 2 2 1]\n",
      "K-Means Clustering: End\n",
      "Sun Nov 11 11:30:33 2018\n"
     ]
    }
   ],
   "source": [
    "if enable_kmeans:\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    print(\"K-Means Clustering: Start\")\n",
    "    kmeans = KMeans(n_clusters=3, init='random', n_init=10, max_iter=300, tol=1e-04, verbose= verbose_level)\n",
    "    print(\"K-Means Clustering: Build\")\n",
    "    ykm = kmeans.fit(X)\n",
    "    \n",
    "    if pyscript:\n",
    "        print(ykm.cluster_centers_)\n",
    "        print(ykm.labels_)\n",
    "    else:\n",
    "        display(ykm.cluster_centers_)\n",
    "        display(ykm.labels_)\n",
    "    \n",
    "    print(\"K-Means Clustering: End\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection using Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the inportant features from random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_rf_features:\n",
    "    print(\"Random Forest Feature Selection: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    forest = RandomForestClassifier(n_estimators=250, random_state=0, n_jobs=-1, verbose=verbose_level)\n",
    "    print(\"Random Forest Feature Selection: Fit Start\")\n",
    "    forest.fit(X, Y)\n",
    "    print(\"Random Forest Feature Selection: Fit\")\n",
    "\n",
    "    importFeatures = forest.feature_importances_\n",
    "    print(\"Random Forest Feature Selection: Feature Importance\")\n",
    "    print(importFeatures)\n",
    "    \n",
    "    indices = np.argsort(importFeatures)[::-1]\n",
    "    print(indices)\n",
    "    featureLabel = X.columns[0:]\n",
    "    print(featureLabel)\n",
    "    rankedFeature = []\n",
    "    for f in range(X.shape[1]):\n",
    "        rankedFeature.append(featureLabel[indices[f]])\n",
    "        print(\"%2d) %-*s %f\" % (f+1, 30,  featureLabel[indices[f]], importFeatures[indices[f]]))\n",
    "    print(rankedFeature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce the number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C_YEAR C_MNTH C_WDAY C_HOUR C_VEHS C_CONF C_RCFG C_WTHR C_RSUR C_RALN  \\\n",
      "1497736   2005      7      5     16      2     21      2      1      1      2   \n",
      "3059749   2013      8      5      8      2     36      3      1      1      1   \n",
      "1908179   2007      6      6     21      3     31      2      1      1      1   \n",
      "737129    2002      3      4     18      2     31      2      1      1      1   \n",
      "345811    2000      7      4     13      2     31      2      1      1      1   \n",
      "3372130   2015      6      2     14      3     33      2      1      1      1   \n",
      "2647942   2011      5      5     18      2     35      3      1      1      1   \n",
      "1760000   2006     10      1     23      1      6      1      4      4      1   \n",
      "1321151   2004      9      6     13      2     31      1      2      2      2   \n",
      "942120    2003      1      4     14      3     21      1      1      1      3   \n",
      "3425156   2015      9      5     10      2     35      2      1      1      1   \n",
      "1308966   2004      9      2     13      2     21      2      1      1      1   \n",
      "2174963   2008     11      1     17      2     33      2      2      1      1   \n",
      "355229    2000      7      7     15      2     34      1      2      1      1   \n",
      "1438872   2005      4      5     13      3     21      1      1      1      1   \n",
      "900425    2002     11      5      7      2     21      1      3      2      2   \n",
      "2171315   2008     10      6     21      2     21      1      1      1      1   \n",
      "3305525   2015      1      4     16      3     21      2      1      1      1   \n",
      "1033057   2003      6      5     12      3     21      2      1      1      2   \n",
      "1718581   2006      7      7     13      2     35      2      1      1      1   \n",
      "\n",
      "        C_TRAF V_ID V_TYPE V_YEAR P_ID P_SEX P_AGE P_PSN P_SAFE P_USER  \n",
      "1497736      3    2      9   1993    4     1     9    32      2      2  \n",
      "3059749     18    1      5   2012    1     1    28    11      2      1  \n",
      "1908179      1    3      1   1991    1     0    19    11      2      1  \n",
      "737129       1    2      1   1977    2     1    15    12      2      2  \n",
      "345811       3    2      1   2000    1     1    32    11      2      1  \n",
      "3372130      1    1      6   2015    1     1    23    11      2      1  \n",
      "2647942     18    1      1   2003    1     0    19    11      2      1  \n",
      "1760000     18    1      1   2003    5     1    12    23      2      2  \n",
      "1321151     18    2      6   2002    1     1    23    11      2      1  \n",
      "942120      18    2      1   2000    1     1    53    11      2      1  \n",
      "3425156      2    1      1   1999    1     1    68    11      2      1  \n",
      "1308966      3    1      1   1994    1     1    23    11      2      1  \n",
      "2174963      1    2      1   2006    1     0    27    11      2      1  \n",
      "355229      18    1      1   1999    2     0    21    13      2      2  \n",
      "1438872     18    2      1   1996    2     1    20    11      2      1  \n",
      "900425      18    2      1   2000    1     0    35    11      2      1  \n",
      "2171315     18    1      1   2000    4     1     8    96      2      2  \n",
      "3305525      1    3      1   2004    1     0    67    11      2      1  \n",
      "1033057      1    3      1   1999    1     0    62    11      2      1  \n",
      "1718581      3    2      1   1999    2     1    18    13      2      2  \n",
      "Sun Nov 11 11:30:33 2018\n",
      "Random Forest Feature Selection: End\n"
     ]
    }
   ],
   "source": [
    "#select features that contribute more than 0.05\n",
    "if enable_rf_features:\n",
    "    X_Selected = X[rankedFeature[0:10]]\n",
    "else:\n",
    "    if feature_all:\n",
    "        X_Selected = X\n",
    "    else:\n",
    "        X_Selected = X[defaultFeatures]\n",
    "\n",
    "if pyscript:\n",
    "    print(X_Selected)\n",
    "else:\n",
    "    display(X_Selected)\n",
    "\n",
    "t_end =  time.time()\n",
    "print(time.asctime( time.localtime(t_end) ))\n",
    "\n",
    "print(\"Random Forest Feature Selection: End\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Test and Train based on Selected Features\n"
     ]
    }
   ],
   "source": [
    "print(\"Split Test and Train based on Selected Features\")\n",
    "#sprint into train and test 70/30\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_Selected, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM GridSearch for Optimal Parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 11 11:30:33 2018\n",
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "{'C': 1, 'gamma': 0.001}\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "[[2 0]\n",
      " [1 3]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      1.00      0.80         2\n",
      "          1       1.00      0.75      0.86         4\n",
      "\n",
      "avg / total       0.89      0.83      0.84         6\n",
      "\n",
      "Sun Nov 11 11:30:33 2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "#This operation is computationaly expensive.\n",
    "if enable_grid_search:\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    param_grid = {'C':[0.1, 1, 10, 100, 1000], 'gamma':[1, 0.1, 0.01, 0.001, 0.0001]}\n",
    "    grid = GridSearchCV(SVC(), param_grid, verbose=verbose_level)\n",
    "    grid.fit(X_train, Y_train)\n",
    "    print(grid.best_params_)\n",
    "    svm_c = grid.best_params_.get('C')\n",
    "    svm_gamma = grid.best_params_.get('gamma')\n",
    "    print(grid.best_estimator_)\n",
    "    grid_predictions = grid.predict(X_test)\n",
    "    cfn_matrix_grid = confusion_matrix(Y_test, grid_predictions)\n",
    "    print(cfn_matrix_grid)\n",
    "    print(classification_report(Y_test,grid_predictions))\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Start\n",
      "Sun Nov 11 11:30:33 2018\n",
      "Logistic Regression: Fit\n",
      "[LibLinear]Logistic Regression: Predict\n",
      "Accuracy of logistic regression classifier on train set: 1.00\n",
      "Accuracy of logistic regression classifier on test set: 0.83\n",
      "Logistic Regression: Intercept\n",
      "[0.00092619]\n",
      "Logistic Regression: Coefficients\n",
      "[[ 0.2639404  -0.49979646 -0.36431306  0.47560835 -0.68541925 -0.01019012\n",
      "   0.42673736  0.31623717  0.54542818  0.08781967  0.22732972 -0.31462104\n",
      "  -0.05327987 -0.2753      0.35185206  0.21527758  0.65930677  0.0316277\n",
      "   0.00185237  0.27041625]]\n",
      "Logistic Regression: Confusion Matrix\n",
      "[[2 0]\n",
      " [1 3]]\n",
      "Logistic Regression: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      1.00      0.80         2\n",
      "          1       1.00      0.75      0.86         4\n",
      "\n",
      "avg / total       0.89      0.83      0.84         6\n",
      "\n",
      "Sun Nov 11 11:30:33 2018\n",
      "Logistic Regression: End\n"
     ]
    }
   ],
   "source": [
    "if enable_logistic_regression:\n",
    "    print(\"Logistic Regression: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    lr = LogisticRegression(C=1, random_state=0, verbose=verbose_level)\n",
    "    print(\"Logistic Regression: Fit\")\n",
    "    lr.fit(X_train, Y_train)\n",
    "    print(\"Logistic Regression: Predict\")\n",
    "    y_pred = lr.predict(X_test)\n",
    "\n",
    "    print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(lr.score(X_train, Y_train)))\n",
    "    print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(lr.score(X_test, Y_test)))\n",
    "\n",
    "    # print the intercept (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "    print(\"Logistic Regression: Intercept\")\n",
    "    print(lr.intercept_)\n",
    "\n",
    "    # print the coeficients (Note: one vs rest => 1 vs 2and3, 2 vs 1and3, 3 vs 1and2)\n",
    "    print(\"Logistic Regression: Coefficients\")\n",
    "    print(lr.coef_)\n",
    "\n",
    "    print(\"Logistic Regression: Confusion Matrix\")\n",
    "    cnf_matrix_lg = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_lg)\n",
    "    \n",
    "    print(\"Logistic Regression: Classification Report\")\n",
    "    print(classification_report(Y_test, y_pred))\n",
    "\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "    print(\"Logistic Regression: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with L1 Regularization: Start\n",
      "Sun Nov 11 11:30:34 2018\n",
      "Logistic Regression with L1 Regularization: Fit\n",
      "[LibLinear]Logistic Regression with L1 Regularization: Predict\n",
      "Accuracy of logistic regression classifier on train set: 0.93\n",
      "Accuracy of logistic regression classifier on test set: 0.83\n",
      "Logistic Regression with L1 Regularization: Confusion Matrix\n",
      "[[2 0]\n",
      " [1 3]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      1.00      0.80         2\n",
      "          1       1.00      0.75      0.86         4\n",
      "\n",
      "avg / total       0.89      0.83      0.84         6\n",
      "\n",
      "Logistic Regression with L1 Regularization: Classification Report\n",
      "Sun Nov 11 11:30:34 2018\n",
      "Logistic Regression with L1 Regularization: End\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:898: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "if enable_logistic_regression_l1:\n",
    "    # with L1 regularization\n",
    "    print(\"Logistic Regression with L1 Regularization: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    lr = LogisticRegression(penalty='l1', C=1, random_state=0, verbose=verbose_level)\n",
    "    print(\"Logistic Regression with L1 Regularization: Fit\")\n",
    "    lr.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"Logistic Regression with L1 Regularization: Predict\")\n",
    "    y_pred = lr.predict(X_test)\n",
    "    \n",
    "    print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(lr.score(X_train, Y_train)))\n",
    "    print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(lr.score(X_test, Y_test)))\n",
    "\n",
    "    print(\"Logistic Regression with L1 Regularization: Confusion Matrix\")\n",
    "    cnf_matrix_lg_l1 = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_lg_l1)\n",
    "    \n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    print(\"Logistic Regression with L1 Regularization: Classification Report\")\n",
    "\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "    print(\"Logistic Regression with L1 Regularization: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: Start\n",
      "Sun Nov 11 11:30:34 2018\n",
      "Decision Tree: Fit\n",
      "Decision Tree: Predict\n",
      "Accuracy of Decision Tree classifier on train set: 1.00\n",
      "Accuracy of Decision Tree classifier on test set: 0.83\n",
      "Decision Tree: Confusion Matrix\n",
      "[[2 0]\n",
      " [1 3]]\n",
      "Decision Tree: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      1.00      0.80         2\n",
      "          1       1.00      0.75      0.86         4\n",
      "\n",
      "avg / total       0.89      0.83      0.84         6\n",
      "\n",
      "Sun Nov 11 11:30:34 2018\n",
      "Decision Tree: End\n"
     ]
    }
   ],
   "source": [
    "if enable_decision_tree:\n",
    "    print(\"Decision Tree: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    tree = DecisionTreeClassifier(criterion='entropy',max_depth=100, random_state=0)\n",
    "    print(\"Decision Tree: Fit\")\n",
    "    tree.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"Decision Tree: Predict\")\n",
    "    y_pred = tree.predict(X_test)\n",
    "    print('Accuracy of Decision Tree classifier on train set: {:.2f}'.format(tree.score(X_train, Y_train)))\n",
    "    print('Accuracy of Decision Tree classifier on test set: {:.2f}'.format(tree.score(X_test, Y_test)))\n",
    "    \n",
    "    cnf_matrix_dt = confusion_matrix(Y_test, y_pred)\n",
    "    print(\"Decision Tree: Confusion Matrix\")\n",
    "    print(cnf_matrix_dt)\n",
    "    print(\"Decision Tree: Classification Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    print(\"Decision Tree: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-N-N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: Start\n",
      "Sun Nov 11 11:30:34 2018\n",
      "KNN: Fit\n",
      "KNN: Predict\n",
      "Accuracy of KNN classifier on train set: 0.57\n",
      "Accuracy of KNN classifier on test set: 0.67\n",
      "KNN: Confusion Matrix\n",
      "[[1 1]\n",
      " [1 3]]\n",
      "KNN: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.50      0.50         2\n",
      "          1       0.75      0.75      0.75         4\n",
      "\n",
      "avg / total       0.67      0.67      0.67         6\n",
      "\n",
      "Sun Nov 11 11:30:34 2018\n",
      "KNN: End\n"
     ]
    }
   ],
   "source": [
    "if enable_knn:\n",
    "    print(\"KNN: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    knn = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "    print(\"KNN: Fit\")\n",
    "    knn.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"KNN: Predict\")\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print('Accuracy of KNN classifier on train set: {:.2f}'.format(knn.score(X_train, Y_train)))\n",
    "    print('Accuracy of KNN classifier on test set: {:.2f}'.format(knn.score(X_test, Y_test)))\n",
    "    \n",
    "    print(\"KNN: Confusion Matrix\")\n",
    "    cnf_matrix_knn = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_knn)\n",
    "\n",
    "    print(\"KNN: Classification Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "\n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "\n",
    "    print(\"KNN: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: Start\n",
      "Sun Nov 11 11:30:34 2018\n",
      "SVM: Fit\n",
      "[LibSVM]SVM: Predict\n",
      "Accuracy of SVM classifier on train set: 0.71\n",
      "Accuracy of SVM classifier on test set: 0.83\n",
      "SVM: Confusion Matrix\n",
      "[[2 0]\n",
      " [1 3]]\n",
      "SVM: Classfication Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      1.00      0.80         2\n",
      "          1       1.00      0.75      0.86         4\n",
      "\n",
      "avg / total       0.89      0.83      0.84         6\n",
      "\n",
      "Sun Nov 11 11:30:34 2018\n",
      "SVM: End\n"
     ]
    }
   ],
   "source": [
    "if enable_svm:\n",
    "    print(\"SVM: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    #svm = SVC(C=1, random_state=0, kernel='sigmoid', verbose=True)\n",
    "    #svm = SVC(C=1, random_state=0, kernel='linear', verbose=True, cache_size=200)\n",
    "    svm = SVC(C=svm_c, gamma=svm_gamma, verbose = verbose_level)\n",
    "    print(\"SVM: Fit\")\n",
    "    svm.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"SVM: Predict\")\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    print('Accuracy of SVM classifier on train set: {:.2f}'.format(svm.score(X_train, Y_train)))\n",
    "    print('Accuracy of SVM classifier on test set: {:.2f}'.format(svm.score(X_test, Y_test)))\n",
    "    \n",
    "    print(\"SVM: Confusion Matrix\")\n",
    "    cnf_matrix_svm = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_svm)\n",
    "    \n",
    "    print(\"SVM: Classfication Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "    print(\"SVM: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN - Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Preceptron: Start\n",
      "Sun Nov 11 11:30:34 2018\n",
      "Multilayer Preceptron: fit\n",
      "Iteration 1, loss = 9.50233944\n",
      "Iteration 2, loss = 7.68951398\n",
      "Iteration 3, loss = 5.73477006\n",
      "Iteration 4, loss = 3.79773224\n",
      "Iteration 5, loss = 1.91898783\n",
      "Iteration 6, loss = 0.67702577\n",
      "Iteration 7, loss = 1.80239473\n",
      "Iteration 8, loss = 2.79859030\n",
      "Iteration 9, loss = 3.06112435\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Multilayer Preceptron: Predict\n",
      "Accuracy of Multilayer Perceptron classifier on train set: 0.43\n",
      "Accuracy of Multilayer Perceptron classifier on test set: 0.67\n",
      "Multilayer Preceptron: Confusion Matrix\n",
      "[[0 2]\n",
      " [0 4]]\n",
      "Multilayer Preceptron: Classificiation Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         2\n",
      "          1       0.67      1.00      0.80         4\n",
      "\n",
      "avg / total       0.44      0.67      0.53         6\n",
      "\n",
      "Sun Nov 11 11:30:34 2018\n",
      "Multilayer Preceptron: End\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "if enable_mlp:\n",
    "    print(\"Multilayer Preceptron: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    \n",
    "    #mlpc = MLPClassifier(alpha=1)\n",
    "    mlpc = MLPClassifier(hidden_layer_sizes=(12, 12, 12), max_iter=1000, verbose=verbose_level)\n",
    "    \n",
    "    #mlp = multilayer_perceptron(n_hidden =2, activation='logistic', algorithm='sgd', random_state=3)\n",
    "    print(\"Multilayer Preceptron: fit\")\n",
    "    mlpc.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"Multilayer Preceptron: Predict\")\n",
    "    y_pred = mlpc.predict(X_test)\n",
    "\n",
    "    print('Accuracy of Multilayer Perceptron classifier on train set: {:.2f}'.format(mlpc.score(X_train, Y_train)))\n",
    "    print('Accuracy of Multilayer Perceptron classifier on test set: {:.2f}'.format(mlpc.score(X_test, Y_test)))\n",
    "    \n",
    "    print(\"Multilayer Preceptron: Confusion Matrix\")\n",
    "    cnf_matrix_mlp = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_mlp)\n",
    "    \n",
    "    print(\"Multilayer Preceptron: Classificiation Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    \n",
    "    t_end =  time.time()\n",
    "    print(time.asctime( time.localtime(t_end) ))\n",
    "    \n",
    "    print(\"Multilayer Preceptron: End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble (Bagging): Random Forest: Start\n",
      "Sun Nov 11 11:30:34 2018\n",
      "Ensemble (Bagging): Random Forest: Fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble (Bagging): Random Forest: Predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 250 out of 250 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 250 out of 250 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 250 out of 250 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 250 out of 250 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForest classifier on train set: 1.00\n",
      "Accuracy of RandomForest classifier on test set: 0.67\n",
      "Ensemble (Bagging): Random Forest: Confusion Matrix\n",
      "[[2 0]\n",
      " [2 2]]\n",
      "Ensemble (Bagging): Random Forest: Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      1.00      0.67         2\n",
      "          1       1.00      0.50      0.67         4\n",
      "\n",
      "avg / total       0.83      0.67      0.67         6\n",
      "\n",
      "Sun Nov 11 11:30:34 2018\n",
      "Ensemble (Bagging): Random Forest: End\n"
     ]
    }
   ],
   "source": [
    "if enable_rf:\n",
    "    print(\"Ensemble (Bagging): Random Forest: Start\")\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    forest = RandomForestClassifier(criterion='entropy', n_estimators=250, random_state=0, n_jobs=2, verbose=verbose_level)\n",
    "    print(\"Ensemble (Bagging): Random Forest: Fit\")\n",
    "    forest.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"Ensemble (Bagging): Random Forest: Predict\")\n",
    "    y_pred = forest.predict(X_test)\n",
    "    \n",
    "    print('Accuracy of RandomForest classifier on train set: {:.2f}'.format(forest.score(X_train, Y_train)))\n",
    "    print('Accuracy of RandomForest classifier on test set: {:.2f}'.format(forest.score(X_test, Y_test)))\n",
    "    \n",
    "    print(\"Ensemble (Bagging): Random Forest: Confusion Matrix\")\n",
    "    cnf_matrix_rf = confusion_matrix(Y_test, y_pred)\n",
    "    print(cnf_matrix_rf)\n",
    "    \n",
    "    print(\"Ensemble (Bagging): Random Forest: Classification Report\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "\n",
    "    t_start =  time.time()\n",
    "    print(time.asctime( time.localtime(t_start) ))\n",
    "    \n",
    "    print(\"Ensemble (Bagging): Random Forest: End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#check sigmoid and rbf\n",
    "#from sklearn.ensemble import BaggingClassifier\n",
    "#from sklearn.svm import SVC\n",
    "#clf = BaggingClassifier(SVC(C=1.0,\n",
    "#        cache_size=200,\n",
    "#        class_weight=None,\n",
    "#        coef0=0.0,\n",
    "#        decision_function_shape=None,\n",
    "#        degree=3,\n",
    "#        gamma='auto',\n",
    "#        kernel='linear',\n",
    "#        max_iter=-1,\n",
    "#        probability=False,\n",
    "#        random_state=None,\n",
    "#        shrinking=True,\n",
    "#        tol=0.001,\n",
    "#        verbose=False,\n",
    "#        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 11 11:30:34 2018\n"
     ]
    }
   ],
   "source": [
    "t_end =  time.time()\n",
    "print(time.asctime( time.localtime(t_end) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.stdout.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
